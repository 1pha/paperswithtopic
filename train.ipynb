{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cc6e76",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1639fa02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T02:52:41.720925Z",
     "start_time": "2021-07-02T02:52:38.036377Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from paperswithtopic.config import load_config\n",
    "from paperswithtopic.run import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba98b5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T02:47:48.215053Z",
     "start_time": "2021-07-02T02:47:48.187534Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = load_config()\n",
    "cfg.use_saved = True\n",
    "cfg.pre_embed = False\n",
    "cfg.use_bert_embed = False\n",
    "\n",
    "cfg.model_name = 'bertforclassification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e68b304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T02:02:52.126225Z",
     "start_time": "2021-06-16T02:02:52.111185Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.init(project='paperswithtopic', name='bertforclassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425cb95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T12:41:16.827319Z",
     "start_time": "2021-06-15T12:41:09.533866Z"
    }
   },
   "outputs": [],
   "source": [
    "run(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89518309",
   "metadata": {},
   "source": [
    "# Hyperparameter grid search with wandb.sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28aaf188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T02:52:42.602481Z",
     "start_time": "2021-07-02T02:52:41.721927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: zbcdux61\n",
      "Sweep URL: https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'name': 'bertforclassification_re',\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': 'valid_auc',\n",
    "        'goal': 'maximize',\n",
    "    },\n",
    "    'parameters': {\n",
    "        'model_name': {\n",
    "            'values': [\n",
    "                'rnn',\n",
    "                'lstm',\n",
    "                'gru',\n",
    "\n",
    "                'bert',\n",
    "                'albert',\n",
    "                'electra',\n",
    "\n",
    "                'bertclassification',\n",
    "                'albertclassification',\n",
    "                'electraclassification',\n",
    "            ]\n",
    "        },\n",
    "        'embed_dim': {\n",
    "            'values': [256, 512]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project='paperswithtopic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a29cfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T02:52:42.618472Z",
     "start_time": "2021-07-02T02:52:42.604472Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def run_sweep():\n",
    "    \n",
    "    with wandb.init(tags=['lookup-all']):\n",
    "        \n",
    "        cfg = load_config()\n",
    "        \n",
    "        cfg.use_saved = True\n",
    "        cfg.pre_embed = False\n",
    "        cfg.use_bert_embed = False        \n",
    "        \n",
    "        _cfg = wandb.config\n",
    "        __cfg = dict(); __cfg.update(_cfg); cfg.update(__cfg)\n",
    "        \n",
    "        cfg.hidden_dim = cfg.embed_dim\n",
    "        name = f'SWEEP_MD{cfg.model_name}_ED{cfg.embed_dim}'\n",
    "        \n",
    "        \n",
    "        wandb.run.name = name\n",
    "        wandb.config.update(cfg)\n",
    "        \n",
    "        run(cfg)\n",
    "        \n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cebc37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T02:58:59.332308Z",
     "start_time": "2021-07-02T02:52:42.620473Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: zoro70lw with config:\n",
      "wandb: \tembed_dim: 256\n",
      "wandb: \tmodel_name: rnn\n",
      "wandb: Currently logged in as: 1pha (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dauntless-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/1pha/paperswithtopic\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/zoro70lw\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/zoro70lw</a><br/>\n",
       "                Run data is saved locally in <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115243-zoro70lw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Config item 'embed_dim' was locked by 'sweep' (ignored update).\n",
      "wandb: WARNING Config item 'model_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenized, without embeddings.\n",
      "[load_data] 0.3 sec \n",
      "[tokenized_pipeline] 3.8 sec \n",
      "NUM TRAIN 44982 | NUM VALID 4998\n",
      "Use cuda:0 as a device.\n",
      "Load Rnn as model.\n",
      "Epoch 1 / 100, BEST AUC 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\xai501\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 41.9 sec [valid] 3.7 sec \n",
      "TRAIN:: AUC 0.547 | LOSS 0.249\n",
      "VALID:: AUC 0.600 | LOSS 0.244\n",
      "saving model ...\n",
      "Epoch 2 / 100, BEST AUC 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\xai501\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 57.4 sec [valid] 3.6 sec \n",
      "TRAIN:: AUC 0.601 | LOSS 0.247\n",
      "VALID:: AUC 0.619 | LOSS 0.240\n",
      "saving model ...\n",
      "Epoch 3 / 100, BEST AUC 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\xai501\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 57.3 sec [valid] 3.5 sec \n",
      "TRAIN:: AUC 0.615 | LOSS 0.243\n",
      "VALID:: AUC 0.612 | LOSS 0.238\n",
      "saving model ...\n",
      "Epoch 4 / 100, BEST AUC 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\xai501\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 95.9 sec [valid] 5.0 sec \n",
      "TRAIN:: AUC 0.640 | LOSS 0.242\n",
      "VALID:: AUC 0.622 | LOSS 0.238\n",
      "saving model ...\n",
      "Epoch 5 / 100, BEST AUC 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\xai501\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25392<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115243-zoro70lw\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115243-zoro70lw\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_auc</td><td>0.64008</td></tr><tr><td>valid_auc</td><td>0.62219</td></tr><tr><td>train_loss</td><td>0.24163</td></tr><tr><td>valid_loss</td><td>0.23847</td></tr><tr><td>_runtime</td><td>282</td></tr><tr><td>_timestamp</td><td>1625194645</td></tr><tr><td>_step</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_auc</td><td>▁▅▆█</td></tr><tr><td>valid_auc</td><td>▁▇▅█</td></tr><tr><td>train_loss</td><td>█▆▂▁</td></tr><tr><td>valid_loss</td><td>█▂▁▁</td></tr><tr><td>_runtime</td><td>▁▃▅█</td></tr><tr><td>_timestamp</td><td>▁▃▅█</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dauntless-sweep-1</strong>: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/zoro70lw\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/zoro70lw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run zoro70lw errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.34 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: ERROR Run zoro70lw errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.34 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: Agent Starting Run: ymciz6tj with config:\n",
      "wandb: \tembed_dim: 256\n",
      "wandb: \tmodel_name: lstm\n",
      "wandb: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">prime-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/1pha/paperswithtopic\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/ymciz6tj\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/ymciz6tj</a><br/>\n",
       "                Run data is saved locally in <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115738-ymciz6tj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Config item 'embed_dim' was locked by 'sweep' (ignored update).\n",
      "wandb: WARNING Config item 'model_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenized, without embeddings.\n",
      "[load_data] 0.3 sec \n",
      "[tokenized_pipeline] 4.8 sec \n",
      "NUM TRAIN 44982 | NUM VALID 4998\n",
      "Use cuda:0 as a device.\n",
      "Load Lstm as model.\n",
      "Epoch 1 / 100, BEST AUC 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\xai501\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27464<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115738-ymciz6tj\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115738-ymciz6tj\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">prime-sweep-2</strong>: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/ymciz6tj\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/ymciz6tj</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ymciz6tj errored: RuntimeError('CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 8.00 GiB total capacity; 11.38 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: ERROR Run ymciz6tj errored: RuntimeError('CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 8.00 GiB total capacity; 11.38 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: Agent Starting Run: vxzeqo3u with config:\n",
      "wandb: \tembed_dim: 256\n",
      "wandb: \tmodel_name: gru\n",
      "wandb: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">pleasant-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/1pha/paperswithtopic\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/vxzeqo3u\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/vxzeqo3u</a><br/>\n",
       "                Run data is saved locally in <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115755-vxzeqo3u</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Config item 'embed_dim' was locked by 'sweep' (ignored update).\n",
      "wandb: WARNING Config item 'model_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenized, without embeddings.\n",
      "[load_data] 0.2 sec \n",
      "[tokenized_pipeline] 3.2 sec \n",
      "NUM TRAIN 44982 | NUM VALID 4998\n",
      "Use cuda:0 as a device.\n",
      "Load Gru as model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28744<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115755-vxzeqo3u\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115755-vxzeqo3u\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">pleasant-sweep-3</strong>: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/vxzeqo3u\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/vxzeqo3u</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run vxzeqo3u errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: ERROR Run vxzeqo3u errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: Agent Starting Run: iqzqzc7w with config:\n",
      "wandb: \tembed_dim: 256\n",
      "wandb: \tmodel_name: bert\n",
      "wandb: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">worldly-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/1pha/paperswithtopic\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/iqzqzc7w\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/iqzqzc7w</a><br/>\n",
       "                Run data is saved locally in <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115810-iqzqzc7w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Config item 'embed_dim' was locked by 'sweep' (ignored update).\n",
      "wandb: WARNING Config item 'model_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenized, without embeddings.\n",
      "[load_data] 0.2 sec \n",
      "[tokenized_pipeline] 3.6 sec \n",
      "NUM TRAIN 44982 | NUM VALID 4998\n",
      "Use cuda:0 as a device.\n",
      "Load Bert as model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10320<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115810-iqzqzc7w\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115810-iqzqzc7w\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">worldly-sweep-4</strong>: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/iqzqzc7w\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/iqzqzc7w</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run iqzqzc7w errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: ERROR Run iqzqzc7w errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: Agent Starting Run: w3jnxuug with config:\n",
      "wandb: \tembed_dim: 256\n",
      "wandb: \tmodel_name: albert\n",
      "wandb: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">volcanic-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/1pha/paperswithtopic\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/w3jnxuug\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/w3jnxuug</a><br/>\n",
       "                Run data is saved locally in <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115827-w3jnxuug</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Config item 'embed_dim' was locked by 'sweep' (ignored update).\n",
      "wandb: WARNING Config item 'model_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenized, without embeddings.\n",
      "[load_data] 0.2 sec \n",
      "[tokenized_pipeline] 3.3 sec \n",
      "NUM TRAIN 44982 | NUM VALID 4998\n",
      "Use cuda:0 as a device.\n",
      "Load Albert as model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19992<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115827-w3jnxuug\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115827-w3jnxuug\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">volcanic-sweep-5</strong>: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/w3jnxuug\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/w3jnxuug</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run w3jnxuug errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: ERROR Run w3jnxuug errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: Agent Starting Run: ob3fa206 with config:\n",
      "wandb: \tembed_dim: 256\n",
      "wandb: \tmodel_name: electra\n",
      "wandb: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">honest-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/1pha/paperswithtopic\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/sweeps/zbcdux61</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/ob3fa206\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/ob3fa206</a><br/>\n",
       "                Run data is saved locally in <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115844-ob3fa206</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Config item 'embed_dim' was locked by 'sweep' (ignored update).\n",
      "wandb: WARNING Config item 'model_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenized, without embeddings.\n",
      "[load_data] 0.2 sec \n",
      "[tokenized_pipeline] 3.1 sec \n",
      "NUM TRAIN 44982 | NUM VALID 4998\n",
      "Use cuda:0 as a device.\n",
      "Load Electra as model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29468<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115844-ob3fa206\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>G:\\My Drive\\projects\\paperswithcode_nlp\\wandb\\run-20210702_115844-ob3fa206\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">honest-sweep-6</strong>: <a href=\"https://wandb.ai/1pha/paperswithtopic/runs/ob3fa206\" target=\"_blank\">https://wandb.ai/1pha/paperswithtopic/runs/ob3fa206</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ob3fa206 errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "wandb: ERROR Run ob3fa206 errored: RuntimeError('CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 8.00 GiB total capacity; 11.35 GiB already allocated; 0 bytes free; 14.20 GiB reserved in total by PyTorch)')\n",
      "Detected 5 failed runs in a row at start, killing sweep.\n",
      "wandb: ERROR Detected 5 failed runs in a row at start, killing sweep.\n",
      "wandb: To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=run_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b736de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
