{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T11:29:02.585381Z",
     "start_time": "2021-04-28T11:29:00.488131Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib import parse\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T11:29:03.203945Z",
     "start_time": "2021-04-28T11:29:02.591378Z"
    }
   },
   "outputs": [],
   "source": [
    "from tea_client.http import HttpClient\n",
    "from tea_client.handler import handler\n",
    "\n",
    "from paperswithcode import PapersWithCodeClient\n",
    "from paperswithcode.config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Use API to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T11:29:03.235974Z",
     "start_time": "2021-04-28T11:29:03.209996Z"
    }
   },
   "outputs": [],
   "source": [
    "token=None\n",
    "url=None\n",
    "url = url or config.server_url\n",
    "http = HttpClient(\n",
    "    url=f\"{url}/api/v{config.api_version}\",\n",
    "    token=token or \"\",\n",
    "    authorization_method=HttpClient.Authorization.token,\n",
    ")\n",
    "\n",
    "client = PapersWithCodeClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is earning the data. Takes about an hour, so don't run unless you lost them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving title-only code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T11:29:04.345899Z",
     "start_time": "2021-04-28T11:29:03.237943Z"
    }
   },
   "outputs": [],
   "source": [
    "get_id = lambda x: x.id\n",
    "areas_id = list(map(get_id, client.area_list().results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-28T11:28:53.733Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Working on Adversarial ---\n"
     ]
    }
   ],
   "source": [
    "area_paper_dict = {area: [] for area in areas_id}\n",
    "for area in areas_id:\n",
    "    \n",
    "    print(f\"--- Working on {area.capitalize()} ---\")\n",
    "    try:\n",
    "        task_id_lists = list(map(get_id, client.area_task_list(area).results))\n",
    "        \n",
    "    except:\n",
    "        print(f\"**Error occurred with area {area}.**\")\n",
    "        continue\n",
    "        \n",
    "    for task_id in task_id_lists:\n",
    "        \n",
    "        page_idx, papers = 1, []\n",
    "        print(f\"\\tWorking on {task_id.capitalize()}\")\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                results = http.get(f\"/tasks/{task_id}/papers/?page={page_idx}\")['results']\n",
    "                _tmp = [p['title'] for p in results]\n",
    "                papers.extend(_tmp)\n",
    "                page_idx += 1\n",
    "                \n",
    "            except:\n",
    "                print(f\"\\tSuccessfully loaded task {task_id}, with papers {len(papers)}\\n\")\n",
    "                break\n",
    "\n",
    "            area_paper_dict[area].extend(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving all meta-informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T12:37:16.774373Z",
     "start_time": "2021-04-28T11:29:05.966025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Working on Adversarial ---\n",
      "\tWorking on Website-fingerprinting-defense\n",
      "\tSuccessfully loaded task website-fingerprinting-defense, with papers 1\n",
      "\n",
      "\tWorking on Adversarial-attack\n",
      "\tSuccessfully loaded task adversarial-attack, with papers 593\n",
      "\n",
      "\tWorking on Adversarial-defense\n",
      "\tSuccessfully loaded task adversarial-defense, with papers 116\n",
      "\n",
      "\tWorking on Real-world-adversarial-attack\n",
      "\tSuccessfully loaded task real-world-adversarial-attack, with papers 0\n",
      "\n",
      "\tWorking on Provable-adversarial-defense\n",
      "\tSuccessfully loaded task provable-adversarial-defense, with papers 0\n",
      "\n",
      "\tWorking on Adversarial-text\n",
      "\tSuccessfully loaded task adversarial-text, with papers 28\n",
      "\n",
      "\tWorking on Data-poisoning\n",
      "\tSuccessfully loaded task data-poisoning, with papers 122\n",
      "\n",
      "\tWorking on Website-fingerprinting-attacks\n",
      "\tSuccessfully loaded task website-fingerprinting-attacks, with papers 6\n",
      "\n",
      "\tWorking on Inference-attack\n",
      "\tSuccessfully loaded task inference-attack, with papers 58\n",
      "\n",
      "--- Working on Audio ---\n",
      "\tWorking on Shooter-localization\n",
      "\tSuccessfully loaded task shooter-localization, with papers 1\n",
      "\n",
      "\tWorking on Sound-event-detection\n",
      "\tSuccessfully loaded task sound-event-detection, with papers 52\n",
      "\n",
      "\tWorking on Acoustic-scene-classification\n",
      "\tSuccessfully loaded task acoustic-scene-classification, with papers 48\n",
      "\n",
      "\tWorking on Environmental-sound-classification\n",
      "\tSuccessfully loaded task environmental-sound-classification, with papers 23\n",
      "\n",
      "\tWorking on Image-animation\n",
      "\tSuccessfully loaded task image-animation, with papers 13\n",
      "\n",
      "\tWorking on Audio-visual-synchronization\n",
      "\tSuccessfully loaded task audio-visual-synchronization, with papers 7\n",
      "\n",
      "\tWorking on Voice-conversion\n",
      "\tSuccessfully loaded task voice-conversion, with papers 142\n",
      "\n",
      "\tWorking on Gunshot-detection\n",
      "\tSuccessfully loaded task gunshot-detection, with papers 0\n",
      "\n",
      "\tWorking on Bird-classification\n",
      "\tSuccessfully loaded task bird-classification, with papers 0\n",
      "\n",
      "\tWorking on Audio-super-resolution\n",
      "\tSuccessfully loaded task audio-super-resolution, with papers 6\n",
      "\n",
      "\tWorking on Audio-classification\n",
      "\tSuccessfully loaded task audio-classification, with papers 76\n",
      "\n",
      "\tWorking on Speaker-orientation\n",
      "\tSuccessfully loaded task speaker-orientation, with papers 1\n",
      "\n",
      "\tWorking on Voice-anti-spoofing\n",
      "\tSuccessfully loaded task voice-anti-spoofing, with papers 3\n",
      "\n",
      "\tWorking on Audio-tagging\n",
      "\tSuccessfully loaded task audio-tagging, with papers 15\n",
      "\n",
      "\tWorking on Audio-generation\n",
      "\tSuccessfully loaded task audio-generation, with papers 30\n",
      "\n",
      "\tWorking on Audio-source-separation\n",
      "\tSuccessfully loaded task audio-source-separation, with papers 51\n",
      "\n",
      "\tWorking on Vowel-classification\n",
      "\tSuccessfully loaded task vowel-classification, with papers 3\n",
      "\n",
      "\tWorking on Audio-signal-recognition\n",
      "\tSuccessfully loaded task audio-signal-recognition, with papers 2\n",
      "\n",
      "\tWorking on Audio-declipping\n",
      "\tSuccessfully loaded task audio-declipping, with papers 2\n",
      "\n",
      "\tWorking on Audio-fingerprint\n",
      "\tSuccessfully loaded task audio-fingerprint, with papers 1\n",
      "\n",
      "\tWorking on Music-generation\n",
      "\tSuccessfully loaded task music-generation, with papers 96\n",
      "\n",
      "\tWorking on Bird-species-classification-with-audio-visual\n",
      "\tSuccessfully loaded task bird-species-classification-with-audio-visual, with papers 0\n",
      "\n",
      "\tWorking on Audio-denoising\n",
      "\tSuccessfully loaded task audio-denoising, with papers 3\n",
      "\n",
      "\tWorking on Audio-dequantization\n",
      "\tSuccessfully loaded task audio-dequantization, with papers 2\n",
      "\n",
      "\tWorking on Acoustic-novelty-detection\n",
      "\tSuccessfully loaded task acoustic-novelty-detection, with papers 3\n",
      "\n",
      "\tWorking on Direction-of-arrival-estimation\n",
      "\tSuccessfully loaded task direction-of-arrival-estimation, with papers 22\n",
      "\n",
      "\tWorking on Chord-recognition\n",
      "\tSuccessfully loaded task chord-recognition, with papers 11\n",
      "\n",
      "\tWorking on Bird-audio-detection\n",
      "\tSuccessfully loaded task bird-audio-detection, with papers 3\n",
      "\n",
      "--- Working on Computer-code ---\n",
      "\tWorking on Code-comment-generation\n",
      "\tSuccessfully loaded task code-comment-generation, with papers 5\n",
      "\n",
      "\tWorking on Codesearchnet-java\n",
      "\tSuccessfully loaded task codesearchnet-java, with papers 0\n",
      "\n",
      "\tWorking on Single-image-portrait-relighting\n",
      "\tSuccessfully loaded task single-image-portrait-relighting, with papers 2\n",
      "\n",
      "\tWorking on Text-to-sql\n",
      "\tSuccessfully loaded task text-to-sql, with papers 71\n",
      "\n",
      "\tWorking on Annotated-code-search\n",
      "\tSuccessfully loaded task annotated-code-search, with papers 2\n",
      "\n",
      "\tWorking on Sparse-subspace-based-clustering\n",
      "\tSuccessfully loaded task sparse-subspace-based-clustering, with papers 1\n",
      "\n",
      "\tWorking on Sentinel-1-sar-processing\n",
      "\tSuccessfully loaded task sentinel-1-sar-processing, with papers 1\n",
      "\n",
      "\tWorking on Program-synthesis\n",
      "\tSuccessfully loaded task program-synthesis, with papers 128\n",
      "\n",
      "\tWorking on Sql-synthesis\n",
      "\tSuccessfully loaded task sql-synthesis, with papers 0\n",
      "\n",
      "\tWorking on Swapped-operands\n",
      "\tSuccessfully loaded task swapped-operands, with papers 1\n",
      "\n",
      "\tWorking on Api-sequence-recommendation\n",
      "\tSuccessfully loaded task api-sequence-recommendation, with papers 0\n",
      "\n",
      "\tWorking on Formalize-foundations-of-universal-algebra-in\n",
      "\tSuccessfully loaded task formalize-foundations-of-universal-algebra-in, with papers 1\n",
      "\n",
      "\tWorking on Wrong-binary-operator\n",
      "\tSuccessfully loaded task wrong-binary-operator, with papers 0\n",
      "\n",
      "\tWorking on Low-rank-compression\n",
      "\tSuccessfully loaded task low-rank-compression, with papers 8\n",
      "\n",
      "\tWorking on Variable-misuse\n",
      "\tSuccessfully loaded task variable-misuse, with papers 4\n",
      "\n",
      "\tWorking on Program-induction\n",
      "\tSuccessfully loaded task program-induction, with papers 31\n",
      "\n",
      "\tWorking on Code-search\n",
      "\tSuccessfully loaded task code-search, with papers 25\n",
      "\n",
      "\tWorking on Function-docstring-mismatch\n",
      "\tSuccessfully loaded task function-docstring-mismatch, with papers 0\n",
      "\n",
      "\tWorking on Fault-localization\n",
      "\tSuccessfully loaded task fault-localization, with papers 15\n",
      "\n",
      "\tWorking on Semi-supervised-semantic-segmentation\n",
      "\tSuccessfully loaded task semi-supervised-semantic-segmentation, with papers 37\n",
      "\n",
      "\tWorking on Enumerative-search\n",
      "\tSuccessfully loaded task enumerative-search, with papers 1\n",
      "\n",
      "\tWorking on Federated-learning\n",
      "\tSuccessfully loaded task federated-learning, with papers 949\n",
      "\n",
      "\tWorking on Write-computer-programs-from-specifications\n",
      "\tSuccessfully loaded task write-computer-programs-from-specifications, with papers 0\n",
      "\n",
      "\tWorking on Program-repair\n",
      "\tSuccessfully loaded task program-repair, with papers 18\n",
      "\n",
      "\tWorking on Type-prediction\n",
      "\tSuccessfully loaded task type-prediction, with papers 40\n",
      "\n",
      "\tWorking on Code-summarization\n",
      "\tSuccessfully loaded task code-summarization, with papers 25\n",
      "\n",
      "\tWorking on Webcam-rgb-image-classification\n",
      "\tSuccessfully loaded task webcam-rgb-image-classification, with papers 3\n",
      "\n",
      "\tWorking on Sql-to-text\n",
      "\tSuccessfully loaded task sql-to-text, with papers 3\n",
      "\n",
      "\tWorking on Exception-type\n",
      "\tSuccessfully loaded task exception-type, with papers 0\n",
      "\n",
      "\tWorking on Code-generation\n",
      "\tSuccessfully loaded task code-generation, with papers 96\n",
      "\n",
      "\tWorking on Learning-to-execute\n",
      "\tSuccessfully loaded task learning-to-execute, with papers 5\n",
      "\n",
      "\tWorking on Value-prediction\n",
      "\tSuccessfully loaded task value-prediction, with papers 23\n",
      "\n",
      "\tWorking on Log-parsing\n",
      "\tSuccessfully loaded task log-parsing, with papers 3\n",
      "\n",
      "\tWorking on Sql-chatbots\n",
      "\tSuccessfully loaded task sql-chatbots, with papers 1\n",
      "\n",
      "\tWorking on Contextual-embedding-for-source-code\n",
      "\tSuccessfully loaded task contextual-embedding-for-source-code, with papers 0\n",
      "\n",
      "\tWorking on Git-commit-message-generation\n",
      "\tSuccessfully loaded task git-commit-message-generation, with papers 0\n",
      "\n",
      "--- Working on Computer-vision ---\n",
      "\tWorking on De-aliasing\n",
      "\tSuccessfully loaded task de-aliasing, with papers 10\n",
      "\n",
      "\tWorking on Point-set-upsampling\n",
      "\tSuccessfully loaded task point-set-upsampling, with papers 2\n",
      "\n",
      "\tWorking on Facial-inpainting\n",
      "\tSuccessfully loaded task facial-inpainting, with papers 26\n",
      "\n",
      "\tWorking on Monocular-depth-estimation\n",
      "\tSuccessfully loaded task monocular-depth-estimation, with papers 234\n",
      "\n",
      "\tWorking on Scene-flow-estimation\n",
      "\tSuccessfully loaded task scene-flow-estimation, with papers 48\n",
      "\n",
      "\tWorking on Event-based-vision\n",
      "\tSuccessfully loaded task event-based-vision, with papers 27\n",
      "\n",
      "\tWorking on Concurrent-activity-recognition\n",
      "\tSuccessfully loaded task concurrent-activity-recognition, with papers 2\n",
      "\n",
      "\tWorking on Direct-transfer-person-re-identification\n",
      "\tSuccessfully loaded task direct-transfer-person-re-identification, with papers 1\n",
      "\n",
      "\tWorking on Fine-grained-action-recognition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task fine-grained-action-recognition, with papers 14\n",
      "\n",
      "\tWorking on Camera-auto-calibration\n",
      "\tSuccessfully loaded task camera-auto-calibration, with papers 4\n",
      "\n",
      "\tWorking on Saliency-detection\n",
      "\tSuccessfully loaded task saliency-detection, with papers 234\n",
      "\n",
      "\tWorking on Video-story-qa\n",
      "\tSuccessfully loaded task video-story-qa, with papers 3\n",
      "\n",
      "\tWorking on 3d-object-super-resolution\n",
      "\tSuccessfully loaded task 3d-object-super-resolution, with papers 2\n",
      "\n",
      "\tWorking on Multi-object-discovery\n",
      "\tSuccessfully loaded task multi-object-discovery, with papers 1\n",
      "\n",
      "\tWorking on Road-damage-detection\n",
      "\tSuccessfully loaded task road-damage-detection, with papers 12\n",
      "\n",
      "\tWorking on Image-classification\n",
      "\tSuccessfully loaded task image-classification, with papers 3581\n",
      "\n",
      "\tWorking on Visual-tracking\n",
      "\tSuccessfully loaded task visual-tracking, with papers 323\n",
      "\n",
      "\tWorking on 3d-object-reconstruction\n",
      "\tSuccessfully loaded task 3d-object-reconstruction, with papers 61\n",
      "\n",
      "\tWorking on Occluded-face-detection\n",
      "\tSuccessfully loaded task occluded-face-detection, with papers 3\n",
      "\n",
      "\tWorking on Retinal-oct-disease-classification\n",
      "\tSuccessfully loaded task retinal-oct-disease-classification, with papers 5\n",
      "\n",
      "\tWorking on Visual-recognition\n",
      "\tSuccessfully loaded task visual-recognition, with papers 0\n",
      "\n",
      "\tWorking on Surgical-tool-detection\n",
      "\tSuccessfully loaded task surgical-tool-detection, with papers 5\n",
      "\n",
      "\tWorking on Unsupervised-video-clustering\n",
      "\tSuccessfully loaded task unsupervised-video-clustering, with papers 1\n",
      "\n",
      "\tWorking on Face-alignment\n",
      "\tSuccessfully loaded task face-alignment, with papers 212\n",
      "\n",
      "\tWorking on Motion-estimation\n",
      "\tSuccessfully loaded task motion-estimation, with papers 311\n",
      "\n",
      "\tWorking on Object-recognition\n",
      "\tSuccessfully loaded task object-recognition, with papers 1121\n",
      "\n",
      "\tWorking on Simultaneous-localization-and-mapping\n",
      "\tSuccessfully loaded task simultaneous-localization-and-mapping, with papers 195\n",
      "\n",
      "\tWorking on Object-discovery\n",
      "\tSuccessfully loaded task object-discovery, with papers 63\n",
      "\n",
      "\tWorking on Fine-grained-visual-categorization\n",
      "\tSuccessfully loaded task fine-grained-visual-categorization, with papers 33\n",
      "\n",
      "\tWorking on Video-prediction\n",
      "\tSuccessfully loaded task video-prediction, with papers 159\n",
      "\n",
      "\tWorking on 2d-object-detection\n",
      "\tSuccessfully loaded task 2d-object-detection, with papers 49\n",
      "\n",
      "\tWorking on Street-scene-parsing\n",
      "\tSuccessfully loaded task street-scene-parsing, with papers 2\n",
      "\n",
      "\tWorking on Smile-recognition\n",
      "\tSuccessfully loaded task smile-recognition, with papers 4\n",
      "\n",
      "\tWorking on Deepfake-detection\n",
      "\tSuccessfully loaded task deepfake-detection, with papers 60\n",
      "\n",
      "\tWorking on Saliency-prediction-1\n",
      "\tSuccessfully loaded task saliency-prediction-1, with papers 1\n",
      "\n",
      "\tWorking on Facial-beauty-prediction\n",
      "\tSuccessfully loaded task facial-beauty-prediction, with papers 4\n",
      "\n",
      "\tWorking on Edge-detection\n",
      "\tSuccessfully loaded task edge-detection, with papers 223\n",
      "\n",
      "\tWorking on Scene-text-editing\n",
      "\tSuccessfully loaded task scene-text-editing, with papers 2\n",
      "\n",
      "\tWorking on Video-salient-object-detection\n",
      "\tSuccessfully loaded task video-salient-object-detection, with papers 17\n",
      "\n",
      "\tWorking on Sign-language-recognition\n",
      "\tSuccessfully loaded task sign-language-recognition, with papers 98\n",
      "\n",
      "\tWorking on Small-data\n",
      "\tSuccessfully loaded task small-data, with papers 160\n",
      "\n",
      "\tWorking on Active-observation-completion\n",
      "\tSuccessfully loaded task active-observation-completion, with papers 1\n",
      "\n",
      "\tWorking on Multimodal-emotion-recognition\n",
      "\tSuccessfully loaded task multimodal-emotion-recognition, with papers 36\n",
      "\n",
      "\tWorking on Deception-detection-in-videos\n",
      "\tSuccessfully loaded task deception-detection-in-videos, with papers 3\n",
      "\n",
      "\tWorking on Salt-and-pepper-noise-removal\n",
      "\tSuccessfully loaded task salt-and-pepper-noise-removal, with papers 9\n",
      "\n",
      "\tWorking on Image-recognition\n",
      "\tSuccessfully loaded task image-recognition, with papers 1\n",
      "\n",
      "\tWorking on Video-style-transfer\n",
      "\tSuccessfully loaded task video-style-transfer, with papers 13\n",
      "\n",
      "\tWorking on Traffic-sign-recognition\n",
      "\tSuccessfully loaded task traffic-sign-recognition, with papers 36\n",
      "\n",
      "\tWorking on Intelligent-surveillance\n",
      "\tSuccessfully loaded task intelligent-surveillance, with papers 0\n",
      "\n",
      "\tWorking on 3d-pose-estimation\n",
      "\tSuccessfully loaded task 3d-pose-estimation, with papers 196\n",
      "\n",
      "--- Working on Graphs ---\n",
      "\tWorking on Structural-node-embedding\n",
      "\tSuccessfully loaded task structural-node-embedding, with papers 2\n",
      "\n",
      "\tWorking on Graphon-estimation\n",
      "\tSuccessfully loaded task graphon-estimation, with papers 14\n",
      "\n",
      "\tWorking on Physics-informed-machine-learning\n",
      "\tSuccessfully loaded task physics-informed-machine-learning, with papers 20\n",
      "\n",
      "\tWorking on Knowledge-graph-embeddings\n",
      "\tSuccessfully loaded task knowledge-graph-embeddings, with papers 92\n",
      "\n",
      "\tWorking on Node-classification\n",
      "\tSuccessfully loaded task node-classification, with papers 529\n",
      "\n",
      "\tWorking on Graph-matching\n",
      "\tSuccessfully loaded task graph-matching, with papers 219\n",
      "\n",
      "\tWorking on Graph-clustering\n",
      "\tSuccessfully loaded task graph-clustering, with papers 160\n",
      "\n",
      "\tWorking on Role-embedding\n",
      "\tSuccessfully loaded task role-embedding, with papers 2\n",
      "\n",
      "\tWorking on Gene-interaction-prediction\n",
      "\tSuccessfully loaded task gene-interaction-prediction, with papers 1\n",
      "\n",
      "\tWorking on Heterogeneous-node-classification\n",
      "\tSuccessfully loaded task heterogeneous-node-classification, with papers 2\n",
      "\n",
      "\tWorking on Graph-construction\n",
      "\tSuccessfully loaded task graph-construction, with papers 140\n",
      "\n",
      "\tWorking on Online-community-detection\n",
      "\tSuccessfully loaded task online-community-detection, with papers 5\n",
      "\n",
      "\tWorking on Graph-sampling\n",
      "\tSuccessfully loaded task graph-sampling, with papers 27\n",
      "\n",
      "\tWorking on Md17\n",
      "\tSuccessfully loaded task md17, with papers 5\n",
      "\n",
      "\tWorking on Link-prediction\n",
      "\tSuccessfully loaded task link-prediction, with papers 565\n",
      "\n",
      "\tWorking on Triad-prediction\n",
      "\tSuccessfully loaded task triad-prediction, with papers 0\n",
      "\n",
      "\tWorking on Graph-to-graph-translation\n",
      "\tSuccessfully loaded task graph-to-graph-translation, with papers 4\n",
      "\n",
      "\tWorking on Hypergraph-partitioning\n",
      "\tSuccessfully loaded task hypergraph-partitioning, with papers 17\n",
      "\n",
      "\tWorking on Collaborative-ranking\n",
      "\tSuccessfully loaded task collaborative-ranking, with papers 21\n",
      "\n",
      "\tWorking on Knowledge-base-completion\n",
      "\tSuccessfully loaded task knowledge-base-completion, with papers 84\n",
      "\n",
      "\tWorking on Graph-generation\n",
      "\tSuccessfully loaded task graph-generation, with papers 134\n",
      "\n",
      "\tWorking on Learning-to-rank\n",
      "\tSuccessfully loaded task learning-to-rank, with papers 399\n",
      "\n",
      "\tWorking on Graph-ranking\n",
      "\tSuccessfully loaded task graph-ranking, with papers 6\n",
      "\n",
      "\tWorking on Community-detection\n",
      "\tSuccessfully loaded task community-detection, with papers 440\n",
      "\n",
      "\tWorking on Graph-partitioning\n",
      "\tSuccessfully loaded task graph-partitioning, with papers 82\n",
      "\n",
      "\tWorking on Nmr-j-coupling\n",
      "\tSuccessfully loaded task nmr-j-coupling, with papers 1\n",
      "\n",
      "\tWorking on Graph-reconstruction\n",
      "\tSuccessfully loaded task graph-reconstruction, with papers 13\n",
      "\n",
      "\tWorking on 3d-hand-pose-estimation\n",
      "\tSuccessfully loaded task 3d-hand-pose-estimation, with papers 67\n",
      "\n",
      "\tWorking on Spectral-graph-clustering\n",
      "\tSuccessfully loaded task spectral-graph-clustering, with papers 0\n",
      "\n",
      "\tWorking on Hypergraph-matching\n",
      "\tSuccessfully loaded task hypergraph-matching, with papers 6\n",
      "\n",
      "\tWorking on Dynamic-graph-embedding\n",
      "\tSuccessfully loaded task dynamic-graph-embedding, with papers 3\n",
      "\n",
      "\tWorking on Hyperedge-classification\n",
      "\tSuccessfully loaded task hyperedge-classification, with papers 1\n",
      "\n",
      "\tWorking on Graph-learning\n",
      "\tSuccessfully loaded task graph-learning, with papers 184\n",
      "\n",
      "\tWorking on Network-community-partition\n",
      "\tSuccessfully loaded task network-community-partition, with papers 0\n",
      "\n",
      "\tWorking on Graph-similarity\n",
      "\tSuccessfully loaded task graph-similarity, with papers 36\n",
      "\n",
      "\tWorking on Graph-classification\n",
      "\tSuccessfully loaded task graph-classification, with papers 215\n",
      "\n",
      "\tWorking on Anchor-link-prediction\n",
      "\tSuccessfully loaded task anchor-link-prediction, with papers 0\n",
      "\n",
      "\tWorking on Topological-data-analysis\n",
      "\tSuccessfully loaded task topological-data-analysis, with papers 154\n",
      "\n",
      "\tWorking on Calibration-for-link-prediction\n",
      "\tSuccessfully loaded task calibration-for-link-prediction, with papers 1\n",
      "\n",
      "\tWorking on Connectivity-estimation\n",
      "\tSuccessfully loaded task connectivity-estimation, with papers 7\n",
      "\n",
      "\tWorking on Graph-embedding\n",
      "\tSuccessfully loaded task graph-embedding, with papers 268\n",
      "\n",
      "\tWorking on Dynamic-link-prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task dynamic-link-prediction, with papers 0\n",
      "\n",
      "\tWorking on Graph-regression\n",
      "\tSuccessfully loaded task graph-regression, with papers 9\n",
      "\n",
      "\tWorking on Local-community-detection\n",
      "\tSuccessfully loaded task local-community-detection, with papers 0\n",
      "\n",
      "\tWorking on Link-sign-prediction\n",
      "\tSuccessfully loaded task link-sign-prediction, with papers 1\n",
      "\n",
      "\tWorking on Graph-question-answering\n",
      "\tSuccessfully loaded task graph-question-answering, with papers 3\n",
      "\n",
      "\tWorking on Graph-mining\n",
      "\tSuccessfully loaded task graph-mining, with papers 38\n",
      "\n",
      "\tWorking on Hypergraph-embedding\n",
      "\tSuccessfully loaded task hypergraph-embedding, with papers 1\n",
      "\n",
      "\tWorking on Knowledge-graph-embedding\n",
      "\tSuccessfully loaded task knowledge-graph-embedding, with papers 0\n",
      "\n",
      "--- Working on Knowledge-base ---\n",
      "\tWorking on Temporal-knowledge-graph-completion\n",
      "\tSuccessfully loaded task temporal-knowledge-graph-completion, with papers 5\n",
      "\n",
      "\tWorking on Open-knowledge-graph-embedding\n",
      "\tSuccessfully loaded task open-knowledge-graph-embedding, with papers 0\n",
      "\n",
      "\tWorking on Open-knowledge-graph-canonicalization\n",
      "\tSuccessfully loaded task open-knowledge-graph-canonicalization, with papers 1\n",
      "\n",
      "\tWorking on Breast-cancer-detection\n",
      "\tSuccessfully loaded task breast-cancer-detection, with papers 36\n",
      "\n",
      "\tWorking on Inductive-knowledge-graph-completion\n",
      "\tSuccessfully loaded task inductive-knowledge-graph-completion, with papers 3\n",
      "\n",
      "\tWorking on Knowledge-graphs-data-curation\n",
      "\tSuccessfully loaded task knowledge-graphs-data-curation, with papers 1\n",
      "\n",
      "\tWorking on Table-to-knowledge-graph-matching\n",
      "\tSuccessfully loaded task table-to-knowledge-graph-matching, with papers 0\n",
      "\n",
      "\tWorking on Causal-discovery\n",
      "\tSuccessfully loaded task causal-discovery, with papers 162\n",
      "\n",
      "\tWorking on Entity-alignment\n",
      "\tSuccessfully loaded task entity-alignment, with papers 42\n",
      "\n",
      "\tWorking on Knowledge-base\n",
      "\tSuccessfully loaded task knowledge-base, with papers 0\n",
      "\n",
      "\tWorking on Relational-pattern-learning\n",
      "\tSuccessfully loaded task relational-pattern-learning, with papers 0\n",
      "\n",
      "\tWorking on Knowledge-graph-completion\n",
      "\tSuccessfully loaded task knowledge-graph-completion, with papers 49\n",
      "\n",
      "\tWorking on Open-knowledge-base-completion\n",
      "\tSuccessfully loaded task open-knowledge-base-completion, with papers 0\n",
      "\n",
      "\tWorking on Multi-hop-question-answering\n",
      "\tSuccessfully loaded task multi-hop-question-answering, with papers 39\n",
      "\n",
      "\tWorking on Cross-lingual-sememe-prediction\n",
      "\tSuccessfully loaded task cross-lingual-sememe-prediction, with papers 1\n",
      "\n",
      "\tWorking on Knowledge-base-completion\n",
      "\tSuccessfully loaded task knowledge-base-completion, with papers 0\n",
      "\n",
      "\tWorking on Rdf-dataset-discovery\n",
      "\tSuccessfully loaded task rdf-dataset-discovery, with papers 2\n",
      "\n",
      "\tWorking on Knowledge-graphs\n",
      "\tSuccessfully loaded task knowledge-graphs, with papers 453\n",
      "\n",
      "\tWorking on Non-intrusive-load-monitoring\n",
      "\tSuccessfully loaded task non-intrusive-load-monitoring, with papers 32\n",
      "\n",
      "\tWorking on Research-knowledge-graph-population\n",
      "\tSuccessfully loaded task research-knowledge-graph-population, with papers 1\n",
      "\n",
      "\tWorking on Commonsense-knowledge-base-construction\n",
      "\tSuccessfully loaded task commonsense-knowledge-base-construction, with papers 1\n",
      "\n",
      "--- Working on Medical ---\n",
      "\tWorking on Atrial-fibrillation-recurrence-estimation\n",
      "\tSuccessfully loaded task atrial-fibrillation-recurrence-estimation, with papers 1\n",
      "\n",
      "\tWorking on Lung-nodule-classification\n",
      "\tSuccessfully loaded task lung-nodule-classification, with papers 20\n",
      "\n",
      "\tWorking on Mortality-prediction\n",
      "\tSuccessfully loaded task mortality-prediction, with papers 71\n",
      "\n",
      "\tWorking on Cell-segmentation\n",
      "\tSuccessfully loaded task cell-segmentation, with papers 61\n",
      "\n",
      "\tWorking on Molecule-interpretation\n",
      "\tSuccessfully loaded task molecule-interpretation, with papers 1\n",
      "\n",
      "\tWorking on Synthetic-data-generation\n",
      "\tSuccessfully loaded task synthetic-data-generation, with papers 83\n",
      "\n",
      "\tWorking on Cervical-cancer-biopsy-identification\n",
      "\tSuccessfully loaded task cervical-cancer-biopsy-identification, with papers 0\n",
      "\n",
      "\tWorking on Epilepsy-prediction\n",
      "\tSuccessfully loaded task epilepsy-prediction, with papers 2\n",
      "\n",
      "\tWorking on Organ-detection\n",
      "\tSuccessfully loaded task organ-detection, with papers 4\n",
      "\n",
      "\tWorking on Joint-vertebrae-identification-and\n",
      "\tSuccessfully loaded task joint-vertebrae-identification-and, with papers 1\n",
      "\n",
      "\tWorking on Brain-lesion-segmentation-from-mri\n",
      "\tSuccessfully loaded task brain-lesion-segmentation-from-mri, with papers 5\n",
      "\n",
      "\tWorking on Pneumonia-detection\n",
      "\tSuccessfully loaded task pneumonia-detection, with papers 16\n",
      "\n",
      "\tWorking on Diabetes-prediction\n",
      "\tSuccessfully loaded task diabetes-prediction, with papers 8\n",
      "\n",
      "\tWorking on Medial-knee-jrf-prediction\n",
      "\tSuccessfully loaded task medial-knee-jrf-prediction, with papers 1\n",
      "\n",
      "\tWorking on Heartbeat-classification\n",
      "\tSuccessfully loaded task heartbeat-classification, with papers 15\n",
      "\n",
      "\tWorking on Liver-segmentation\n",
      "\tSuccessfully loaded task liver-segmentation, with papers 46\n",
      "\n",
      "\tWorking on Motion-correction-in-multishot-mri\n",
      "\tSuccessfully loaded task motion-correction-in-multishot-mri, with papers 2\n",
      "\n",
      "\tWorking on Arrhythmia-detection\n",
      "\tSuccessfully loaded task arrhythmia-detection, with papers 26\n",
      "\n",
      "\tWorking on Pulse-wave-simulation\n",
      "\tSuccessfully loaded task pulse-wave-simulation, with papers 1\n",
      "\n",
      "\tWorking on Sequential-diagnosis\n",
      "\tSuccessfully loaded task sequential-diagnosis, with papers 9\n",
      "\n",
      "\tWorking on Participant-intervention-comparison-outcome\n",
      "\tSuccessfully loaded task participant-intervention-comparison-outcome, with papers 2\n",
      "\n",
      "\tWorking on Disease-trajectory-forecasting\n",
      "\tSuccessfully loaded task disease-trajectory-forecasting, with papers 3\n",
      "\n",
      "\tWorking on Automatic-sleep-stage-classification\n",
      "\tSuccessfully loaded task automatic-sleep-stage-classification, with papers 10\n",
      "\n",
      "\tWorking on Molecular-dynamics\n",
      "\tSuccessfully loaded task molecular-dynamics, with papers 0\n",
      "\n",
      "\tWorking on Low-dose-x-ray-ct-reconstruction\n",
      "\tSuccessfully loaded task low-dose-x-ray-ct-reconstruction, with papers 4\n",
      "\n",
      "\tWorking on White-matter-fiber-tractography\n",
      "\tSuccessfully loaded task white-matter-fiber-tractography, with papers 1\n",
      "\n",
      "\tWorking on Cerebrovascular-network-segmentation\n",
      "\tSuccessfully loaded task cerebrovascular-network-segmentation, with papers 1\n",
      "\n",
      "\tWorking on Muscular-movement-recognition\n",
      "\tSuccessfully loaded task muscular-movement-recognition, with papers 2\n",
      "\n",
      "\tWorking on Mapping-of-lung-nodules-in-low-dose-ct-images\n",
      "\tSuccessfully loaded task mapping-of-lung-nodules-in-low-dose-ct-images, with papers 0\n",
      "\n",
      "\tWorking on Sleep-quality-prediction-1\n",
      "\tSuccessfully loaded task sleep-quality-prediction-1, with papers 2\n",
      "\n",
      "\tWorking on Surgical-skills-evaluation\n",
      "\tSuccessfully loaded task surgical-skills-evaluation, with papers 2\n",
      "\n",
      "\tWorking on Outcome-prediction-in-multimodal-mri\n",
      "\tSuccessfully loaded task outcome-prediction-in-multimodal-mri, with papers 1\n",
      "\n",
      "\tWorking on Medical-image-generation\n",
      "\tSuccessfully loaded task medical-image-generation, with papers 15\n",
      "\n",
      "\tWorking on Automated-pancreas-segmentation\n",
      "\tSuccessfully loaded task automated-pancreas-segmentation, with papers 5\n",
      "\n",
      "\tWorking on Malaria-risk-exposure-prediction\n",
      "\tSuccessfully loaded task malaria-risk-exposure-prediction, with papers 2\n",
      "\n",
      "\tWorking on Medical-super-resolution\n",
      "\tSuccessfully loaded task medical-super-resolution, with papers 1\n",
      "\n",
      "\tWorking on Nuclear-segmentation\n",
      "\tSuccessfully loaded task nuclear-segmentation, with papers 14\n",
      "\n",
      "\tWorking on Breast-cancer-detection\n",
      "\tSuccessfully loaded task breast-cancer-detection, with papers 0\n",
      "\n",
      "\tWorking on Lung-cancer-diagnosis\n",
      "\tSuccessfully loaded task lung-cancer-diagnosis, with papers 17\n",
      "\n",
      "\tWorking on Mass-segmentation-from-mammograms\n",
      "\tSuccessfully loaded task mass-segmentation-from-mammograms, with papers 2\n",
      "\n",
      "\tWorking on Photoplethysmogram-simulation\n",
      "\tSuccessfully loaded task photoplethysmogram-simulation, with papers 0\n",
      "\n",
      "\tWorking on Pulmonary-embolism-detection\n",
      "\tSuccessfully loaded task pulmonary-embolism-detection, with papers 1\n",
      "\n",
      "\tWorking on Spindle-detection\n",
      "\tSuccessfully loaded task spindle-detection, with papers 5\n",
      "\n",
      "\tWorking on Registration-of-sparse-clinical-images\n",
      "\tSuccessfully loaded task registration-of-sparse-clinical-images, with papers 1\n",
      "\n",
      "\tWorking on Oral-cancer-classification\n",
      "\tSuccessfully loaded task oral-cancer-classification, with papers 2\n",
      "\n",
      "\tWorking on Lesion-segmentation\n",
      "\tSuccessfully loaded task lesion-segmentation, with papers 224\n",
      "\n",
      "\tWorking on Diabetic-retinopathy-grading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task diabetic-retinopathy-grading, with papers 13\n",
      "\n",
      "\tWorking on Colon-cancer-detection-in-confocal-laser\n",
      "\tSuccessfully loaded task colon-cancer-detection-in-confocal-laser, with papers 1\n",
      "\n",
      "\tWorking on Sleep-micro-event-detection\n",
      "\tSuccessfully loaded task sleep-micro-event-detection, with papers 1\n",
      "\n",
      "\tWorking on Readmission-prediction\n",
      "\tSuccessfully loaded task readmission-prediction, with papers 10\n",
      "\n",
      "--- Working on Methodology ---\n",
      "\tWorking on Probabilistic-programming\n",
      "\tSuccessfully loaded task probabilistic-programming, with papers 161\n",
      "\n",
      "\tWorking on Efficient-exploration\n",
      "\tSuccessfully loaded task efficient-exploration, with papers 179\n",
      "\n",
      "\tWorking on Continual-learning\n",
      "\tSuccessfully loaded task continual-learning, with papers 452\n",
      "\n",
      "\tWorking on Network-embedding\n",
      "\tSuccessfully loaded task network-embedding, with papers 125\n",
      "\n",
      "\tWorking on Point-processes\n",
      "\tSuccessfully loaded task point-processes, with papers 280\n",
      "\n",
      "\tWorking on Model-selection\n",
      "\tSuccessfully loaded task model-selection, with papers 798\n",
      "\n",
      "\tWorking on Dimensionality-reduction\n",
      "\tSuccessfully loaded task dimensionality-reduction, with papers 1249\n",
      "\n",
      "\tWorking on Automl\n",
      "\tSuccessfully loaded task automl, with papers 183\n",
      "\n",
      "\tWorking on Unsupervised-representation-learning\n",
      "\tSuccessfully loaded task unsupervised-representation-learning, with papers 177\n",
      "\n",
      "\tWorking on Representation-learning\n",
      "\tSuccessfully loaded task representation-learning, with papers 1920\n",
      "\n",
      "\tWorking on Sentence-embeddings-for-biomedical-texts\n",
      "\tSuccessfully loaded task sentence-embeddings-for-biomedical-texts, with papers 2\n",
      "\n",
      "\tWorking on Outlier-ensembles\n",
      "\tSuccessfully loaded task outlier-ensembles, with papers 6\n",
      "\n",
      "\tWorking on Multi-goal-reinforcement-learning\n",
      "\tSuccessfully loaded task multi-goal-reinforcement-learning, with papers 14\n",
      "\n",
      "\tWorking on Quantum-circuit-equivalence-checking\n",
      "\tSuccessfully loaded task quantum-circuit-equivalence-checking, with papers 2\n",
      "\n",
      "\tWorking on Matrix-completion\n",
      "\tSuccessfully loaded task matrix-completion, with papers 480\n",
      "\n",
      "\tWorking on Generalization-bounds\n",
      "\tSuccessfully loaded task generalization-bounds, with papers 267\n",
      "\n",
      "\tWorking on Learning-word-embeddings\n",
      "\tSuccessfully loaded task learning-word-embeddings, with papers 64\n",
      "\n",
      "\tWorking on Hyperparameter-optimization\n",
      "\tSuccessfully loaded task hyperparameter-optimization, with papers 221\n",
      "\n",
      "\tWorking on Normalising-flows\n",
      "\tSuccessfully loaded task normalising-flows, with papers 14\n",
      "\n",
      "\tWorking on Gaussian-processes\n",
      "\tSuccessfully loaded task gaussian-processes, with papers 896\n",
      "\n",
      "\tWorking on Abnormal-event-detection-in-video\n",
      "\tSuccessfully loaded task abnormal-event-detection-in-video, with papers 11\n",
      "\n",
      "\tWorking on Few-shot-imitation-learning\n",
      "\tSuccessfully loaded task few-shot-imitation-learning, with papers 2\n",
      "\n",
      "\tWorking on Quantum-machine-learning\n",
      "\tSuccessfully loaded task quantum-machine-learning, with papers 118\n",
      "\n",
      "\tWorking on Outlier-detection\n",
      "\tSuccessfully loaded task outlier-detection, with papers 278\n",
      "\n",
      "\tWorking on Anomaly-detection\n",
      "\tSuccessfully loaded task anomaly-detection, with papers 1084\n",
      "\n",
      "\tWorking on Multi-task-learning\n",
      "\tSuccessfully loaded task multi-task-learning, with papers 1134\n",
      "\n",
      "\tWorking on Multi-label-learning\n",
      "\tSuccessfully loaded task multi-label-learning, with papers 146\n",
      "\n",
      "\tWorking on Learning-semantic-representations\n",
      "\tSuccessfully loaded task learning-semantic-representations, with papers 19\n",
      "\n",
      "\tWorking on L2-regularization\n",
      "\tSuccessfully loaded task l2-regularization, with papers 60\n",
      "\n",
      "\tWorking on Partial-domain-adaptation\n",
      "\tSuccessfully loaded task partial-domain-adaptation, with papers 25\n",
      "\n",
      "\tWorking on Feature-importance\n",
      "\tSuccessfully loaded task feature-importance, with papers 200\n",
      "\n",
      "\tWorking on Model-extraction\n",
      "\tSuccessfully loaded task model-extraction, with papers 37\n",
      "\n",
      "\tWorking on One-shot-learning\n",
      "\tSuccessfully loaded task one-shot-learning, with papers 143\n",
      "\n",
      "\tWorking on Document-embedding\n",
      "\tSuccessfully loaded task document-embedding, with papers 33\n",
      "\n",
      "\tWorking on Data-augmentation\n",
      "\tSuccessfully loaded task data-augmentation, with papers 1539\n",
      "\n",
      "\tWorking on Word-embeddings\n",
      "\tSuccessfully loaded task word-embeddings, with papers 1519\n",
      "\n",
      "\tWorking on Information-plane\n",
      "\tSuccessfully loaded task information-plane, with papers 13\n",
      "\n",
      "\tWorking on Metric-learning\n",
      "\tSuccessfully loaded task metric-learning, with papers 711\n",
      "\n",
      "\tWorking on Global-optimization\n",
      "\tSuccessfully loaded task global-optimization, with papers 282\n",
      "\n",
      "\tWorking on Policy-gradient-methods\n",
      "\tSuccessfully loaded task policy-gradient-methods, with papers 166\n",
      "\n",
      "\tWorking on Structured-prediction\n",
      "\tSuccessfully loaded task structured-prediction, with papers 430\n",
      "\n",
      "\tWorking on Arbitrary-conditional-density-estimation\n",
      "\tSuccessfully loaded task arbitrary-conditional-density-estimation, with papers 1\n",
      "\n",
      "\tWorking on Few-shot-camera-adaptive-color-constancy\n",
      "\tSuccessfully loaded task few-shot-camera-adaptive-color-constancy, with papers 1\n",
      "\n",
      "\tWorking on Few-shot-regression\n",
      "\tSuccessfully loaded task few-shot-regression, with papers 10\n",
      "\n",
      "\tWorking on Federated-learning\n",
      "\tSuccessfully loaded task federated-learning, with papers 0\n",
      "\n",
      "\tWorking on Bayesian-inference\n",
      "\tSuccessfully loaded task bayesian-inference, with papers 824\n",
      "\n",
      "\tWorking on Electrocardiography-ecg\n",
      "\tSuccessfully loaded task electrocardiography-ecg, with papers 29\n",
      "\n",
      "\tWorking on Privacy-preserving-deep-learning\n",
      "\tSuccessfully loaded task privacy-preserving-deep-learning, with papers 16\n",
      "\n",
      "\tWorking on Auxiliary-learning\n",
      "\tSuccessfully loaded task auxiliary-learning, with papers 16\n",
      "\n",
      "\tWorking on Few-shot-image-classification\n",
      "\tSuccessfully loaded task few-shot-image-classification, with papers 42\n",
      "\n",
      "--- Working on Miscellaneous ---\n",
      "\tWorking on Malware-detection\n",
      "\tSuccessfully loaded task malware-detection, with papers 157\n",
      "\n",
      "\tWorking on Remote-sensing\n",
      "\tSuccessfully loaded task remote-sensing, with papers 0\n",
      "\n",
      "\tWorking on Continual-learning\n",
      "\tSuccessfully loaded task continual-learning, with papers 0\n",
      "\n",
      "\tWorking on Click-through-rate-prediction\n",
      "\tSuccessfully loaded task click-through-rate-prediction, with papers 90\n",
      "\n",
      "\tWorking on Making-hiring-decisions\n",
      "\tSuccessfully loaded task making-hiring-decisions, with papers 0\n",
      "\n",
      "\tWorking on Food-recommendation\n",
      "\tSuccessfully loaded task food-recommendation, with papers 8\n",
      "\n",
      "\tWorking on Deception-detection-in-videos\n",
      "\tSuccessfully loaded task deception-detection-in-videos, with papers 0\n",
      "\n",
      "\tWorking on Synthetic-data-generation\n",
      "\tSuccessfully loaded task synthetic-data-generation, with papers 0\n",
      "\n",
      "\tWorking on Fault-detection\n",
      "\tSuccessfully loaded task fault-detection, with papers 91\n",
      "\n",
      "\tWorking on Classification-with-costly-features\n",
      "\tSuccessfully loaded task classification-with-costly-features, with papers 2\n",
      "\n",
      "\tWorking on Cross-modal-retrieval\n",
      "\tSuccessfully loaded task cross-modal-retrieval, with papers 132\n",
      "\n",
      "\tWorking on Business-taxonomy-construction\n",
      "\tSuccessfully loaded task business-taxonomy-construction, with papers 1\n",
      "\n",
      "\tWorking on Social-media-popularity-prediction\n",
      "\tSuccessfully loaded task social-media-popularity-prediction, with papers 0\n",
      "\n",
      "\tWorking on Vulnerability-detection\n",
      "\tSuccessfully loaded task vulnerability-detection, with papers 20\n",
      "\n",
      "\tWorking on Trajectory-prediction\n",
      "\tSuccessfully loaded task trajectory-prediction, with papers 262\n",
      "\n",
      "\tWorking on Session-based-recommendations\n",
      "\tSuccessfully loaded task session-based-recommendations, with papers 54\n",
      "\n",
      "\tWorking on Twitter-bot-detection\n",
      "\tSuccessfully loaded task twitter-bot-detection, with papers 7\n",
      "\n",
      "\tWorking on Load-forecasting\n",
      "\tSuccessfully loaded task load-forecasting, with papers 53\n",
      "\n",
      "\tWorking on Air-pollution-prediction\n",
      "\tSuccessfully loaded task air-pollution-prediction, with papers 4\n",
      "\n",
      "\tWorking on Artificial-life\n",
      "\tSuccessfully loaded task artificial-life, with papers 53\n",
      "\n",
      "\tWorking on Imbalanced-classification\n",
      "\tSuccessfully loaded task imbalanced-classification, with papers 52\n",
      "\n",
      "\tWorking on Deep-clustering\n",
      "\tSuccessfully loaded task deep-clustering, with papers 80\n",
      "\n",
      "\tWorking on Automated-theorem-proving\n",
      "\tSuccessfully loaded task automated-theorem-proving, with papers 107\n",
      "\n",
      "\tWorking on Problem-decomposition\n",
      "\tSuccessfully loaded task problem-decomposition, with papers 10\n",
      "\n",
      "\tWorking on Android-malware-detection\n",
      "\tSuccessfully loaded task android-malware-detection, with papers 0\n",
      "\n",
      "\tWorking on Data-visualization\n",
      "\tSuccessfully loaded task data-visualization, with papers 83\n",
      "\n",
      "\tWorking on Sequential-correlation-estimation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task sequential-correlation-estimation, with papers 2\n",
      "\n",
      "\tWorking on Seismic-interpretation\n",
      "\tSuccessfully loaded task seismic-interpretation, with papers 12\n",
      "\n",
      "\tWorking on Oceanic-eddy-classification\n",
      "\tSuccessfully loaded task oceanic-eddy-classification, with papers 1\n",
      "\n",
      "\tWorking on Mobile-security\n",
      "\tSuccessfully loaded task mobile-security, with papers 4\n",
      "\n",
      "\tWorking on Multi-modal-person-identification\n",
      "\tSuccessfully loaded task multi-modal-person-identification, with papers 2\n",
      "\n",
      "\tWorking on Self-organized-clustering\n",
      "\tSuccessfully loaded task self-organized-clustering, with papers 1\n",
      "\n",
      "\tWorking on Recipe-generation\n",
      "\tSuccessfully loaded task recipe-generation, with papers 10\n",
      "\n",
      "\tWorking on Traffic-classification\n",
      "\tSuccessfully loaded task traffic-classification, with papers 20\n",
      "\n",
      "\tWorking on Md17\n",
      "\tSuccessfully loaded task md17, with papers 0\n",
      "\n",
      "\tWorking on Gravitational-wave-detection\n",
      "\tSuccessfully loaded task gravitational-wave-detection, with papers 9\n",
      "\n",
      "\tWorking on Multi-modal\n",
      "\tSuccessfully loaded task multi-modal, with papers 7\n",
      "\n",
      "\tWorking on Jsoniq-query-execution\n",
      "\tSuccessfully loaded task jsoniq-query-execution, with papers 1\n",
      "\n",
      "\tWorking on Numerical-integration\n",
      "\tSuccessfully loaded task numerical-integration, with papers 62\n",
      "\n",
      "\tWorking on Gender-bias-detection\n",
      "\tSuccessfully loaded task gender-bias-detection, with papers 2\n",
      "\n",
      "\tWorking on Product-categorization\n",
      "\tSuccessfully loaded task product-categorization, with papers 14\n",
      "\n",
      "\tWorking on Radio-interferometry\n",
      "\tSuccessfully loaded task radio-interferometry, with papers 7\n",
      "\n",
      "\tWorking on Multi-armed-bandits\n",
      "\tSuccessfully loaded task multi-armed-bandits, with papers 469\n",
      "\n",
      "\tWorking on Crop-classification\n",
      "\tSuccessfully loaded task crop-classification, with papers 11\n",
      "\n",
      "\tWorking on Time-offset-calibration\n",
      "\tSuccessfully loaded task time-offset-calibration, with papers 1\n",
      "\n",
      "\tWorking on Lake-ice-detection\n",
      "\tSuccessfully loaded task lake-ice-detection, with papers 1\n",
      "\n",
      "\tWorking on Data-summarization\n",
      "\tSuccessfully loaded task data-summarization, with papers 53\n",
      "\n",
      "\tWorking on Behavioral-malware-detection\n",
      "\tSuccessfully loaded task behavioral-malware-detection, with papers 0\n",
      "\n",
      "\tWorking on Air-quality-inference\n",
      "\tSuccessfully loaded task air-quality-inference, with papers 1\n",
      "\n",
      "\tWorking on Sequential-distribution-function-estimation\n",
      "\tSuccessfully loaded task sequential-distribution-function-estimation, with papers 0\n",
      "\n",
      "--- Working on Music ---\n",
      "\tWorking on Cover-song-identification\n",
      "\tSuccessfully loaded task cover-song-identification, with papers 8\n",
      "\n",
      "\tWorking on Music-emotion-recognition\n",
      "\tSuccessfully loaded task music-emotion-recognition, with papers 11\n",
      "\n",
      "\tWorking on Music-generation\n",
      "\tSuccessfully loaded task music-generation, with papers 0\n",
      "\n",
      "\tWorking on Recognizing-seven-different-dastgahs-of\n",
      "\tSuccessfully loaded task recognizing-seven-different-dastgahs-of, with papers 1\n",
      "\n",
      "\tWorking on Music-classification\n",
      "\tSuccessfully loaded task music-classification, with papers 17\n",
      "\n",
      "\tWorking on Music-auto-tagging\n",
      "\tSuccessfully loaded task music-auto-tagging, with papers 5\n",
      "\n",
      "\tWorking on Piano-music-modeling\n",
      "\tSuccessfully loaded task piano-music-modeling, with papers 1\n",
      "\n",
      "\tWorking on Music-texture-transfer\n",
      "\tSuccessfully loaded task music-texture-transfer, with papers 1\n",
      "\n",
      "\tWorking on Music-genre-recognition\n",
      "\tSuccessfully loaded task music-genre-recognition, with papers 5\n",
      "\n",
      "\tWorking on Drum-transcription\n",
      "\tSuccessfully loaded task drum-transcription, with papers 3\n",
      "\n",
      "\tWorking on Detection-of-instrumentals-musical-tracks\n",
      "\tSuccessfully loaded task detection-of-instrumentals-musical-tracks, with papers 0\n",
      "\n",
      "\tWorking on Music-source-separation\n",
      "\tSuccessfully loaded task music-source-separation, with papers 29\n",
      "\n",
      "\tWorking on Music-transcription\n",
      "\tSuccessfully loaded task music-transcription, with papers 27\n",
      "\n",
      "\tWorking on Melody-extraction\n",
      "\tSuccessfully loaded task melody-extraction, with papers 1\n",
      "\n",
      "\tWorking on Music-information-retrieval\n",
      "\tSuccessfully loaded task music-information-retrieval, with papers 64\n",
      "\n",
      "\tWorking on Music-modeling\n",
      "\tSuccessfully loaded task music-modeling, with papers 15\n",
      "\n",
      "--- Working on Natural-language-processing ---\n",
      "\tWorking on Aggression-identification\n",
      "\tSuccessfully loaded task aggression-identification, with papers 19\n",
      "\n",
      "\tWorking on Reading-comprehension\n",
      "\tSuccessfully loaded task reading-comprehension, with papers 843\n",
      "\n",
      "\tWorking on Hope-speech-detection\n",
      "\tSuccessfully loaded task hope-speech-detection, with papers 5\n",
      "\n",
      "\tWorking on Bridging-anaphora-resolution\n",
      "\tSuccessfully loaded task bridging-anaphora-resolution, with papers 6\n",
      "\n",
      "\tWorking on Story-completion\n",
      "\tSuccessfully loaded task story-completion, with papers 4\n",
      "\n",
      "\tWorking on Query-wellformedness\n",
      "\tSuccessfully loaded task query-wellformedness, with papers 1\n",
      "\n",
      "\tWorking on Csc\n",
      "\tSuccessfully loaded task csc, with papers 2\n",
      "\n",
      "\tWorking on Conditional-text-generation\n",
      "\tSuccessfully loaded task conditional-text-generation, with papers 23\n",
      "\n",
      "\tWorking on Transition-based-dependency-parsing\n",
      "\tSuccessfully loaded task transition-based-dependency-parsing, with papers 58\n",
      "\n",
      "\tWorking on Data-to-text-generation\n",
      "\tSuccessfully loaded task data-to-text-generation, with papers 94\n",
      "\n",
      "\tWorking on Open-information-extraction\n",
      "\tSuccessfully loaded task open-information-extraction, with papers 110\n",
      "\n",
      "\tWorking on Implicit-discourse-relation-classification\n",
      "\tSuccessfully loaded task implicit-discourse-relation-classification, with papers 21\n",
      "\n",
      "\tWorking on Text-augmentation\n",
      "\tSuccessfully loaded task text-augmentation, with papers 9\n",
      "\n",
      "\tWorking on Selection-bias\n",
      "\tSuccessfully loaded task selection-bias, with papers 91\n",
      "\n",
      "\tWorking on Decipherment\n",
      "\tSuccessfully loaded task decipherment, with papers 28\n",
      "\n",
      "\tWorking on Sentence-classification\n",
      "\tSuccessfully loaded task sentence-classification, with papers 130\n",
      "\n",
      "\tWorking on Sentence-embeddings-for-biomedical-texts\n",
      "\tSuccessfully loaded task sentence-embeddings-for-biomedical-texts, with papers 0\n",
      "\n",
      "\tWorking on Hope-speech-detection-for-malayalam\n",
      "\tSuccessfully loaded task hope-speech-detection-for-malayalam, with papers 0\n",
      "\n",
      "\tWorking on Low-resource-named-entity-recognition\n",
      "\tSuccessfully loaded task low-resource-named-entity-recognition, with papers 17\n",
      "\n",
      "\tWorking on Abstract-argumentation\n",
      "\tSuccessfully loaded task abstract-argumentation, with papers 85\n",
      "\n",
      "\tWorking on Sentence-ordering\n",
      "\tSuccessfully loaded task sentence-ordering, with papers 25\n",
      "\n",
      "\tWorking on Propaganda-span-identification\n",
      "\tSuccessfully loaded task propaganda-span-identification, with papers 3\n",
      "\n",
      "\tWorking on Hypernym-discovery\n",
      "\tSuccessfully loaded task hypernym-discovery, with papers 22\n",
      "\n",
      "\tWorking on Arabic-sentiment-analysis\n",
      "\tSuccessfully loaded task arabic-sentiment-analysis, with papers 30\n",
      "\n",
      "\tWorking on Task-completion-dialogue-policy-learning\n",
      "\tSuccessfully loaded task task-completion-dialogue-policy-learning, with papers 6\n",
      "\n",
      "\tWorking on Text-matching\n",
      "\tSuccessfully loaded task text-matching, with papers 86\n",
      "\n",
      "\tWorking on Rumour-detection\n",
      "\tSuccessfully loaded task rumour-detection, with papers 49\n",
      "\n",
      "\tWorking on Semi-supervised-text-classification-1\n",
      "\tSuccessfully loaded task semi-supervised-text-classification-1, with papers 9\n",
      "\n",
      "\tWorking on Language-modelling\n",
      "\tSuccessfully loaded task language-modelling, with papers 1844\n",
      "\n",
      "\tWorking on Multimodal-sentiment-analysis\n",
      "\tSuccessfully loaded task multimodal-sentiment-analysis, with papers 35\n",
      "\n",
      "\tWorking on Clinical-language-translation\n",
      "\tSuccessfully loaded task clinical-language-translation, with papers 1\n",
      "\n",
      "\tWorking on Unsupervised-kg-to-text\n",
      "\tSuccessfully loaded task unsupervised-kg-to-text, with papers 1\n",
      "\n",
      "\tWorking on Part-of-speech-tagging\n",
      "\tSuccessfully loaded task part-of-speech-tagging, with papers 495\n",
      "\n",
      "\tWorking on Causal-emotion-entailment\n",
      "\tSuccessfully loaded task causal-emotion-entailment, with papers 1\n",
      "\n",
      "\tWorking on Relation-extraction\n",
      "\tSuccessfully loaded task relation-extraction, with papers 299\n",
      "\n",
      "\tWorking on Tokenization\n",
      "\tSuccessfully loaded task tokenization, with papers 259\n",
      "\n",
      "\tWorking on Morphological-inflection\n",
      "\tSuccessfully loaded task morphological-inflection, with papers 78\n",
      "\n",
      "\tWorking on Medical-named-entity-recognition\n",
      "\tSuccessfully loaded task medical-named-entity-recognition, with papers 6\n",
      "\n",
      "\tWorking on Recognizing-emotion-cause-in-conversations\n",
      "\tSuccessfully loaded task recognizing-emotion-cause-in-conversations, with papers 0\n",
      "\n",
      "\tWorking on Named-entity-recognition-ner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task named-entity-recognition-ner, with papers 886\n",
      "\n",
      "\tWorking on Text-generation\n",
      "\tSuccessfully loaded task text-generation, with papers 1153\n",
      "\n",
      "\tWorking on Turning-point-identification\n",
      "\tSuccessfully loaded task turning-point-identification, with papers 2\n",
      "\n",
      "\tWorking on Chinese-word-segmentation\n",
      "\tSuccessfully loaded task chinese-word-segmentation, with papers 143\n",
      "\n",
      "\tWorking on Task-oriented-dialogue-systems\n",
      "\tSuccessfully loaded task task-oriented-dialogue-systems, with papers 93\n",
      "\n",
      "\tWorking on Machine-reading-comprehension\n",
      "\tSuccessfully loaded task machine-reading-comprehension, with papers 2\n",
      "\n",
      "\tWorking on Definition-extraction\n",
      "\tSuccessfully loaded task definition-extraction, with papers 7\n",
      "\n",
      "\tWorking on Extracting-covid-19-events-from-twitter\n",
      "\tSuccessfully loaded task extracting-covid-19-events-from-twitter, with papers 2\n",
      "\n",
      "\tWorking on Polyphone-disambiguation\n",
      "\tSuccessfully loaded task polyphone-disambiguation, with papers 5\n",
      "\n",
      "\tWorking on Taxonomy-learning\n",
      "\tSuccessfully loaded task taxonomy-learning, with papers 0\n",
      "\n",
      "\tWorking on Document-summarization\n",
      "\tSuccessfully loaded task document-summarization, with papers 0\n",
      "\n",
      "--- Working on Playing-games ---\n",
      "\tWorking on Dota-2\n",
      "\tSuccessfully loaded task dota-2, with papers 14\n",
      "\n",
      "\tWorking on Board-games\n",
      "\tSuccessfully loaded task board-games, with papers 56\n",
      "\n",
      "\tWorking on Acrobot\n",
      "\tSuccessfully loaded task acrobot, with papers 9\n",
      "\n",
      "\tWorking on Real-time-strategy-games\n",
      "\tSuccessfully loaded task real-time-strategy-games, with papers 31\n",
      "\n",
      "\tWorking on Game-of-chess\n",
      "\tSuccessfully loaded task game-of-chess, with papers 13\n",
      "\n",
      "\tWorking on Game-of-doom\n",
      "\tSuccessfully loaded task game-of-doom, with papers 5\n",
      "\n",
      "\tWorking on Injury-prediction\n",
      "\tSuccessfully loaded task injury-prediction, with papers 5\n",
      "\n",
      "\tWorking on Text-based-games\n",
      "\tSuccessfully loaded task text-based-games, with papers 18\n",
      "\n",
      "\tWorking on Game-of-shogi\n",
      "\tSuccessfully loaded task game-of-shogi, with papers 0\n",
      "\n",
      "\tWorking on Snes-games\n",
      "\tSuccessfully loaded task snes-games, with papers 4\n",
      "\n",
      "\tWorking on Starcraft-ii\n",
      "\tSuccessfully loaded task starcraft-ii, with papers 52\n",
      "\n",
      "\tWorking on League-of-legends\n",
      "\tSuccessfully loaded task league-of-legends, with papers 13\n",
      "\n",
      "\tWorking on Continuous-control\n",
      "\tSuccessfully loaded task continuous-control, with papers 411\n",
      "\n",
      "\tWorking on Atari-games\n",
      "\tSuccessfully loaded task atari-games, with papers 271\n",
      "\n",
      "\tWorking on Dqn-replay-dataset\n",
      "\tSuccessfully loaded task dqn-replay-dataset, with papers 2\n",
      "\n",
      "\tWorking on Multi-agent-path-finding\n",
      "\tSuccessfully loaded task multi-agent-path-finding, with papers 45\n",
      "\n",
      "\tWorking on Klondike\n",
      "\tSuccessfully loaded task klondike, with papers 1\n",
      "\n",
      "\tWorking on Offline-rl\n",
      "\tSuccessfully loaded task offline-rl, with papers 36\n",
      "\n",
      "\tWorking on Football-action-valuation\n",
      "\tSuccessfully loaded task football-action-valuation, with papers 2\n",
      "\n",
      "\tWorking on Minecraft\n",
      "\tSuccessfully loaded task minecraft, with papers 54\n",
      "\n",
      "\tWorking on Openai-gym\n",
      "\tSuccessfully loaded task openai-gym, with papers 122\n",
      "\n",
      "\tWorking on Card-games\n",
      "\tSuccessfully loaded task card-games, with papers 16\n",
      "\n",
      "\tWorking on Pass-classification\n",
      "\tSuccessfully loaded task pass-classification, with papers 1\n",
      "\n",
      "\tWorking on Video-games\n",
      "\tSuccessfully loaded task video-games, with papers 0\n",
      "\n",
      "\tWorking on Game-of-hanabi\n",
      "\tSuccessfully loaded task game-of-hanabi, with papers 3\n",
      "\n",
      "\tWorking on Fps-games\n",
      "\tSuccessfully loaded task fps-games, with papers 4\n",
      "\n",
      "\tWorking on Montezumas-revenge\n",
      "\tSuccessfully loaded task montezumas-revenge, with papers 16\n",
      "\n",
      "\tWorking on Suduko\n",
      "\tSuccessfully loaded task suduko, with papers 1\n",
      "\n",
      "\tWorking on Nethack\n",
      "\tSuccessfully loaded task nethack, with papers 2\n",
      "\n",
      "\tWorking on Game-of-cricket\n",
      "\tSuccessfully loaded task game-of-cricket, with papers 4\n",
      "\n",
      "\tWorking on Starcraft\n",
      "\tSuccessfully loaded task starcraft, with papers 44\n",
      "\n",
      "\tWorking on Smac\n",
      "\tSuccessfully loaded task smac, with papers 14\n",
      "\n",
      "\tWorking on Game-of-poker\n",
      "\tSuccessfully loaded task game-of-poker, with papers 2\n",
      "\n",
      "\tWorking on Score\n",
      "\tSuccessfully loaded task score, with papers 0\n",
      "\n",
      "\tWorking on Game-of-go\n",
      "\tSuccessfully loaded task game-of-go, with papers 29\n",
      "\n",
      "\tWorking on Solitaire\n",
      "\tSuccessfully loaded task solitaire, with papers 2\n",
      "\n",
      "\tWorking on Carracing-v0\n",
      "\tSuccessfully loaded task carracing-v0, with papers 19\n",
      "\n",
      "\tWorking on Game-of-football\n",
      "\tSuccessfully loaded task game-of-football, with papers 6\n",
      "\n",
      "--- Working on Reasoning ---\n",
      "\tWorking on Model-based-reinforcement-learning\n",
      "\tSuccessfully loaded task model-based-reinforcement-learning, with papers 200\n",
      "\n",
      "\tWorking on Program-repair\n",
      "\tSuccessfully loaded task program-repair, with papers 0\n",
      "\n",
      "\tWorking on Common-sense-reasoning\n",
      "\tSuccessfully loaded task common-sense-reasoning, with papers 245\n",
      "\n",
      "\tWorking on Visual-commonsense-reasoning\n",
      "\tSuccessfully loaded task visual-commonsense-reasoning, with papers 12\n",
      "\n",
      "\tWorking on Decision-making-under-uncertainty\n",
      "\tSuccessfully loaded task decision-making-under-uncertainty, with papers 77\n",
      "\n",
      "\tWorking on Visual-reasoning\n",
      "\tSuccessfully loaded task visual-reasoning, with papers 105\n",
      "\n",
      "\tWorking on Temporal-logic\n",
      "\tSuccessfully loaded task temporal-logic, with papers 165\n",
      "\n",
      "\tWorking on Pre-election-ratings-estimation\n",
      "\tSuccessfully loaded task pre-election-ratings-estimation, with papers 1\n",
      "\n",
      "\tWorking on Natural-language-visual-grounding\n",
      "\tSuccessfully loaded task natural-language-visual-grounding, with papers 8\n",
      "\n",
      "\tWorking on Abstract-argumentation\n",
      "\tSuccessfully loaded task abstract-argumentation, with papers 0\n",
      "\n",
      "\tWorking on Causal-identification\n",
      "\tSuccessfully loaded task causal-identification, with papers 10\n",
      "\n",
      "\tWorking on Commonsense-rl\n",
      "\tSuccessfully loaded task commonsense-rl, with papers 0\n",
      "\n",
      "\tWorking on Decision-making\n",
      "\tSuccessfully loaded task decision-making, with papers 2486\n",
      "\n",
      "\tWorking on Math-word-problem-solving\n",
      "\tSuccessfully loaded task math-word-problem-solving, with papers 18\n",
      "\n",
      "\tWorking on Systematic-generalization\n",
      "\tSuccessfully loaded task systematic-generalization, with papers 24\n",
      "\n",
      "--- Working on Robots ---\n",
      "\tWorking on Deformable-object-manipulation\n",
      "\tSuccessfully loaded task deformable-object-manipulation, with papers 7\n",
      "\n",
      "\tWorking on Robot-task-planning\n",
      "\tSuccessfully loaded task robot-task-planning, with papers 6\n",
      "\n",
      "\tWorking on Motion-planning\n",
      "\tSuccessfully loaded task motion-planning, with papers 246\n",
      "\n",
      "\tWorking on Optimal-motion-planning\n",
      "\tSuccessfully loaded task optimal-motion-planning, with papers 0\n",
      "\n",
      "\tWorking on Visual-navigation\n",
      "\tSuccessfully loaded task visual-navigation, with papers 86\n",
      "\n",
      "\tWorking on Robotic-grasping\n",
      "\tSuccessfully loaded task robotic-grasping, with papers 75\n",
      "\n",
      "\tWorking on Sequential-place-recognition\n",
      "\tSuccessfully loaded task sequential-place-recognition, with papers 1\n",
      "\n",
      "\tWorking on Vision-and-language-navigation\n",
      "\tSuccessfully loaded task vision-and-language-navigation, with papers 34\n",
      "\n",
      "\tWorking on Human-robot-interaction\n",
      "\tSuccessfully loaded task human-robot-interaction, with papers 203\n",
      "\n",
      "\tWorking on Visual-odometry\n",
      "\tSuccessfully loaded task visual-odometry, with papers 152\n",
      "\n",
      "\tWorking on Safe-exploration\n",
      "\tSuccessfully loaded task safe-exploration, with papers 27\n",
      "\n",
      "\tWorking on Developmental-learning\n",
      "\tSuccessfully loaded task developmental-learning, with papers 4\n",
      "\n",
      "\tWorking on Pointgoal-navigation\n",
      "\tSuccessfully loaded task pointgoal-navigation, with papers 8\n",
      "\n",
      "\tWorking on Marine-robot-navigation\n",
      "\tSuccessfully loaded task marine-robot-navigation, with papers 1\n",
      "\n",
      "\tWorking on Trajectory-planning\n",
      "\tSuccessfully loaded task trajectory-planning, with papers 52\n",
      "\n",
      "\tWorking on Sequential-place-learning\n",
      "\tSuccessfully loaded task sequential-place-learning, with papers 0\n",
      "\n",
      "\tWorking on Industrial-robots\n",
      "\tSuccessfully loaded task industrial-robots, with papers 9\n",
      "\n",
      "\tWorking on Monocular-visual-odometry\n",
      "\tSuccessfully loaded task monocular-visual-odometry, with papers 0\n",
      "\n",
      "\tWorking on Gesture-generation\n",
      "\tSuccessfully loaded task gesture-generation, with papers 11\n",
      "\n",
      "\tWorking on Legged-robots\n",
      "\tSuccessfully loaded task legged-robots, with papers 27\n",
      "\n",
      "\tWorking on Robot-navigation\n",
      "\tSuccessfully loaded task robot-navigation, with papers 132\n",
      "\n",
      "\tWorking on 3d-face-reconstruction\n",
      "\tSuccessfully loaded task 3d-face-reconstruction, with papers 71\n",
      "\n",
      "\tWorking on Mental-stress-detection\n",
      "\tSuccessfully loaded task mental-stress-detection, with papers 1\n",
      "\n",
      "\tWorking on Curriculum-learning\n",
      "\tSuccessfully loaded task curriculum-learning, with papers 225\n",
      "\n",
      "\tWorking on Vision-based-navigation-with-language-based\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task vision-based-navigation-with-language-based, with papers 1\n",
      "\n",
      "\tWorking on Voice-assistant\n",
      "\tSuccessfully loaded task voice-assistant, with papers 17\n",
      "\n",
      "--- Working on Speech ---\n",
      "\tWorking on Acoustic-echo-cancellation\n",
      "\tSuccessfully loaded task acoustic-echo-cancellation, with papers 17\n",
      "\n",
      "\tWorking on Speech-separation\n",
      "\tSuccessfully loaded task speech-separation, with papers 102\n",
      "\n",
      "\tWorking on Acoustic-unit-discovery\n",
      "\tSuccessfully loaded task acoustic-unit-discovery, with papers 8\n",
      "\n",
      "\tWorking on Speaker-recognition\n",
      "\tSuccessfully loaded task speaker-recognition, with papers 163\n",
      "\n",
      "\tWorking on Acoustic-question-answering\n",
      "\tSuccessfully loaded task acoustic-question-answering, with papers 1\n",
      "\n",
      "\tWorking on End-to-end-speech-recognition\n",
      "\tSuccessfully loaded task end-to-end-speech-recognition, with papers 168\n",
      "\n",
      "\tWorking on Speaker-diarization\n",
      "\tSuccessfully loaded task speaker-diarization, with papers 78\n",
      "\n",
      "\tWorking on Spoken-dialogue-systems\n",
      "\tSuccessfully loaded task spoken-dialogue-systems, with papers 132\n",
      "\n",
      "\tWorking on Speech-quality\n",
      "\tSuccessfully loaded task speech-quality, with papers 91\n",
      "\n",
      "\tWorking on Acoustic-modelling\n",
      "\tSuccessfully loaded task acoustic-modelling, with papers 24\n",
      "\n",
      "\tWorking on Sequence-to-sequence-speech-recognition\n",
      "\tSuccessfully loaded task sequence-to-sequence-speech-recognition, with papers 8\n",
      "\n",
      "\tWorking on Manner-of-articulation-detection\n",
      "\tSuccessfully loaded task manner-of-articulation-detection, with papers 2\n",
      "\n",
      "\tWorking on Speaker-verification\n",
      "\tSuccessfully loaded task speaker-verification, with papers 158\n",
      "\n",
      "\tWorking on Voice-query-recognition\n",
      "\tSuccessfully loaded task voice-query-recognition, with papers 1\n",
      "\n",
      "\tWorking on Speaker-separation\n",
      "\tSuccessfully loaded task speaker-separation, with papers 12\n",
      "\n",
      "\tWorking on Speech-dereverberation\n",
      "\tSuccessfully loaded task speech-dereverberation, with papers 8\n",
      "\n",
      "\tWorking on Speech-enhancement\n",
      "\tSuccessfully loaded task speech-enhancement, with papers 184\n",
      "\n",
      "\tWorking on Speech-denoising\n",
      "\tSuccessfully loaded task speech-denoising, with papers 3\n",
      "\n",
      "\tWorking on Speech-emotion-recognition\n",
      "\tSuccessfully loaded task speech-emotion-recognition, with papers 67\n",
      "\n",
      "\tWorking on Robust-speech-recognition\n",
      "\tSuccessfully loaded task robust-speech-recognition, with papers 28\n",
      "\n",
      "\tWorking on Text-dependent-speaker-verification\n",
      "\tSuccessfully loaded task text-dependent-speaker-verification, with papers 0\n",
      "\n",
      "\tWorking on Speech-synthesis\n",
      "\tSuccessfully loaded task speech-synthesis, with papers 334\n",
      "\n",
      "\tWorking on Spoken-language-understanding\n",
      "\tSuccessfully loaded task spoken-language-understanding, with papers 201\n",
      "\n",
      "\tWorking on Noisy-speech-recognition\n",
      "\tSuccessfully loaded task noisy-speech-recognition, with papers 6\n",
      "\n",
      "\tWorking on Voice-conversion\n",
      "\tSuccessfully loaded task voice-conversion, with papers 0\n",
      "\n",
      "\tWorking on Visual-speech-recognition\n",
      "\tSuccessfully loaded task visual-speech-recognition, with papers 46\n",
      "\n",
      "\tWorking on Text-independent-speaker-recognition\n",
      "\tSuccessfully loaded task text-independent-speaker-recognition, with papers 0\n",
      "\n",
      "\tWorking on Small-footprint-keyword-spotting\n",
      "\tSuccessfully loaded task small-footprint-keyword-spotting, with papers 11\n",
      "\n",
      "\tWorking on Keyword-spotting\n",
      "\tSuccessfully loaded task keyword-spotting, with papers 88\n",
      "\n",
      "\tWorking on Dialogue-generation\n",
      "\tSuccessfully loaded task dialogue-generation, with papers 128\n",
      "\n",
      "\tWorking on Expressive-speech-synthesis\n",
      "\tSuccessfully loaded task expressive-speech-synthesis, with papers 0\n",
      "\n",
      "\tWorking on Text-independent-speaker-verification\n",
      "\tSuccessfully loaded task text-independent-speaker-verification, with papers 0\n",
      "\n",
      "\tWorking on Spoken-language-identification\n",
      "\tSuccessfully loaded task spoken-language-identification, with papers 13\n",
      "\n",
      "\tWorking on Pronunciation-assessment\n",
      "\tSuccessfully loaded task pronunciation-assessment, with papers 0\n",
      "\n",
      "\tWorking on Speaker-profiling\n",
      "\tSuccessfully loaded task speaker-profiling, with papers 2\n",
      "\n",
      "\tWorking on Speech-recognition\n",
      "\tSuccessfully loaded task speech-recognition, with papers 808\n",
      "\n",
      "\tWorking on Distant-speech-recognition\n",
      "\tSuccessfully loaded task distant-speech-recognition, with papers 6\n",
      "\n",
      "\tWorking on English-conversational-speech-recognition\n",
      "\tSuccessfully loaded task english-conversational-speech-recognition, with papers 1\n",
      "\n",
      "\tWorking on Speech-to-gesture-translation\n",
      "\tSuccessfully loaded task speech-to-gesture-translation, with papers 1\n",
      "\n",
      "\tWorking on Speaking-style-synthesis\n",
      "\tSuccessfully loaded task speaking-style-synthesis, with papers 0\n",
      "\n",
      "\tWorking on Speech-extraction\n",
      "\tSuccessfully loaded task speech-extraction, with papers 4\n",
      "\n",
      "\tWorking on Emotional-speech-synthesis\n",
      "\tSuccessfully loaded task emotional-speech-synthesis, with papers 0\n",
      "\n",
      "\tWorking on Phone-level-pronunciation-scoring\n",
      "\tSuccessfully loaded task phone-level-pronunciation-scoring, with papers 1\n",
      "\n",
      "\tWorking on Anomaly-detection\n",
      "\tSuccessfully loaded task anomaly-detection, with papers 21\n",
      "\n",
      "\tWorking on Multi-speaker-source-separation\n",
      "\tSuccessfully loaded task multi-speaker-source-separation, with papers 3\n",
      "\n",
      "\tWorking on Unsupervised-speech-recognition\n",
      "\tSuccessfully loaded task unsupervised-speech-recognition, with papers 2\n",
      "\n",
      "\tWorking on Accented-speech-recognition\n",
      "\tSuccessfully loaded task accented-speech-recognition, with papers 1\n",
      "\n",
      "\tWorking on Text-to-speech-synthesis\n",
      "\tSuccessfully loaded task text-to-speech-synthesis, with papers 1\n",
      "\n",
      "\tWorking on Speaker-identification\n",
      "\tSuccessfully loaded task speaker-identification, with papers 44\n",
      "\n",
      "\tWorking on Large-vocabulary-continuous-speech\n",
      "\tSuccessfully loaded task large-vocabulary-continuous-speech, with papers 25\n",
      "\n",
      "--- Working on Time-series ---\n",
      "\tWorking on Moving-point-cloud-processing\n",
      "\tSuccessfully loaded task moving-point-cloud-processing, with papers 1\n",
      "\n",
      "\tWorking on Eeg\n",
      "\tSuccessfully loaded task eeg, with papers 608\n",
      "\n",
      "\tWorking on Time-series-denoising\n",
      "\tSuccessfully loaded task time-series-denoising, with papers 2\n",
      "\n",
      "\tWorking on Multivariate-time-series-imputation\n",
      "\tSuccessfully loaded task multivariate-time-series-imputation, with papers 14\n",
      "\n",
      "\tWorking on Time-series-analysis\n",
      "\tSuccessfully loaded task time-series-analysis, with papers 169\n",
      "\n",
      "\tWorking on Multivariate-time-series-forecasting\n",
      "\tSuccessfully loaded task multivariate-time-series-forecasting, with papers 25\n",
      "\n",
      "\tWorking on Seismic-source-localization\n",
      "\tSuccessfully loaded task seismic-source-localization, with papers 1\n",
      "\n",
      "\tWorking on Sleep-spindles-detection\n",
      "\tSuccessfully loaded task sleep-spindles-detection, with papers 0\n",
      "\n",
      "\tWorking on Time-series-alignment\n",
      "\tSuccessfully loaded task time-series-alignment, with papers 4\n",
      "\n",
      "\tWorking on Time-series-averaging\n",
      "\tSuccessfully loaded task time-series-averaging, with papers 6\n",
      "\n",
      "\tWorking on Lip-password-classification\n",
      "\tSuccessfully loaded task lip-password-classification, with papers 1\n",
      "\n",
      "\tWorking on Human-motion-prediction\n",
      "\tSuccessfully loaded task human-motion-prediction, with papers 39\n",
      "\n",
      "\tWorking on Spatio-temporal-forecasting\n",
      "\tSuccessfully loaded task spatio-temporal-forecasting, with papers 14\n",
      "\n",
      "\tWorking on Time-to-event-prediction\n",
      "\tSuccessfully loaded task time-to-event-prediction, with papers 6\n",
      "\n",
      "\tWorking on Time-series\n",
      "\tSuccessfully loaded task time-series, with papers 2056\n",
      "\n",
      "\tWorking on Traffic-prediction\n",
      "\tSuccessfully loaded task traffic-prediction, with papers 58\n",
      "\n",
      "\tWorking on Change-point-detection\n",
      "\tSuccessfully loaded task change-point-detection, with papers 55\n",
      "\n",
      "\tWorking on Irregular-time-series\n",
      "\tSuccessfully loaded task irregular-time-series, with papers 1\n",
      "\n",
      "\tWorking on Math-word-problem-solving\n",
      "\tSuccessfully loaded task math-word-problem-solving, with papers 0\n",
      "\n",
      "\tWorking on Time-series-regression\n",
      "\tSuccessfully loaded task time-series-regression, with papers 2\n",
      "\n",
      "\tWorking on Semanticity-prediction\n",
      "\tSuccessfully loaded task semanticity-prediction, with papers 1\n",
      "\n",
      "\tWorking on Imputation\n",
      "\tSuccessfully loaded task imputation, with papers 218\n",
      "\n",
      "\tWorking on Stock-trend-prediction\n",
      "\tSuccessfully loaded task stock-trend-prediction, with papers 3\n",
      "\n",
      "\tWorking on Attention-score-prediction\n",
      "\tSuccessfully loaded task attention-score-prediction, with papers 0\n",
      "\n",
      "\tWorking on Time-series-forecasting\n",
      "\tSuccessfully loaded task time-series-forecasting, with papers 27\n",
      "\n",
      "\tWorking on Semi-supervised-semantic-segmentation\n",
      "\tSuccessfully loaded task semi-supervised-semantic-segmentation, with papers 0\n",
      "\n",
      "\tWorking on Eeg-decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task eeg-decoding, with papers 0\n",
      "\n",
      "\tWorking on Covid-19-modelling\n",
      "\tSuccessfully loaded task covid-19-modelling, with papers 0\n",
      "\n",
      "\tWorking on Predictive-process-monitoring\n",
      "\tSuccessfully loaded task predictive-process-monitoring, with papers 9\n",
      "\n",
      "\tWorking on Stock-price-prediction\n",
      "\tSuccessfully loaded task stock-price-prediction, with papers 37\n",
      "\n",
      "\tWorking on Trajectory-modeling\n",
      "\tSuccessfully loaded task trajectory-modeling, with papers 5\n",
      "\n",
      "\tWorking on Edge-computing\n",
      "\tSuccessfully loaded task edge-computing, with papers 216\n",
      "\n",
      "\tWorking on Clustering-multivariate-time-series\n",
      "\tSuccessfully loaded task clustering-multivariate-time-series, with papers 1\n",
      "\n",
      "\tWorking on Sequential-skip-prediction\n",
      "\tSuccessfully loaded task sequential-skip-prediction, with papers 3\n",
      "\n",
      "\tWorking on Covid-19-tracking\n",
      "\tSuccessfully loaded task covid-19-tracking, with papers 0\n",
      "\n",
      "\tWorking on Unsupervised-spatial-clustering\n",
      "\tSuccessfully loaded task unsupervised-spatial-clustering, with papers 3\n",
      "\n",
      "\tWorking on Portfolio-optimization\n",
      "\tSuccessfully loaded task portfolio-optimization, with papers 100\n",
      "\n",
      "\tWorking on Univariate-time-series-forecasting\n",
      "\tSuccessfully loaded task univariate-time-series-forecasting, with papers 0\n",
      "\n",
      "\tWorking on Trajectory-prediction\n",
      "\tSuccessfully loaded task trajectory-prediction, with papers 0\n",
      "\n",
      "\tWorking on Stock-market-prediction\n",
      "\tSuccessfully loaded task stock-market-prediction, with papers 31\n",
      "\n",
      "\tWorking on Noise-level-prediction\n",
      "\tSuccessfully loaded task noise-level-prediction, with papers 0\n",
      "\n",
      "\tWorking on Time-series-classification\n",
      "\tSuccessfully loaded task time-series-classification, with papers 21\n",
      "\n",
      "\tWorking on Non-intrusive-load-monitoring\n",
      "\tSuccessfully loaded task non-intrusive-load-monitoring, with papers 0\n",
      "\n",
      "\tWorking on Traffic-data-imputation\n",
      "\tSuccessfully loaded task traffic-data-imputation, with papers 0\n",
      "\n",
      "\tWorking on Time-series-prediction\n",
      "\tSuccessfully loaded task time-series-prediction, with papers 15\n",
      "\n",
      "\tWorking on Probabilistic-time-series-forecasting\n",
      "\tSuccessfully loaded task probabilistic-time-series-forecasting, with papers 0\n",
      "\n",
      "\tWorking on Lwr-classification\n",
      "\tSuccessfully loaded task lwr-classification, with papers 0\n",
      "\n",
      "\tWorking on Time-series-clustering\n",
      "\tSuccessfully loaded task time-series-clustering, with papers 1\n",
      "\n",
      "\tWorking on Stock-prediction\n",
      "\tSuccessfully loaded task stock-prediction, with papers 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_meta_dict = {}\n",
    "for area in areas_id:\n",
    "    \n",
    "    print(f\"--- Working on {area.capitalize()} ---\")\n",
    "    try:\n",
    "        task_id_lists = list(map(get_id, client.area_task_list(area).results))\n",
    "        \n",
    "    except:\n",
    "        print(f\"**Error occurred with area {area}.**\")\n",
    "        continue\n",
    "        \n",
    "    for task_id in task_id_lists:\n",
    "        \n",
    "        page_idx = 1\n",
    "        ref = len(paper_meta_dict)\n",
    "        print(f\"\\tWorking on {task_id.capitalize()}\")\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                results = http.get(f\"/tasks/{task_id}/papers/?page={page_idx}\")['results']\n",
    "                for p in results:\n",
    "                    paper_meta_dict[p['title']] = p\n",
    "                page_idx += 1\n",
    "                \n",
    "            except:\n",
    "                print(f\"\\tSuccessfully loaded task {task_id}, with papers {len(paper_meta_dict) - ref}\\n\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T13:08:29.305973Z",
     "start_time": "2021-04-28T13:06:09.120302Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE DICT TO YAML\n",
    "with open('paperswithcode_meta.yml', 'w') as y:\n",
    "    yaml.dump(paper_meta_dict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T23:26:14.114580Z",
     "start_time": "2021-04-28T23:26:14.108603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'brilliant-ai-doctor-in-rural-china-tensions',\n",
       " 'arxiv_id': '2101.01524',\n",
       " 'nips_id': None,\n",
       " 'url_abs': 'https://arxiv.org/abs/2101.01524v2',\n",
       " 'url_pdf': 'https://arxiv.org/pdf/2101.01524v2.pdf',\n",
       " 'title': '\"Brilliant AI Doctor\" in Rural China: Tensions and Challenges in AI-Powered CDSS Deployment',\n",
       " 'abstract': 'Artificial intelligence (AI) technology has been increasingly used in the implementation of advanced Clinical Decision Support Systems (CDSS). Research demonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical decision making scenarios. However, post-adoption user perception and experience remain understudied, especially in developing countries. Through observations and interviews with 22 clinicians from 6 rural clinics in China, this paper reports the various tensions between the design of an AI-CDSS system (\"Brilliant Doctor\") and the rural clinical context, such as the misalignment with local context and workflow, the technical limitations and usability barriers, as well as issues related to transparency and trustworthiness of AI-CDSS. Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as \"a doctor\\'s AI assistant\" to realize a Human-AI Collaboration future in clinical settings. Finally we draw on our findings to discuss implications for designing AI-CDSS interventions for rural clinical contexts in developing countries.',\n",
       " 'authors': ['Dakuo Wang',\n",
       "  'Liuping Wang',\n",
       "  'Zhan Zhang',\n",
       "  'Ding Wang',\n",
       "  'Haiyi Zhu',\n",
       "  'Yvonne Gao',\n",
       "  'Xiangmin Fan',\n",
       "  'Feng Tian'],\n",
       " 'published': '2021-01-04',\n",
       " 'conference': None,\n",
       " 'conference_url_abs': None,\n",
       " 'conference_url_pdf': None,\n",
       " 'proceeding': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_meta_dict['\"Brilliant AI Doctor\" in Rural China: Tensions and Challenges in AI-Powered CDSS Deployment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:48:38.835615Z",
     "start_time": "2021-04-22T13:47:15.576916Z"
    }
   },
   "outputs": [],
   "source": [
    "# # SAVE DICT TO YAML\n",
    "# with open('paperswithcode_title.yml', 'w') as y:\n",
    "#     yaml.dump(area_paper_dict, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Convert to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T03:48:26.648972Z",
     "start_time": "2021-04-24T03:46:34.684015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d4a523342fa9>:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  paper_dict = yaml.load(y)\n"
     ]
    }
   ],
   "source": [
    "# with open('paperswithcode_title.yml', 'r') as y:\n",
    "#     paper_dict = yaml.load(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T04:07:24.593717Z",
     "start_time": "2021-04-24T04:07:24.583719Z"
    }
   },
   "outputs": [],
   "source": [
    "_area = list(paper_dict.keys())\n",
    "_zeros = np.zeros_like(_area, dtype='uint8')\n",
    "paper_onehot_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T04:07:52.270085Z",
     "start_time": "2021-04-24T04:07:50.014841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, (area, papers) in enumerate(tqdm(paper_dict.items())):\n",
    "    \n",
    "    for p in papers:\n",
    "        \n",
    "        if paper_onehot_dict.get(p) is None:\n",
    "            one_hot = _zeros.copy()\n",
    "            one_hot[idx] += 1\n",
    "            paper_onehot_dict[p] = one_hot            \n",
    "        \n",
    "        else:\n",
    "            paper_onehot_dict[p][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T04:07:58.736927Z",
     "start_time": "2021-04-24T04:07:56.407957Z"
    }
   },
   "outputs": [],
   "source": [
    "paper_area_df = pd.DataFrame(paper_onehot_dict, index=paper_dict.keys()).T\n",
    "paper_area_df.to_csv('./paperswithtopic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:01:46.029962Z",
     "start_time": "2021-04-24T05:01:45.852116Z"
    }
   },
   "outputs": [],
   "source": [
    "paper_df = pd.read_csv('paperswithtopic.csv', index_col=0)\n",
    "paper_df[paper_df >= 1] = 1\n",
    "paper_df = paper_df.astype({c: 'int8' for c in paper_df.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:01:46.421280Z",
     "start_time": "2021-04-24T05:01:46.395101Z"
    }
   },
   "outputs": [],
   "source": [
    "paper2idx = {p: i for p, i in enumerate(paper_df.index)}\n",
    "X_raw = list(map(str.lower, paper2idx.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T06:01:05.120206Z",
     "start_time": "2021-04-24T06:01:05.110163Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = paper_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T06:07:46.729305Z",
     "start_time": "2021-04-24T06:07:46.699063Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, labels, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Unique number of papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:01:54.927931Z",
     "start_time": "2021-04-24T05:01:54.914933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Papers: 49980\n",
      "# Areas : 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Papers: {paper_df.shape[0]}\\n# Areas : {paper_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Label number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:01:55.650578Z",
     "start_time": "2021-04-24T05:01:55.642069Z"
    }
   },
   "outputs": [],
   "source": [
    "paper_sum = paper_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:01:56.062221Z",
     "start_time": "2021-04-24T05:01:56.043221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 40694, 2: 8297, 3: 932, 4: 53, 5: 3, 7: 1})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(paper_sum.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generalized format for every models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:01:57.108326Z",
     "start_time": "2021-04-24T05:01:57.098327Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T05:02:01.161566Z",
     "start_time": "2021-04-24T05:01:57.458119Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-large-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:37.517362Z",
     "start_time": "2021-04-24T10:36:35.159639Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer(X_train, padding=True, add_special_tokens=False,\n",
    "                              max_length=60, truncation=True)\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, add_special_tokens=False,\n",
    "                             max_length=60, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:16.506047Z",
     "start_time": "2021-04-24T10:36:16.493002Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaperDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.loc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:20.727884Z",
     "start_time": "2021-04-24T10:36:20.695853Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = PaperDataset(X_train_tokenized, y_train)\n",
    "test_dataset = PaperDataset(X_test_tokenized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:21.094416Z",
     "start_time": "2021-04-24T10:36:20.840124Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:21.110415Z",
     "start_time": "2021-04-24T10:36:21.097418Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:21.237412Z",
     "start_time": "2021-04-24T10:36:21.230377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 65])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:22.625924Z",
     "start_time": "2021-04-24T10:36:22.607338Z"
    }
   },
   "outputs": [],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:38.325905Z",
     "start_time": "2021-04-24T10:36:38.070362Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train2token_np = np.array(X_train_tokenized['input_ids'], dtype=float)\n",
    "X_test2token_np = np.array(X_test_tokenized['input_ids'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:39.405388Z",
     "start_time": "2021-04-24T10:36:38.334906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train2token_np, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:40.272896Z",
     "start_time": "2021-04-24T10:36:40.125897Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test2token_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:40.399922Z",
     "start_time": "2021-04-24T10:36:40.390408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44982, 60), (4998, 60))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2token_np.shape, X_test2token_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:41.113979Z",
     "start_time": "2021-04-24T10:36:41.093946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020008003201280514"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test.values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:43.155123Z",
     "start_time": "2021-04-24T10:36:42.070511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.669334400426837e-05"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train.values, classifier.predict(X_train2token_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:35:15.221688Z",
     "start_time": "2021-04-24T10:35:15.206691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:35:03.742701Z",
     "start_time": "2021-04-24T10:35:03.729028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:36:57.614336Z",
     "start_time": "2021-04-24T10:36:57.543412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train2token_np, y_train.loc[:, 'adversarial'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:37:10.059719Z",
     "start_time": "2021-04-24T10:37:09.982484Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pred = clf.predict(X_train2token_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:37:22.973667Z",
     "start_time": "2021-04-24T10:37:22.957664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02914499132986528"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train.loc[:, 'adversarial'].values, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T10:37:56.080432Z",
     "start_time": "2021-04-24T10:37:56.063393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44496"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T00:41:15.859771Z",
     "start_time": "2021-04-26T00:41:15.833738Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
