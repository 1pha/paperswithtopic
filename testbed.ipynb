{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:17.972303Z",
     "start_time": "2021-04-21T08:37:17.450764Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:18.636889Z",
     "start_time": "2021-04-21T08:37:17.973305Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "\n",
    "from tea_client.http import HttpClient\n",
    "from tea_client.handler import handler\n",
    "\n",
    "from paperswithcode.config import config\n",
    "from paperswithcode.models import (\n",
    "    Paper,\n",
    "    Papers,\n",
    "    Repository,\n",
    "    Conference,\n",
    "    Conferences,\n",
    "    Proceeding,\n",
    "    Proceedings,\n",
    "    Area,\n",
    "    Areas,\n",
    "    Task,\n",
    "    TaskCreateRequest,\n",
    "    TaskUpdateRequest,\n",
    "    Tasks,\n",
    "    Dataset,\n",
    "    DatasetCreateRequest,\n",
    "    DatasetUpdateRequest,\n",
    "    Datasets,\n",
    "    Method,\n",
    "    Methods,\n",
    "    Metric,\n",
    "    MetricCreateRequest,\n",
    "    MetricUpdateRequest,\n",
    "    Result,\n",
    "    ResultCreateRequest,\n",
    "    ResultUpdateRequest,\n",
    "    EvaluationTable,\n",
    "    EvaluationTables,\n",
    "    EvaluationTableCreateRequest,\n",
    "    EvaluationTableUpdateRequest,\n",
    "    EvaluationTableSyncRequest,\n",
    "    EvaluationTableSyncResponse,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:18.651921Z",
     "start_time": "2021-04-21T08:37:18.637891Z"
    }
   },
   "outputs": [],
   "source": [
    "token=None\n",
    "url=None\n",
    "url = url or config.server_url\n",
    "http = HttpClient(\n",
    "    url=f\"{url}/api/v{config.api_version}\",\n",
    "    token=token or \"\",\n",
    "    authorization_method=HttpClient.Authorization.token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:49.554487Z",
     "start_time": "2021-04-21T08:37:44.631880Z"
    }
   },
   "outputs": [],
   "source": [
    "from paperswithcode import PapersWithCodeClient\n",
    "\n",
    "client = PapersWithCodeClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:41:06.325501Z",
     "start_time": "2021-04-21T06:41:06.313921Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tasks(_id):\n",
    "    \n",
    "    try:\n",
    "        tasks = [t['id'] for t in http.get(f\"/papers/{_id}/tasks/\")['results']]\n",
    "        return tasks\n",
    "    except:\n",
    "        print(\"error occured.\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:42:16.191427Z",
     "start_time": "2021-04-21T06:42:16.175846Z"
    }
   },
   "outputs": [],
   "source": [
    "paper_task_dict = dict()\n",
    "exception_logs = dict()\n",
    "\n",
    "empty_cnt = 0\n",
    "max_tasks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:44:07.180945Z",
     "start_time": "2021-04-21T06:42:16.626630Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-unique-games-over-compact-groups-and: ['electron-microscopy']\n",
      "parametric-regression-on-the-grassmannian: ['crowd-counting']\n",
      "non-unique-games-over-compact-groups-and: ['electron-microscopy']\n",
      "pinball-loss-minimization-for-one-bit: ['quantization', 'compressive-sensing']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'papers_tasks_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-803ad544ddcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpapers_tasks_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'papers_tasks_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for p in range(1000, 14817):\n",
    "    \n",
    "    try:\n",
    "        papers_list = client.paper_list(page=p)\n",
    "    except:\n",
    "        print(f\"Unable to load page {p}.\")\n",
    "        continue\n",
    "        \n",
    "    for paper in papers_list.results:\n",
    "        \n",
    "        _id = paper.id\n",
    "        tasks = get_tasks(_id)\n",
    "        if tasks:\n",
    "            print(f\"{_id}: {tasks}\")\n",
    "            if len(tasks) <= max_tasks:\n",
    "                paper_task_dict.update({\n",
    "                    _id: tasks\n",
    "                })\n",
    "            elif len(tasks) > max_tasks:\n",
    "                print(_id, len(tasks))\n",
    "                exception_logs[_id] = {'# of tasks': len(tasks)}\n",
    "        else:\n",
    "            empty_cnt += 1\n",
    "            \n",
    "    if p % 20:\n",
    "        pd.DataFrame(paper_task_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:30.340514Z",
     "start_time": "2021-04-21T08:37:30.334892Z"
    }
   },
   "outputs": [],
   "source": [
    "get_id = lambda x: x.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:43:01.834023Z",
     "start_time": "2021-04-21T08:40:51.953585Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Working on Adversarial ---\n",
      "\tWorking on Website-fingerprinting-defense\n",
      "\tSuccessfully loaded task website-fingerprinting-defense, with papers 1\n",
      "\n",
      "\tWorking on Adversarial-attack\n",
      "\tSuccessfully loaded task adversarial-attack, with papers 585\n",
      "\n",
      "\tWorking on Adversarial-defense\n",
      "\tSuccessfully loaded task adversarial-defense, with papers 158\n",
      "\n",
      "\tWorking on Real-world-adversarial-attack\n",
      "\tSuccessfully loaded task real-world-adversarial-attack, with papers 4\n",
      "\n",
      "\tWorking on Provable-adversarial-defense\n",
      "\tSuccessfully loaded task provable-adversarial-defense, with papers 1\n",
      "\n",
      "\tWorking on Adversarial-text\n",
      "\tSuccessfully loaded task adversarial-text, with papers 32\n",
      "\n",
      "\tWorking on Data-poisoning\n",
      "\tSuccessfully loaded task data-poisoning, with papers 128\n",
      "\n",
      "\tWorking on Website-fingerprinting-attacks\n",
      "\tSuccessfully loaded task website-fingerprinting-attacks, with papers 6\n",
      "\n",
      "\tWorking on Inference-attack\n",
      "\tSuccessfully loaded task inference-attack, with papers 61\n",
      "\n",
      "--- Working on Audio ---\n",
      "\tWorking on Shooter-localization\n",
      "\tSuccessfully loaded task shooter-localization, with papers 1\n",
      "\n",
      "\tWorking on Sound-event-detection\n",
      "\tSuccessfully loaded task sound-event-detection, with papers 52\n",
      "\n",
      "\tWorking on Acoustic-scene-classification\n",
      "\tSuccessfully loaded task acoustic-scene-classification, with papers 52\n",
      "\n",
      "\tWorking on Environmental-sound-classification\n",
      "\tSuccessfully loaded task environmental-sound-classification, with papers 25\n",
      "\n",
      "\tWorking on Image-animation\n",
      "\tSuccessfully loaded task image-animation, with papers 13\n",
      "\n",
      "\tWorking on Audio-visual-synchronization\n",
      "\tSuccessfully loaded task audio-visual-synchronization, with papers 7\n",
      "\n",
      "\tWorking on Voice-conversion\n",
      "\tSuccessfully loaded task voice-conversion, with papers 139\n",
      "\n",
      "\tWorking on Gunshot-detection\n",
      "\tSuccessfully loaded task gunshot-detection, with papers 1\n",
      "\n",
      "\tWorking on Bird-classification\n",
      "\tSuccessfully loaded task bird-classification, with papers 0\n",
      "\n",
      "\tWorking on Audio-super-resolution\n",
      "\tSuccessfully loaded task audio-super-resolution, with papers 6\n",
      "\n",
      "\tWorking on Audio-classification\n",
      "\tSuccessfully loaded task audio-classification, with papers 87\n",
      "\n",
      "\tWorking on Speaker-orientation\n",
      "\tSuccessfully loaded task speaker-orientation, with papers 1\n",
      "\n",
      "\tWorking on Voice-anti-spoofing\n",
      "\tSuccessfully loaded task voice-anti-spoofing, with papers 5\n",
      "\n",
      "\tWorking on Audio-tagging\n",
      "\tSuccessfully loaded task audio-tagging, with papers 23\n",
      "\n",
      "\tWorking on Audio-generation\n",
      "\tSuccessfully loaded task audio-generation, with papers 33\n",
      "\n",
      "\tWorking on Audio-source-separation\n",
      "\tSuccessfully loaded task audio-source-separation, with papers 53\n",
      "\n",
      "\tWorking on Vowel-classification\n",
      "\tSuccessfully loaded task vowel-classification, with papers 3\n",
      "\n",
      "\tWorking on Audio-signal-recognition\n",
      "\tSuccessfully loaded task audio-signal-recognition, with papers 2\n",
      "\n",
      "\tWorking on Audio-declipping\n",
      "\tSuccessfully loaded task audio-declipping, with papers 2\n",
      "\n",
      "\tWorking on Audio-fingerprint\n",
      "\tSuccessfully loaded task audio-fingerprint, with papers 1\n",
      "\n",
      "\tWorking on Music-generation\n",
      "\tSuccessfully loaded task music-generation, with papers 99\n",
      "\n",
      "\tWorking on Bird-species-classification-with-audio-visual\n",
      "\tSuccessfully loaded task bird-species-classification-with-audio-visual, with papers 1\n",
      "\n",
      "\tWorking on Audio-denoising\n",
      "\tSuccessfully loaded task audio-denoising, with papers 6\n",
      "\n",
      "\tWorking on Audio-dequantization\n",
      "\tSuccessfully loaded task audio-dequantization, with papers 3\n",
      "\n",
      "\tWorking on Acoustic-novelty-detection\n",
      "\tSuccessfully loaded task acoustic-novelty-detection, with papers 3\n",
      "\n",
      "\tWorking on Direction-of-arrival-estimation\n",
      "\tSuccessfully loaded task direction-of-arrival-estimation, with papers 22\n",
      "\n",
      "\tWorking on Chord-recognition\n",
      "\tSuccessfully loaded task chord-recognition, with papers 12\n",
      "\n",
      "\tWorking on Bird-audio-detection\n",
      "\tSuccessfully loaded task bird-audio-detection, with papers 3\n",
      "\n",
      "--- Working on Computer-code ---\n",
      "\tWorking on Code-comment-generation\n",
      "\tSuccessfully loaded task code-comment-generation, with papers 5\n",
      "\n",
      "\tWorking on Codesearchnet-java\n",
      "\tSuccessfully loaded task codesearchnet-java, with papers 0\n",
      "\n",
      "\tWorking on Single-image-portrait-relighting\n",
      "\tSuccessfully loaded task single-image-portrait-relighting, with papers 2\n",
      "\n",
      "\tWorking on Text-to-sql\n",
      "\tSuccessfully loaded task text-to-sql, with papers 71\n",
      "\n",
      "\tWorking on Annotated-code-search\n",
      "\tSuccessfully loaded task annotated-code-search, with papers 2\n",
      "\n",
      "\tWorking on Sparse-subspace-based-clustering\n",
      "\tSuccessfully loaded task sparse-subspace-based-clustering, with papers 1\n",
      "\n",
      "\tWorking on Sentinel-1-sar-processing\n",
      "\tSuccessfully loaded task sentinel-1-sar-processing, with papers 1\n",
      "\n",
      "\tWorking on Program-synthesis\n",
      "\tSuccessfully loaded task program-synthesis, with papers 128\n",
      "\n",
      "\tWorking on Sql-synthesis\n",
      "\tSuccessfully loaded task sql-synthesis, with papers 1\n",
      "\n",
      "\tWorking on Swapped-operands\n",
      "\tSuccessfully loaded task swapped-operands, with papers 1\n",
      "\n",
      "\tWorking on Api-sequence-recommendation\n",
      "\tSuccessfully loaded task api-sequence-recommendation, with papers 1\n",
      "\n",
      "\tWorking on Formalize-foundations-of-universal-algebra-in\n",
      "\tSuccessfully loaded task formalize-foundations-of-universal-algebra-in, with papers 1\n",
      "\n",
      "\tWorking on Wrong-binary-operator\n",
      "\tSuccessfully loaded task wrong-binary-operator, with papers 1\n",
      "\n",
      "\tWorking on Low-rank-compression\n",
      "\tSuccessfully loaded task low-rank-compression, with papers 7\n",
      "\n",
      "\tWorking on Variable-misuse\n",
      "\tSuccessfully loaded task variable-misuse, with papers 5\n",
      "\n",
      "\tWorking on Program-induction\n",
      "\tSuccessfully loaded task program-induction, with papers 41\n",
      "\n",
      "\tWorking on Code-search\n",
      "\tSuccessfully loaded task code-search, with papers 27\n",
      "\n",
      "\tWorking on Function-docstring-mismatch\n",
      "\tSuccessfully loaded task function-docstring-mismatch, with papers 1\n",
      "\n",
      "\tWorking on Fault-localization\n",
      "\tSuccessfully loaded task fault-localization, with papers 18\n",
      "\n",
      "\tWorking on Semi-supervised-semantic-segmentation\n",
      "\tSuccessfully loaded task semi-supervised-semantic-segmentation, with papers 38\n",
      "\n",
      "\tWorking on Enumerative-search\n",
      "\tSuccessfully loaded task enumerative-search, with papers 5\n",
      "\n",
      "\tWorking on Federated-learning\n",
      "\tSuccessfully loaded task federated-learning, with papers 952\n",
      "\n",
      "\tWorking on Write-computer-programs-from-specifications\n",
      "\tSuccessfully loaded task write-computer-programs-from-specifications, with papers 0\n",
      "\n",
      "\tWorking on Program-repair\n",
      "\tSuccessfully loaded task program-repair, with papers 28\n",
      "\n",
      "\tWorking on Type-prediction\n",
      "\tSuccessfully loaded task type-prediction, with papers 40\n",
      "\n",
      "\tWorking on Code-summarization\n",
      "\tSuccessfully loaded task code-summarization, with papers 29\n",
      "\n",
      "\tWorking on Webcam-rgb-image-classification\n",
      "\tSuccessfully loaded task webcam-rgb-image-classification, with papers 3\n",
      "\n",
      "\tWorking on Sql-to-text\n",
      "\tSuccessfully loaded task sql-to-text, with papers 3\n",
      "\n",
      "\tWorking on Exception-type\n",
      "\tSuccessfully loaded task exception-type, with papers 1\n",
      "\n",
      "\tWorking on Code-generation\n",
      "\tSuccessfully loaded task code-generation, with papers 102\n",
      "\n",
      "\tWorking on Learning-to-execute\n",
      "\tSuccessfully loaded task learning-to-execute, with papers 6\n",
      "\n",
      "\tWorking on Value-prediction\n",
      "\tSuccessfully loaded task value-prediction, with papers 24\n",
      "\n",
      "\tWorking on Log-parsing\n",
      "\tSuccessfully loaded task log-parsing, with papers 3\n",
      "\n",
      "\tWorking on Sql-chatbots\n",
      "\tSuccessfully loaded task sql-chatbots, with papers 1\n",
      "\n",
      "\tWorking on Contextual-embedding-for-source-code\n",
      "\tSuccessfully loaded task contextual-embedding-for-source-code, with papers 2\n",
      "\n",
      "\tWorking on Git-commit-message-generation\n",
      "\tSuccessfully loaded task git-commit-message-generation, with papers 1\n",
      "\n",
      "--- Working on Computer-vision ---\n",
      "\tWorking on Semi-supervised-video-classification\n",
      "\tSuccessfully loaded task semi-supervised-video-classification, with papers 2\n",
      "\n",
      "\tWorking on Activity-recognition\n",
      "\tSuccessfully loaded task activity-recognition, with papers 550\n",
      "\n",
      "\tWorking on Point-cloud-super-resolution\n",
      "\tSuccessfully loaded task point-cloud-super-resolution, with papers 7\n",
      "\n",
      "\tWorking on Video-retrieval\n",
      "\tSuccessfully loaded task video-retrieval, with papers 132\n",
      "\n",
      "\tWorking on Blind-image-quality-assessment\n",
      "\tSuccessfully loaded task blind-image-quality-assessment, with papers 26\n",
      "\n",
      "\tWorking on Self-driving-cars\n",
      "\tSuccessfully loaded task self-driving-cars, with papers 255\n",
      "\n",
      "\tWorking on Image-dehazing\n",
      "\tSuccessfully loaded task image-dehazing, with papers 106\n",
      "\n",
      "\tWorking on Camera-auto-calibration\n",
      "\tSuccessfully loaded task camera-auto-calibration, with papers 4\n",
      "\n",
      "\tWorking on Concurrent-activity-recognition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task concurrent-activity-recognition, with papers 2\n",
      "\n",
      "\tWorking on Object-skeleton-detection\n",
      "\tSuccessfully loaded task object-skeleton-detection, with papers 5\n",
      "\n",
      "\tWorking on Video-story-qa\n",
      "\tSuccessfully loaded task video-story-qa, with papers 3\n",
      "\n",
      "\tWorking on 3d-multi-person-pose-estimation-absolute\n",
      "\tSuccessfully loaded task 3d-multi-person-pose-estimation-absolute, with papers 5\n",
      "\n",
      "\tWorking on Sketch-based-image-retrieval\n",
      "\tSuccessfully loaded task sketch-based-image-retrieval, with papers 55\n",
      "\n",
      "\tWorking on Real-time-instance-segmentation\n",
      "\tSuccessfully loaded task real-time-instance-segmentation, with papers 13\n",
      "\n",
      "\tWorking on Rgb-d-salient-object-detection\n",
      "\tSuccessfully loaded task rgb-d-salient-object-detection, with papers 46\n",
      "\n",
      "\tWorking on 3d-object-reconstruction\n",
      "\tSuccessfully loaded task 3d-object-reconstruction, with papers 62\n",
      "\n",
      "\tWorking on Facial-expression-recognition\n",
      "\tSuccessfully loaded task facial-expression-recognition, with papers 243\n",
      "\n",
      "\tWorking on Visual-social-relationship-recognition\n",
      "\tSuccessfully loaded task visual-social-relationship-recognition, with papers 3\n",
      "\n",
      "\tWorking on 3d-part-segmentation\n",
      "\tSuccessfully loaded task 3d-part-segmentation, with papers 38\n",
      "\n",
      "\tWorking on Localization-in-video-forgery\n",
      "\tSuccessfully loaded task localization-in-video-forgery, with papers 2\n",
      "\n",
      "\tWorking on 3d-multi-person-pose-estimation-root-relative\n",
      "\tSuccessfully loaded task 3d-multi-person-pose-estimation-root-relative, with papers 6\n",
      "\n",
      "\tWorking on Image-generation\n",
      "\tSuccessfully loaded task image-generation, with papers 1311\n",
      "\n",
      "\tWorking on Video-compression\n",
      "\tSuccessfully loaded task video-compression, with papers 119\n",
      "\n",
      "\tWorking on Keypoint-detection\n",
      "\tSuccessfully loaded task keypoint-detection, with papers 127\n",
      "\n",
      "\tWorking on Object-detection-in-aerial-images\n",
      "\tSuccessfully loaded task object-detection-in-aerial-images, with papers 24\n",
      "\n",
      "\tWorking on Template-matching\n",
      "\tSuccessfully loaded task template-matching, with papers 129\n",
      "\n",
      "\tWorking on Loop-closure-detection\n",
      "\tSuccessfully loaded task loop-closure-detection, with papers 38\n",
      "\n",
      "\tWorking on Real-time-semantic-segmentation\n",
      "\tSuccessfully loaded task real-time-semantic-segmentation, with papers 76\n",
      "\n",
      "\tWorking on Autonomous-navigation\n",
      "\tSuccessfully loaded task autonomous-navigation, with papers 168\n",
      "\n",
      "\tWorking on Lane-detection\n",
      "\tSuccessfully loaded task lane-detection, with papers 77\n",
      "\n",
      "\tWorking on Sports-analytics\n",
      "\tSuccessfully loaded task sports-analytics, with papers 16\n",
      "\n",
      "\tWorking on Skeleton-based-action-recognition\n",
      "\tSuccessfully loaded task skeleton-based-action-recognition, with papers 197\n",
      "\n",
      "\tWorking on Scene-classification\n",
      "\tSuccessfully loaded task scene-classification, with papers 209\n",
      "\n",
      "\tWorking on Severity-prediction\n",
      "\tSuccessfully loaded task severity-prediction, with papers 15\n",
      "\n",
      "\tWorking on Pedestrian-attribute-recognition\n",
      "\tSuccessfully loaded task pedestrian-attribute-recognition, with papers 20\n",
      "\n",
      "\tWorking on Image-classification\n",
      "\tSuccessfully loaded task image-classification, with papers 4120\n",
      "\n",
      "\tWorking on Face-image-retrieval\n",
      "\tSuccessfully loaded task face-image-retrieval, with papers 8\n",
      "\n",
      "\tWorking on 3d-point-cloud-classification\n",
      "\tSuccessfully loaded task 3d-point-cloud-classification, with papers 48\n",
      "\n",
      "\tWorking on Face-age-editing\n",
      "\tSuccessfully loaded task face-age-editing, with papers 3\n",
      "\n",
      "\tWorking on Video-style-transfer\n",
      "\tSuccessfully loaded task video-style-transfer, with papers 15\n",
      "\n",
      "\tWorking on Video-denoising\n",
      "\tSuccessfully loaded task video-denoising, with papers 30\n",
      "\n",
      "\tWorking on Crowds\n",
      "\tSuccessfully loaded task crowds, with papers 0\n",
      "\n",
      "\tWorking on Temporal-localization\n",
      "\tSuccessfully loaded task temporal-localization, with papers 56\n",
      "\n",
      "\tWorking on Image-deconvolution\n",
      "\tSuccessfully loaded task image-deconvolution, with papers 47\n",
      "\n",
      "\tWorking on Video-restoration\n",
      "\tSuccessfully loaded task video-restoration, with papers 14\n",
      "\n",
      "\tWorking on Scene-flow-estimation\n",
      "\tSuccessfully loaded task scene-flow-estimation, with papers 49\n",
      "\n",
      "\tWorking on Weakly-supervised-3d-human-pose-estimation\n",
      "\tSuccessfully loaded task weakly-supervised-3d-human-pose-estimation, with papers 12\n",
      "\n",
      "\tWorking on Video-understanding\n",
      "\tSuccessfully loaded task video-understanding, with papers 207\n",
      "\n",
      "\tWorking on One-shot-segmentation\n",
      "\tSuccessfully loaded task one-shot-segmentation, with papers 9\n",
      "\n",
      "\tWorking on Person-identification\n",
      "\tSuccessfully loaded task person-identification, with papers 51\n",
      "\n",
      "--- Working on Graphs ---\n",
      "\tWorking on Structural-node-embedding\n",
      "\tSuccessfully loaded task structural-node-embedding, with papers 2\n",
      "\n",
      "\tWorking on Graphon-estimation\n",
      "\tSuccessfully loaded task graphon-estimation, with papers 14\n",
      "\n",
      "\tWorking on Physics-informed-machine-learning\n",
      "\tSuccessfully loaded task physics-informed-machine-learning, with papers 20\n",
      "\n",
      "\tWorking on Knowledge-graph-embeddings\n",
      "\tSuccessfully loaded task knowledge-graph-embeddings, with papers 95\n",
      "\n",
      "\tWorking on Node-classification\n",
      "\tSuccessfully loaded task node-classification, with papers 549\n",
      "\n",
      "\tWorking on Graph-matching\n",
      "\tSuccessfully loaded task graph-matching, with papers 231\n",
      "\n",
      "\tWorking on Graph-clustering\n",
      "\tSuccessfully loaded task graph-clustering, with papers 175\n",
      "\n",
      "\tWorking on Role-embedding\n",
      "\tSuccessfully loaded task role-embedding, with papers 2\n",
      "\n",
      "\tWorking on Gene-interaction-prediction\n",
      "\tSuccessfully loaded task gene-interaction-prediction, with papers 1\n",
      "\n",
      "\tWorking on Heterogeneous-node-classification\n",
      "\tSuccessfully loaded task heterogeneous-node-classification, with papers 5\n",
      "\n",
      "\tWorking on Graph-construction\n",
      "\tSuccessfully loaded task graph-construction, with papers 155\n",
      "\n",
      "\tWorking on Online-community-detection\n",
      "\tSuccessfully loaded task online-community-detection, with papers 5\n",
      "\n",
      "\tWorking on Graph-sampling\n",
      "\tSuccessfully loaded task graph-sampling, with papers 35\n",
      "\n",
      "\tWorking on Md17\n",
      "\tSuccessfully loaded task md17, with papers 5\n",
      "\n",
      "\tWorking on Link-prediction\n",
      "\tSuccessfully loaded task link-prediction, with papers 804\n",
      "\n",
      "\tWorking on Triad-prediction\n",
      "\tSuccessfully loaded task triad-prediction, with papers 1\n",
      "\n",
      "\tWorking on Graph-to-graph-translation\n",
      "\tSuccessfully loaded task graph-to-graph-translation, with papers 4\n",
      "\n",
      "\tWorking on Hypergraph-partitioning\n",
      "\tSuccessfully loaded task hypergraph-partitioning, with papers 17\n",
      "\n",
      "\tWorking on Collaborative-ranking\n",
      "\tSuccessfully loaded task collaborative-ranking, with papers 21\n",
      "\n",
      "\tWorking on Knowledge-base-completion\n",
      "\tSuccessfully loaded task knowledge-base-completion, with papers 116\n",
      "\n",
      "\tWorking on Graph-generation\n",
      "\tSuccessfully loaded task graph-generation, with papers 153\n",
      "\n",
      "\tWorking on Learning-to-rank\n",
      "\tSuccessfully loaded task learning-to-rank, with papers 412\n",
      "\n",
      "\tWorking on Graph-ranking\n",
      "\tSuccessfully loaded task graph-ranking, with papers 9\n",
      "\n",
      "\tWorking on Community-detection\n",
      "\tSuccessfully loaded task community-detection, with papers 526\n",
      "\n",
      "\tWorking on Graph-partitioning\n",
      "\tSuccessfully loaded task graph-partitioning, with papers 111\n",
      "\n",
      "\tWorking on Nmr-j-coupling\n",
      "\tSuccessfully loaded task nmr-j-coupling, with papers 1\n",
      "\n",
      "\tWorking on Graph-reconstruction\n",
      "\tSuccessfully loaded task graph-reconstruction, with papers 23\n",
      "\n",
      "\tWorking on Spectral-graph-clustering\n",
      "\tSuccessfully loaded task spectral-graph-clustering, with papers 15\n",
      "\n",
      "\tWorking on Hypergraph-matching\n",
      "\tSuccessfully loaded task hypergraph-matching, with papers 9\n",
      "\n",
      "\tWorking on Dynamic-graph-embedding\n",
      "\tSuccessfully loaded task dynamic-graph-embedding, with papers 9\n",
      "\n",
      "\tWorking on Hyperedge-classification\n",
      "\tSuccessfully loaded task hyperedge-classification, with papers 2\n",
      "\n",
      "\tWorking on Graph-learning\n",
      "\tSuccessfully loaded task graph-learning, with papers 261\n",
      "\n",
      "\tWorking on Network-community-partition\n",
      "\tSuccessfully loaded task network-community-partition, with papers 2\n",
      "\n",
      "\tWorking on Graph-similarity\n",
      "\tSuccessfully loaded task graph-similarity, with papers 56\n",
      "\n",
      "\tWorking on Graph-classification\n",
      "\tSuccessfully loaded task graph-classification, with papers 341\n",
      "\n",
      "\tWorking on Anchor-link-prediction\n",
      "\tSuccessfully loaded task anchor-link-prediction, with papers 4\n",
      "\n",
      "\tWorking on Topological-data-analysis\n",
      "\tSuccessfully loaded task topological-data-analysis, with papers 166\n",
      "\n",
      "\tWorking on Calibration-for-link-prediction\n",
      "\tSuccessfully loaded task calibration-for-link-prediction, with papers 1\n",
      "\n",
      "\tWorking on Connectivity-estimation\n",
      "\tSuccessfully loaded task connectivity-estimation, with papers 7\n",
      "\n",
      "\tWorking on Graph-embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task graph-embedding, with papers 505\n",
      "\n",
      "\tWorking on Dynamic-link-prediction\n",
      "\tSuccessfully loaded task dynamic-link-prediction, with papers 9\n",
      "\n",
      "\tWorking on Graph-regression\n",
      "\tSuccessfully loaded task graph-regression, with papers 44\n",
      "\n",
      "\tWorking on Local-community-detection\n",
      "\tSuccessfully loaded task local-community-detection, with papers 5\n",
      "\n",
      "\tWorking on Link-sign-prediction\n",
      "\tSuccessfully loaded task link-sign-prediction, with papers 3\n",
      "\n",
      "\tWorking on Graph-mining\n",
      "\tSuccessfully loaded task graph-mining, with papers 57\n",
      "\n",
      "\tWorking on Hypergraph-embedding\n",
      "\tSuccessfully loaded task hypergraph-embedding, with papers 4\n",
      "\n",
      "\tWorking on Knowledge-graph-embedding\n",
      "\tSuccessfully loaded task knowledge-graph-embedding, with papers 162\n",
      "\n",
      "--- Working on Knowledge-base ---\n",
      "\tWorking on Temporal-knowledge-graph-completion\n",
      "\tSuccessfully loaded task temporal-knowledge-graph-completion, with papers 9\n",
      "\n",
      "\tWorking on Open-knowledge-graph-embedding\n",
      "\tSuccessfully loaded task open-knowledge-graph-embedding, with papers 1\n",
      "\n",
      "\tWorking on Open-knowledge-graph-canonicalization\n",
      "\tSuccessfully loaded task open-knowledge-graph-canonicalization, with papers 1\n",
      "\n",
      "\tWorking on Breast-cancer-detection\n",
      "\tSuccessfully loaded task breast-cancer-detection, with papers 38\n",
      "\n",
      "\tWorking on Inductive-knowledge-graph-completion\n",
      "\tSuccessfully loaded task inductive-knowledge-graph-completion, with papers 7\n",
      "\n",
      "\tWorking on Knowledge-graphs-data-curation\n",
      "\tSuccessfully loaded task knowledge-graphs-data-curation, with papers 1\n",
      "\n",
      "\tWorking on Table-to-knowledge-graph-matching\n",
      "\tSuccessfully loaded task table-to-knowledge-graph-matching, with papers 2\n",
      "\n",
      "\tWorking on Causal-discovery\n",
      "\tSuccessfully loaded task causal-discovery, with papers 162\n",
      "\n",
      "\tWorking on Entity-alignment\n",
      "\tSuccessfully loaded task entity-alignment, with papers 51\n",
      "\n",
      "\tWorking on Knowledge-base\n",
      "\tSuccessfully loaded task knowledge-base, with papers 0\n",
      "\n",
      "\tWorking on Relational-pattern-learning\n",
      "\tSuccessfully loaded task relational-pattern-learning, with papers 1\n",
      "\n",
      "\tWorking on Knowledge-graph-completion\n",
      "\tSuccessfully loaded task knowledge-graph-completion, with papers 141\n",
      "\n",
      "\tWorking on Open-knowledge-base-completion\n",
      "\tSuccessfully loaded task open-knowledge-base-completion, with papers 1\n",
      "\n",
      "\tWorking on Multi-hop-question-answering\n",
      "\tSuccessfully loaded task multi-hop-question-answering, with papers 40\n",
      "\n",
      "\tWorking on Cross-lingual-sememe-prediction\n",
      "\tSuccessfully loaded task cross-lingual-sememe-prediction, with papers 1\n",
      "\n",
      "\tWorking on Knowledge-base-completion\n",
      "\tSuccessfully loaded task knowledge-base-completion, with papers 116\n",
      "\n",
      "\tWorking on Rdf-dataset-discovery\n",
      "\tSuccessfully loaded task rdf-dataset-discovery, with papers 2\n",
      "\n",
      "\tWorking on Knowledge-graphs\n",
      "\tSuccessfully loaded task knowledge-graphs, with papers 788\n",
      "\n",
      "\tWorking on Non-intrusive-load-monitoring\n",
      "\tSuccessfully loaded task non-intrusive-load-monitoring, with papers 33\n",
      "\n",
      "\tWorking on Research-knowledge-graph-population\n",
      "\tSuccessfully loaded task research-knowledge-graph-population, with papers 1\n",
      "\n",
      "\tWorking on Commonsense-knowledge-base-construction\n",
      "\tSuccessfully loaded task commonsense-knowledge-base-construction, with papers 1\n",
      "\n",
      "--- Working on Medical ---\n",
      "\tWorking on Molecule-interpretation\n",
      "\tSuccessfully loaded task molecule-interpretation, with papers 1\n",
      "\n",
      "\tWorking on Whole-mammogram-classification\n",
      "\tSuccessfully loaded task whole-mammogram-classification, with papers 3\n",
      "\n",
      "\tWorking on Eeg-decoding\n",
      "\tSuccessfully loaded task eeg-decoding, with papers 13\n",
      "\n",
      "\tWorking on Acute-stroke-lesion-segmentation\n",
      "\tSuccessfully loaded task acute-stroke-lesion-segmentation, with papers 1\n",
      "\n",
      "\tWorking on Skin-cancer-classification\n",
      "\tSuccessfully loaded task skin-cancer-classification, with papers 19\n",
      "\n",
      "\tWorking on Skin-lesion-classification\n",
      "\tSuccessfully loaded task skin-lesion-classification, with papers 48\n",
      "\n",
      "\tWorking on Epilepsy-prediction\n",
      "\tSuccessfully loaded task epilepsy-prediction, with papers 2\n",
      "\n",
      "\tWorking on Synthetic-data-generation\n",
      "\tSuccessfully loaded task synthetic-data-generation, with papers 86\n",
      "\n",
      "\tWorking on Mitosis-detection\n",
      "\tSuccessfully loaded task mitosis-detection, with papers 19\n",
      "\n",
      "\tWorking on Heartbeat-classification\n",
      "\tSuccessfully loaded task heartbeat-classification, with papers 15\n",
      "\n",
      "\tWorking on Spindle-detection\n",
      "\tSuccessfully loaded task spindle-detection, with papers 5\n",
      "\n",
      "\tWorking on Registration-of-sparse-clinical-images\n",
      "\tSuccessfully loaded task registration-of-sparse-clinical-images, with papers 1\n",
      "\n",
      "\tWorking on Ecg-risk-stratification\n",
      "\tSuccessfully loaded task ecg-risk-stratification, with papers 2\n",
      "\n",
      "\tWorking on Multi-diseases-detection\n",
      "\tSuccessfully loaded task multi-diseases-detection, with papers 0\n",
      "\n",
      "\tWorking on Liver-segmentation\n",
      "\tSuccessfully loaded task liver-segmentation, with papers 46\n",
      "\n",
      "\tWorking on Arrhythmia-detection\n",
      "\tSuccessfully loaded task arrhythmia-detection, with papers 32\n",
      "\n",
      "\tWorking on Pulse-wave-simulation\n",
      "\tSuccessfully loaded task pulse-wave-simulation, with papers 1\n",
      "\n",
      "\tWorking on Seizure-detection\n",
      "\tSuccessfully loaded task seizure-detection, with papers 54\n",
      "\n",
      "\tWorking on Chemical-reaction-prediction\n",
      "\tSuccessfully loaded task chemical-reaction-prediction, with papers 3\n",
      "\n",
      "\tWorking on Protein-secondary-structure-prediction\n",
      "\tSuccessfully loaded task protein-secondary-structure-prediction, with papers 16\n",
      "\n",
      "\tWorking on Qrs-complex-detection\n",
      "\tSuccessfully loaded task qrs-complex-detection, with papers 4\n",
      "\n",
      "\tWorking on Semantic-segmentation-of-orthoimagery\n",
      "\tSuccessfully loaded task semantic-segmentation-of-orthoimagery, with papers 1\n",
      "\n",
      "\tWorking on Participant-intervention-comparison-outcome\n",
      "\tSuccessfully loaded task participant-intervention-comparison-outcome, with papers 2\n",
      "\n",
      "\tWorking on Disease-trajectory-forecasting\n",
      "\tSuccessfully loaded task disease-trajectory-forecasting, with papers 3\n",
      "\n",
      "\tWorking on Bone-suppression-from-dual-energy-chest-x\n",
      "\tSuccessfully loaded task bone-suppression-from-dual-energy-chest-x, with papers 1\n",
      "\n",
      "\tWorking on Molecular-dynamics\n",
      "\tSuccessfully loaded task molecular-dynamics, with papers 0\n",
      "\n",
      "\tWorking on White-matter-fiber-tractography\n",
      "\tSuccessfully loaded task white-matter-fiber-tractography, with papers 1\n",
      "\n",
      "\tWorking on Atrial-fibrillation-detection\n",
      "\tSuccessfully loaded task atrial-fibrillation-detection, with papers 16\n",
      "\n",
      "\tWorking on Mapping-of-lung-nodules-in-low-dose-ct-images\n",
      "\tSuccessfully loaded task mapping-of-lung-nodules-in-low-dose-ct-images, with papers 1\n",
      "\n",
      "\tWorking on Pneumonia-detection\n",
      "\tSuccessfully loaded task pneumonia-detection, with papers 19\n",
      "\n",
      "\tWorking on Outcome-prediction-in-multimodal-mri\n",
      "\tSuccessfully loaded task outcome-prediction-in-multimodal-mri, with papers 1\n",
      "\n",
      "\tWorking on Malaria-risk-exposure-prediction\n",
      "\tSuccessfully loaded task malaria-risk-exposure-prediction, with papers 2\n",
      "\n",
      "\tWorking on Automated-pancreas-segmentation\n",
      "\tSuccessfully loaded task automated-pancreas-segmentation, with papers 6\n",
      "\n",
      "\tWorking on Brain-image-segmentation\n",
      "\tSuccessfully loaded task brain-image-segmentation, with papers 17\n",
      "\n",
      "\tWorking on Ultrasound\n",
      "\tSuccessfully loaded task ultrasound, with papers 1\n",
      "\n",
      "\tWorking on Cardiac-segmentation\n",
      "\tSuccessfully loaded task cardiac-segmentation, with papers 39\n",
      "\n",
      "\tWorking on Medical-code-prediction\n",
      "\tSuccessfully loaded task medical-code-prediction, with papers 4\n",
      "\n",
      "\tWorking on Medical-super-resolution\n",
      "\tSuccessfully loaded task medical-super-resolution, with papers 1\n",
      "\n",
      "\tWorking on Nuclear-segmentation\n",
      "\tSuccessfully loaded task nuclear-segmentation, with papers 15\n",
      "\n",
      "\tWorking on Lung-cancer-diagnosis\n",
      "\tSuccessfully loaded task lung-cancer-diagnosis, with papers 21\n",
      "\n",
      "\tWorking on Breast-cancer-detection\n",
      "\tSuccessfully loaded task breast-cancer-detection, with papers 38\n",
      "\n",
      "\tWorking on X-ray\n",
      "\tSuccessfully loaded task x-ray, with papers 0\n",
      "\n",
      "\tWorking on Mass-segmentation-from-mammograms\n",
      "\tSuccessfully loaded task mass-segmentation-from-mammograms, with papers 2\n",
      "\n",
      "\tWorking on Photoplethysmogram-simulation\n",
      "\tSuccessfully loaded task photoplethysmogram-simulation, with papers 0\n",
      "\n",
      "\tWorking on Pulmonary-embolism-detection\n",
      "\tSuccessfully loaded task pulmonary-embolism-detection, with papers 2\n",
      "\n",
      "\tWorking on Seizure-prediction\n",
      "\tSuccessfully loaded task seizure-prediction, with papers 20\n",
      "\n",
      "\tWorking on Skin-lesion-identification\n",
      "\tSuccessfully loaded task skin-lesion-identification, with papers 2\n",
      "\n",
      "\tWorking on Oral-cancer-classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task oral-cancer-classification, with papers 2\n",
      "\n",
      "\tWorking on Diabetic-retinopathy-grading\n",
      "\tSuccessfully loaded task diabetic-retinopathy-grading, with papers 14\n",
      "\n",
      "\tWorking on Cell-segmentation\n",
      "\tSuccessfully loaded task cell-segmentation, with papers 60\n",
      "\n",
      "--- Working on Methodology ---\n",
      "\tWorking on Quantization\n",
      "\tSuccessfully loaded task quantization, with papers 1479\n",
      "\n",
      "\tWorking on Partial-domain-adaptation\n",
      "\tSuccessfully loaded task partial-domain-adaptation, with papers 29\n",
      "\n",
      "\tWorking on Continual-learning\n",
      "\tSuccessfully loaded task continual-learning, with papers 485\n",
      "\n",
      "\tWorking on Stroke-classification\n",
      "\tSuccessfully loaded task stroke-classification, with papers 3\n",
      "\n",
      "\tWorking on Feature-engineering\n",
      "\tSuccessfully loaded task feature-engineering, with papers 947\n",
      "\n",
      "\tWorking on Network-embedding\n",
      "\tSuccessfully loaded task network-embedding, with papers 253\n",
      "\n",
      "\tWorking on Document-embedding\n",
      "\tSuccessfully loaded task document-embedding, with papers 42\n",
      "\n",
      "\tWorking on Sentence-embeddings-for-biomedical-texts\n",
      "\tSuccessfully loaded task sentence-embeddings-for-biomedical-texts, with papers 2\n",
      "\n",
      "\tWorking on Policy-gradient-methods\n",
      "\tSuccessfully loaded task policy-gradient-methods, with papers 168\n",
      "\n",
      "\tWorking on Core-set-discovery\n",
      "\tSuccessfully loaded task core-set-discovery, with papers 1\n",
      "\n",
      "\tWorking on Metric-learning\n",
      "\tSuccessfully loaded task metric-learning, with papers 904\n",
      "\n",
      "\tWorking on Arbitrary-conditional-density-estimation\n",
      "\tSuccessfully loaded task arbitrary-conditional-density-estimation, with papers 1\n",
      "\n",
      "\tWorking on Model-selection\n",
      "\tSuccessfully loaded task model-selection, with papers 855\n",
      "\n",
      "\tWorking on Domain-generalization\n",
      "\tSuccessfully loaded task domain-generalization, with papers 229\n",
      "\n",
      "\tWorking on Probabilistic-programming\n",
      "\tSuccessfully loaded task probabilistic-programming, with papers 172\n",
      "\n",
      "\tWorking on Gaussian-processes\n",
      "\tSuccessfully loaded task gaussian-processes, with papers 976\n",
      "\n",
      "\tWorking on Structured-prediction\n",
      "\tSuccessfully loaded task structured-prediction, with papers 503\n",
      "\n",
      "\tWorking on Information-plane\n",
      "\tSuccessfully loaded task information-plane, with papers 17\n",
      "\n",
      "\tWorking on Unsupervised-domain-expansion\n",
      "\tSuccessfully loaded task unsupervised-domain-expansion, with papers 2\n",
      "\n",
      "\tWorking on Federated-learning\n",
      "\tSuccessfully loaded task federated-learning, with papers 952\n",
      "\n",
      "\tWorking on Word-embeddings\n",
      "\tSuccessfully loaded task word-embeddings, with papers 2150\n",
      "\n",
      "\tWorking on Quantum-machine-learning\n",
      "\tSuccessfully loaded task quantum-machine-learning, with papers 126\n",
      "\n",
      "\tWorking on Graph-representation-learning\n",
      "\tSuccessfully loaded task graph-representation-learning, with papers 208\n",
      "\n",
      "\tWorking on Latent-variable-models\n",
      "\tSuccessfully loaded task latent-variable-models, with papers 406\n",
      "\n",
      "\tWorking on Anomaly-detection\n",
      "\tSuccessfully loaded task anomaly-detection, with papers 1350\n",
      "\n",
      "\tWorking on Multi-label-learning\n",
      "\tSuccessfully loaded task multi-label-learning, with papers 163\n",
      "\n",
      "\tWorking on Abnormal-event-detection-in-video\n",
      "\tSuccessfully loaded task abnormal-event-detection-in-video, with papers 12\n",
      "\n",
      "\tWorking on Few-shot-learning\n",
      "\tSuccessfully loaded task few-shot-learning, with papers 767\n",
      "\n",
      "\tWorking on Anomaly-detection-in-surveillance-videos\n",
      "\tSuccessfully loaded task anomaly-detection-in-surveillance-videos, with papers 16\n",
      "\n",
      "\tWorking on Learning-semantic-representations\n",
      "\tSuccessfully loaded task learning-semantic-representations, with papers 21\n",
      "\n",
      "\tWorking on Efficient-exploration\n",
      "\tSuccessfully loaded task efficient-exploration, with papers 183\n",
      "\n",
      "\tWorking on L2-regularization\n",
      "\tSuccessfully loaded task l2-regularization, with papers 68\n",
      "\n",
      "\tWorking on Global-optimization\n",
      "\tSuccessfully loaded task global-optimization, with papers 331\n",
      "\n",
      "\tWorking on Automl\n",
      "\tSuccessfully loaded task automl, with papers 226\n",
      "\n",
      "\tWorking on Network-pruning\n",
      "\tSuccessfully loaded task network-pruning, with papers 208\n",
      "\n",
      "\tWorking on Feature-importance\n",
      "\tSuccessfully loaded task feature-importance, with papers 225\n",
      "\n",
      "\tWorking on Learning-representation-on-graph\n",
      "\tSuccessfully loaded task learning-representation-on-graph, with papers 1\n",
      "\n",
      "\tWorking on Auxiliary-learning\n",
      "\tSuccessfully loaded task auxiliary-learning, with papers 28\n",
      "\n",
      "\tWorking on Model-extraction\n",
      "\tSuccessfully loaded task model-extraction, with papers 45\n",
      "\n",
      "\tWorking on Zero-shot-learning\n",
      "\tSuccessfully loaded task zero-shot-learning, with papers 556\n",
      "\n",
      "\tWorking on Data-augmentation\n",
      "\tSuccessfully loaded task data-augmentation, with papers 2271\n",
      "\n",
      "\tWorking on Ticket-search\n",
      "\tSuccessfully loaded task ticket-search, with papers 1\n",
      "\n",
      "\tWorking on Computed-tomography-ct\n",
      "\tSuccessfully loaded task computed-tomography-ct, with papers 496\n",
      "\n",
      "\tWorking on Electrocardiography-ecg\n",
      "\tSuccessfully loaded task electrocardiography-ecg, with papers 54\n",
      "\n",
      "\tWorking on Sparse-learning\n",
      "\tSuccessfully loaded task sparse-learning, with papers 109\n",
      "\n",
      "\tWorking on Personalized-federated-learning\n",
      "\tSuccessfully loaded task personalized-federated-learning, with papers 17\n",
      "\n",
      "\tWorking on Dimensionality-reduction\n",
      "\tSuccessfully loaded task dimensionality-reduction, with papers 1626\n",
      "\n",
      "\tWorking on Few-shot-image-classification\n",
      "\tSuccessfully loaded task few-shot-image-classification, with papers 131\n",
      "\n",
      "\tWorking on Few-shot-camera-adaptive-color-constancy\n",
      "\tSuccessfully loaded task few-shot-camera-adaptive-color-constancy, with papers 1\n",
      "\n",
      "\tWorking on Unsupervised-domain-adaptation\n",
      "\tSuccessfully loaded task unsupervised-domain-adaptation, with papers 671\n",
      "\n",
      "--- Working on Miscellaneous ---\n",
      "\tWorking on Making-hiring-decisions\n",
      "\tSuccessfully loaded task making-hiring-decisions, with papers 0\n",
      "\n",
      "\tWorking on Seismic-interpretation\n",
      "\tSuccessfully loaded task seismic-interpretation, with papers 12\n",
      "\n",
      "\tWorking on Continual-learning\n",
      "\tSuccessfully loaded task continual-learning, with papers 485\n",
      "\n",
      "\tWorking on Traffic-classification\n",
      "\tSuccessfully loaded task traffic-classification, with papers 26\n",
      "\n",
      "\tWorking on Product-categorization\n",
      "\tSuccessfully loaded task product-categorization, with papers 17\n",
      "\n",
      "\tWorking on Multi-armed-bandits\n",
      "\tSuccessfully loaded task multi-armed-bandits, with papers 512\n",
      "\n",
      "\tWorking on Synthetic-data-generation\n",
      "\tSuccessfully loaded task synthetic-data-generation, with papers 86\n",
      "\n",
      "\tWorking on Fault-detection\n",
      "\tSuccessfully loaded task fault-detection, with papers 111\n",
      "\n",
      "\tWorking on Detecting-adverts\n",
      "\tSuccessfully loaded task detecting-adverts, with papers 1\n",
      "\n",
      "\tWorking on Crime-prediction\n",
      "\tSuccessfully loaded task crime-prediction, with papers 17\n",
      "\n",
      "\tWorking on Sensor-fusion\n",
      "\tSuccessfully loaded task sensor-fusion, with papers 147\n",
      "\n",
      "\tWorking on Automated-theorem-proving\n",
      "\tSuccessfully loaded task automated-theorem-proving, with papers 110\n",
      "\n",
      "\tWorking on Business-taxonomy-construction\n",
      "\tSuccessfully loaded task business-taxonomy-construction, with papers 1\n",
      "\n",
      "\tWorking on Md17\n",
      "\tSuccessfully loaded task md17, with papers 5\n",
      "\n",
      "\tWorking on Social-media-popularity-prediction\n",
      "\tSuccessfully loaded task social-media-popularity-prediction, with papers 0\n",
      "\n",
      "\tWorking on Vulnerability-detection\n",
      "\tSuccessfully loaded task vulnerability-detection, with papers 22\n",
      "\n",
      "\tWorking on Physical-simulations\n",
      "\tSuccessfully loaded task physical-simulations, with papers 25\n",
      "\n",
      "\tWorking on Stress-strain-relation\n",
      "\tSuccessfully loaded task stress-strain-relation, with papers 6\n",
      "\n",
      "\tWorking on Air-pollution-prediction\n",
      "\tSuccessfully loaded task air-pollution-prediction, with papers 5\n",
      "\n",
      "\tWorking on Counterfactual-inference\n",
      "\tSuccessfully loaded task counterfactual-inference, with papers 33\n",
      "\n",
      "\tWorking on Cantilever-beam\n",
      "\tSuccessfully loaded task cantilever-beam, with papers 5\n",
      "\n",
      "\tWorking on Crowd-flows-prediction\n",
      "\tSuccessfully loaded task crowd-flows-prediction, with papers 1\n",
      "\n",
      "\tWorking on Mathematical-proofs\n",
      "\tSuccessfully loaded task mathematical-proofs, with papers 18\n",
      "\n",
      "\tWorking on Imbalanced-classification\n",
      "\tSuccessfully loaded task imbalanced-classification, with papers 65\n",
      "\n",
      "\tWorking on Artificial-life\n",
      "\tSuccessfully loaded task artificial-life, with papers 55\n",
      "\n",
      "\tWorking on Deep-clustering\n",
      "\tSuccessfully loaded task deep-clustering, with papers 112\n",
      "\n",
      "\tWorking on Data-summarization\n",
      "\tSuccessfully loaded task data-summarization, with papers 61\n",
      "\n",
      "\tWorking on Problem-decomposition\n",
      "\tSuccessfully loaded task problem-decomposition, with papers 14\n",
      "\n",
      "\tWorking on Gravitational-wave-detection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task gravitational-wave-detection, with papers 11\n",
      "\n",
      "\tWorking on Android-malware-detection\n",
      "\tSuccessfully loaded task android-malware-detection, with papers 31\n",
      "\n",
      "\tWorking on Data-visualization\n",
      "\tSuccessfully loaded task data-visualization, with papers 121\n",
      "\n",
      "\tWorking on Sequential-correlation-estimation\n",
      "\tSuccessfully loaded task sequential-correlation-estimation, with papers 2\n",
      "\n",
      "\tWorking on Mobile-security\n",
      "\tSuccessfully loaded task mobile-security, with papers 9\n",
      "\n",
      "\tWorking on Oceanic-eddy-classification\n",
      "\tSuccessfully loaded task oceanic-eddy-classification, with papers 1\n",
      "\n",
      "\tWorking on Outdoor-positioning\n",
      "\tSuccessfully loaded task outdoor-positioning, with papers 3\n",
      "\n",
      "\tWorking on Remote-sensing\n",
      "\tSuccessfully loaded task remote-sensing, with papers 0\n",
      "\n",
      "\tWorking on Multi-modal-person-identification\n",
      "\tSuccessfully loaded task multi-modal-person-identification, with papers 2\n",
      "\n",
      "\tWorking on Network-intrusion-detection\n",
      "\tSuccessfully loaded task network-intrusion-detection, with papers 79\n",
      "\n",
      "\tWorking on Crop-classification\n",
      "\tSuccessfully loaded task crop-classification, with papers 13\n",
      "\n",
      "\tWorking on Lake-ice-detection\n",
      "\tSuccessfully loaded task lake-ice-detection, with papers 5\n",
      "\n",
      "\tWorking on Recipe-generation\n",
      "\tSuccessfully loaded task recipe-generation, with papers 11\n",
      "\n",
      "\tWorking on Pulsar-prediction\n",
      "\tSuccessfully loaded task pulsar-prediction, with papers 1\n",
      "\n",
      "\tWorking on Time-offset-calibration\n",
      "\tSuccessfully loaded task time-offset-calibration, with papers 1\n",
      "\n",
      "\tWorking on Jsoniq-query-execution\n",
      "\tSuccessfully loaded task jsoniq-query-execution, with papers 1\n",
      "\n",
      "\tWorking on Behavioral-malware-detection\n",
      "\tSuccessfully loaded task behavioral-malware-detection, with papers 2\n",
      "\n",
      "\tWorking on Sequential-distribution-function-estimation\n",
      "\tSuccessfully loaded task sequential-distribution-function-estimation, with papers 1\n",
      "\n",
      "\tWorking on Cross-modal-retrieval\n",
      "\tSuccessfully loaded task cross-modal-retrieval, with papers 157\n",
      "\n",
      "\tWorking on The-semantic-segmentation-of-remote-sensing\n",
      "\tSuccessfully loaded task the-semantic-segmentation-of-remote-sensing, with papers 6\n",
      "\n",
      "\tWorking on Deception-detection-in-videos\n",
      "\tSuccessfully loaded task deception-detection-in-videos, with papers 3\n",
      "\n",
      "\tWorking on Gender-bias-detection\n",
      "\tSuccessfully loaded task gender-bias-detection, with papers 2\n",
      "\n",
      "--- Working on Music ---\n",
      "\tWorking on Cover-song-identification\n",
      "\tSuccessfully loaded task cover-song-identification, with papers 9\n",
      "\n",
      "\tWorking on Music-emotion-recognition\n",
      "\tSuccessfully loaded task music-emotion-recognition, with papers 14\n",
      "\n",
      "\tWorking on Music-generation\n",
      "\tSuccessfully loaded task music-generation, with papers 99\n",
      "\n",
      "\tWorking on Recognizing-seven-different-dastgahs-of\n",
      "\tSuccessfully loaded task recognizing-seven-different-dastgahs-of, with papers 1\n",
      "\n",
      "\tWorking on Music-classification\n",
      "\tSuccessfully loaded task music-classification, with papers 23\n",
      "\n",
      "\tWorking on Music-auto-tagging\n",
      "\tSuccessfully loaded task music-auto-tagging, with papers 10\n",
      "\n",
      "\tWorking on Piano-music-modeling\n",
      "\tSuccessfully loaded task piano-music-modeling, with papers 1\n",
      "\n",
      "\tWorking on Music-texture-transfer\n",
      "\tSuccessfully loaded task music-texture-transfer, with papers 1\n",
      "\n",
      "\tWorking on Music-genre-recognition\n",
      "\tSuccessfully loaded task music-genre-recognition, with papers 7\n",
      "\n",
      "\tWorking on Drum-transcription\n",
      "\tSuccessfully loaded task drum-transcription, with papers 4\n",
      "\n",
      "\tWorking on Detection-of-instrumentals-musical-tracks\n",
      "\tSuccessfully loaded task detection-of-instrumentals-musical-tracks, with papers 0\n",
      "\n",
      "\tWorking on Music-source-separation\n",
      "\tSuccessfully loaded task music-source-separation, with papers 44\n",
      "\n",
      "\tWorking on Music-transcription\n",
      "\tSuccessfully loaded task music-transcription, with papers 33\n",
      "\n",
      "\tWorking on Melody-extraction\n",
      "\tSuccessfully loaded task melody-extraction, with papers 2\n",
      "\n",
      "\tWorking on Music-information-retrieval\n",
      "\tSuccessfully loaded task music-information-retrieval, with papers 95\n",
      "\n",
      "\tWorking on Music-modeling\n",
      "\tSuccessfully loaded task music-modeling, with papers 23\n",
      "\n",
      "--- Working on Natural-language-processing ---\n",
      "\tWorking on Intent-classification\n",
      "\tSuccessfully loaded task intent-classification, with papers 109\n",
      "\n",
      "\tWorking on Text-classification\n",
      "\tSuccessfully loaded task text-classification, with papers 1050\n",
      "\n",
      "\tWorking on Multi-labeled-relation-extraction\n",
      "\tSuccessfully loaded task multi-labeled-relation-extraction, with papers 1\n",
      "\n",
      "\tWorking on Bridging-anaphora-resolution\n",
      "\tSuccessfully loaded task bridging-anaphora-resolution, with papers 7\n",
      "\n",
      "\tWorking on Hope-speech-detection\n",
      "\tSuccessfully loaded task hope-speech-detection, with papers 6\n",
      "\n",
      "\tWorking on Counterspeech-detection\n",
      "\tSuccessfully loaded task counterspeech-detection, with papers 0\n",
      "\n",
      "\tWorking on Clinical-assertion-status-detection\n",
      "\tSuccessfully loaded task clinical-assertion-status-detection, with papers 1\n",
      "\n",
      "\tWorking on Csc\n",
      "\tSuccessfully loaded task csc, with papers 2\n",
      "\n",
      "\tWorking on Temporal-information-extraction\n",
      "\tSuccessfully loaded task temporal-information-extraction, with papers 71\n",
      "\n",
      "\tWorking on Question-similarity\n",
      "\tSuccessfully loaded task question-similarity, with papers 47\n",
      "\n",
      "\tWorking on Hate-speech-detection\n",
      "\tSuccessfully loaded task hate-speech-detection, with papers 132\n",
      "\n",
      "\tWorking on Hope-speech-detection-for-english\n",
      "\tSuccessfully loaded task hope-speech-detection-for-english, with papers 2\n",
      "\n",
      "\tWorking on Cross-lingual-bitext-mining\n",
      "\tSuccessfully loaded task cross-lingual-bitext-mining, with papers 4\n",
      "\n",
      "\tWorking on Abstract-argumentation\n",
      "\tSuccessfully loaded task abstract-argumentation, with papers 87\n",
      "\n",
      "\tWorking on Table-search\n",
      "\tSuccessfully loaded task table-search, with papers 5\n",
      "\n",
      "\tWorking on Hope-speech-detection-for-tamil\n",
      "\tSuccessfully loaded task hope-speech-detection-for-tamil, with papers 2\n",
      "\n",
      "\tWorking on Arabic-text-diacritization\n",
      "\tSuccessfully loaded task arabic-text-diacritization, with papers 7\n",
      "\n",
      "\tWorking on Sentence-classification\n",
      "\tSuccessfully loaded task sentence-classification, with papers 176\n",
      "\n",
      "\tWorking on Sentence-embeddings-for-biomedical-texts\n",
      "\tSuccessfully loaded task sentence-embeddings-for-biomedical-texts, with papers 2\n",
      "\n",
      "\tWorking on Multimodal-machine-translation\n",
      "\tSuccessfully loaded task multimodal-machine-translation, with papers 58\n",
      "\n",
      "\tWorking on Hope-speech-detection-for-malayalam\n",
      "\tSuccessfully loaded task hope-speech-detection-for-malayalam, with papers 2\n",
      "\n",
      "\tWorking on Propaganda-span-identification\n",
      "\tSuccessfully loaded task propaganda-span-identification, with papers 4\n",
      "\n",
      "\tWorking on Question-quality-assessment\n",
      "\tSuccessfully loaded task question-quality-assessment, with papers 0\n",
      "\n",
      "\tWorking on Rumour-detection\n",
      "\tSuccessfully loaded task rumour-detection, with papers 58\n",
      "\n",
      "\tWorking on Open-domain-question-answering\n",
      "\tSuccessfully loaded task open-domain-question-answering, with papers 165\n",
      "\n",
      "\tWorking on Multi-word-expression-embedding\n",
      "\tSuccessfully loaded task multi-word-expression-embedding, with papers 1\n",
      "\n",
      "\tWorking on Text-matching\n",
      "\tSuccessfully loaded task text-matching, with papers 108\n",
      "\n",
      "\tWorking on Negation-detection\n",
      "\tSuccessfully loaded task negation-detection, with papers 33\n",
      "\n",
      "\tWorking on Semi-supervised-text-classification-1\n",
      "\tSuccessfully loaded task semi-supervised-text-classification-1, with papers 14\n",
      "\n",
      "\tWorking on Scientific-concept-extraction\n",
      "\tSuccessfully loaded task scientific-concept-extraction, with papers 1\n",
      "\n",
      "\tWorking on Ad-hoc-information-retrieval\n",
      "\tSuccessfully loaded task ad-hoc-information-retrieval, with papers 36\n",
      "\n",
      "\tWorking on Morphological-tagging\n",
      "\tSuccessfully loaded task morphological-tagging, with papers 75\n",
      "\n",
      "\tWorking on Tokenization\n",
      "\tSuccessfully loaded task tokenization, with papers 369\n",
      "\n",
      "\tWorking on Dependency-parsing\n",
      "\tSuccessfully loaded task dependency-parsing, with papers 950\n",
      "\n",
      "\tWorking on Lemmatization\n",
      "\tSuccessfully loaded task lemmatization, with papers 0\n",
      "\n",
      "\tWorking on Turning-point-identification\n",
      "\tSuccessfully loaded task turning-point-identification, with papers 3\n",
      "\n",
      "\tWorking on Stance-detection\n",
      "\tSuccessfully loaded task stance-detection, with papers 127\n",
      "\n",
      "\tWorking on Text-attribute-transfer\n",
      "\tSuccessfully loaded task text-attribute-transfer, with papers 6\n",
      "\n",
      "\tWorking on Opinion-mining\n",
      "\tSuccessfully loaded task opinion-mining, with papers 300\n",
      "\n",
      "\tWorking on Definition-extraction\n",
      "\tSuccessfully loaded task definition-extraction, with papers 13\n",
      "\n",
      "\tWorking on Cross-lingual-entity-linking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task cross-lingual-entity-linking, with papers 16\n",
      "\n",
      "\tWorking on Unsupervised-part-of-speech-tagging\n",
      "\tSuccessfully loaded task unsupervised-part-of-speech-tagging, with papers 4\n",
      "\n",
      "\tWorking on Dialogue-understanding\n",
      "\tSuccessfully loaded task dialogue-understanding, with papers 22\n",
      "\n",
      "\tWorking on Document-dating\n",
      "\tSuccessfully loaded task document-dating, with papers 6\n",
      "\n",
      "\tWorking on Cross-lingual-document-classification\n",
      "\tSuccessfully loaded task cross-lingual-document-classification, with papers 23\n",
      "\n",
      "\tWorking on Multi-word-expression-sememe-prediction\n",
      "\tSuccessfully loaded task multi-word-expression-sememe-prediction, with papers 1\n",
      "\n",
      "\tWorking on Selection-bias\n",
      "\tSuccessfully loaded task selection-bias, with papers 120\n",
      "\n",
      "\tWorking on Coreference-resolution\n",
      "\tSuccessfully loaded task coreference-resolution, with papers 561\n",
      "\n",
      "\tWorking on Joint-ner-and-classification\n",
      "\tSuccessfully loaded task joint-ner-and-classification, with papers 1\n",
      "\n",
      "\tWorking on Relation-mention-extraction\n",
      "\tSuccessfully loaded task relation-mention-extraction, with papers 1\n",
      "\n",
      "--- Working on Playing-games ---\n",
      "\tWorking on Dota-2\n",
      "\tSuccessfully loaded task dota-2, with papers 15\n",
      "\n",
      "\tWorking on Board-games\n",
      "\tSuccessfully loaded task board-games, with papers 57\n",
      "\n",
      "\tWorking on Acrobot\n",
      "\tSuccessfully loaded task acrobot, with papers 10\n",
      "\n",
      "\tWorking on Real-time-strategy-games\n",
      "\tSuccessfully loaded task real-time-strategy-games, with papers 32\n",
      "\n",
      "\tWorking on Game-of-chess\n",
      "\tSuccessfully loaded task game-of-chess, with papers 15\n",
      "\n",
      "\tWorking on Game-of-doom\n",
      "\tSuccessfully loaded task game-of-doom, with papers 5\n",
      "\n",
      "\tWorking on Injury-prediction\n",
      "\tSuccessfully loaded task injury-prediction, with papers 5\n",
      "\n",
      "\tWorking on Text-based-games\n",
      "\tSuccessfully loaded task text-based-games, with papers 26\n",
      "\n",
      "\tWorking on Game-of-shogi\n",
      "\tSuccessfully loaded task game-of-shogi, with papers 2\n",
      "\n",
      "\tWorking on Snes-games\n",
      "\tSuccessfully loaded task snes-games, with papers 4\n",
      "\n",
      "\tWorking on Starcraft-ii\n",
      "\tSuccessfully loaded task starcraft-ii, with papers 62\n",
      "\n",
      "\tWorking on League-of-legends\n",
      "\tSuccessfully loaded task league-of-legends, with papers 15\n",
      "\n",
      "\tWorking on Continuous-control\n",
      "\tSuccessfully loaded task continuous-control, with papers 486\n",
      "\n",
      "\tWorking on Atari-games\n",
      "\tSuccessfully loaded task atari-games, with papers 369\n",
      "\n",
      "\tWorking on Dqn-replay-dataset\n",
      "\tSuccessfully loaded task dqn-replay-dataset, with papers 6\n",
      "\n",
      "\tWorking on Multi-agent-path-finding\n",
      "\tSuccessfully loaded task multi-agent-path-finding, with papers 44\n",
      "\n",
      "\tWorking on Klondike\n",
      "\tSuccessfully loaded task klondike, with papers 1\n",
      "\n",
      "\tWorking on Offline-rl\n",
      "\tSuccessfully loaded task offline-rl, with papers 56\n",
      "\n",
      "\tWorking on Football-action-valuation\n",
      "\tSuccessfully loaded task football-action-valuation, with papers 2\n",
      "\n",
      "\tWorking on Minecraft\n",
      "\tSuccessfully loaded task minecraft, with papers 66\n",
      "\n",
      "\tWorking on Openai-gym\n",
      "\tSuccessfully loaded task openai-gym, with papers 173\n",
      "\n",
      "\tWorking on Card-games\n",
      "\tSuccessfully loaded task card-games, with papers 24\n",
      "\n",
      "\tWorking on Pass-classification\n",
      "\tSuccessfully loaded task pass-classification, with papers 1\n",
      "\n",
      "\tWorking on Video-games\n",
      "\tSuccessfully loaded task video-games, with papers 0\n",
      "\n",
      "\tWorking on Game-of-hanabi\n",
      "\tSuccessfully loaded task game-of-hanabi, with papers 3\n",
      "\n",
      "\tWorking on Fps-games\n",
      "\tSuccessfully loaded task fps-games, with papers 9\n",
      "\n",
      "\tWorking on Montezumas-revenge\n",
      "\tSuccessfully loaded task montezumas-revenge, with papers 38\n",
      "\n",
      "\tWorking on Suduko\n",
      "\tSuccessfully loaded task suduko, with papers 1\n",
      "\n",
      "\tWorking on Nethack\n",
      "\tSuccessfully loaded task nethack, with papers 3\n",
      "\n",
      "\tWorking on Game-of-cricket\n",
      "\tSuccessfully loaded task game-of-cricket, with papers 4\n",
      "\n",
      "\tWorking on Starcraft\n",
      "\tSuccessfully loaded task starcraft, with papers 124\n",
      "\n",
      "\tWorking on Smac\n",
      "\tSuccessfully loaded task smac, with papers 32\n",
      "\n",
      "\tWorking on Game-of-poker\n",
      "\tSuccessfully loaded task game-of-poker, with papers 6\n",
      "\n",
      "\tWorking on Score\n",
      "\tSuccessfully loaded task score, with papers 1\n",
      "\n",
      "\tWorking on Game-of-go\n",
      "\tSuccessfully loaded task game-of-go, with papers 44\n",
      "\n",
      "\tWorking on Solitaire\n",
      "\tSuccessfully loaded task solitaire, with papers 5\n",
      "\n",
      "\tWorking on Carracing-v0\n",
      "\tSuccessfully loaded task carracing-v0, with papers 24\n",
      "\n",
      "\tWorking on Game-of-football\n",
      "\tSuccessfully loaded task game-of-football, with papers 9\n",
      "\n",
      "--- Working on Reasoning ---\n",
      "\tWorking on Decision-making-under-uncertainty\n",
      "\tSuccessfully loaded task decision-making-under-uncertainty, with papers 95\n",
      "\n",
      "\tWorking on Visual-reasoning\n",
      "\tSuccessfully loaded task visual-reasoning, with papers 134\n",
      "\n",
      "\tWorking on Temporal-logic\n",
      "\tSuccessfully loaded task temporal-logic, with papers 179\n",
      "\n",
      "\tWorking on Pre-election-ratings-estimation\n",
      "\tSuccessfully loaded task pre-election-ratings-estimation, with papers 1\n",
      "\n",
      "\tWorking on Program-repair\n",
      "\tSuccessfully loaded task program-repair, with papers 28\n",
      "\n",
      "\tWorking on Common-sense-reasoning\n",
      "\tSuccessfully loaded task common-sense-reasoning, with papers 339\n",
      "\n",
      "\tWorking on Visual-commonsense-reasoning\n",
      "\tSuccessfully loaded task visual-commonsense-reasoning, with papers 19\n",
      "\n",
      "\tWorking on Natural-language-visual-grounding\n",
      "\tSuccessfully loaded task natural-language-visual-grounding, with papers 11\n",
      "\n",
      "\tWorking on Abstract-argumentation\n",
      "\tSuccessfully loaded task abstract-argumentation, with papers 87\n",
      "\n",
      "\tWorking on Causal-identification\n",
      "\tSuccessfully loaded task causal-identification, with papers 13\n",
      "\n",
      "\tWorking on Commonsense-rl\n",
      "\tSuccessfully loaded task commonsense-rl, with papers 1\n",
      "\n",
      "\tWorking on Decision-making\n",
      "\tSuccessfully loaded task decision-making, with papers 3526\n",
      "\n",
      "\tWorking on Math-word-problem-solving\n",
      "\tSuccessfully loaded task math-word-problem-solving, with papers 21\n",
      "\n",
      "\tWorking on Systematic-generalization\n",
      "\tSuccessfully loaded task systematic-generalization, with papers 29\n",
      "\n",
      "--- Working on Robots ---\n",
      "\tWorking on Deformable-object-manipulation\n",
      "\tSuccessfully loaded task deformable-object-manipulation, with papers 9\n",
      "\n",
      "\tWorking on Robot-task-planning\n",
      "\tSuccessfully loaded task robot-task-planning, with papers 8\n",
      "\n",
      "\tWorking on Motion-planning\n",
      "\tSuccessfully loaded task motion-planning, with papers 302\n",
      "\n",
      "\tWorking on Optimal-motion-planning\n",
      "\tSuccessfully loaded task optimal-motion-planning, with papers 8\n",
      "\n",
      "\tWorking on Visual-navigation\n",
      "\tSuccessfully loaded task visual-navigation, with papers 108\n",
      "\n",
      "\tWorking on Robotic-grasping\n",
      "\tSuccessfully loaded task robotic-grasping, with papers 91\n",
      "\n",
      "\tWorking on Sequential-place-recognition\n",
      "\tSuccessfully loaded task sequential-place-recognition, with papers 4\n",
      "\n",
      "\tWorking on Vision-and-language-navigation\n",
      "\tSuccessfully loaded task vision-and-language-navigation, with papers 49\n",
      "\n",
      "\tWorking on Human-robot-interaction\n",
      "\tSuccessfully loaded task human-robot-interaction, with papers 245\n",
      "\n",
      "\tWorking on Visual-odometry\n",
      "\tSuccessfully loaded task visual-odometry, with papers 224\n",
      "\n",
      "\tWorking on Safe-exploration\n",
      "\tSuccessfully loaded task safe-exploration, with papers 45\n",
      "\n",
      "\tWorking on Developmental-learning\n",
      "\tSuccessfully loaded task developmental-learning, with papers 6\n",
      "\n",
      "\tWorking on Pointgoal-navigation\n",
      "\tSuccessfully loaded task pointgoal-navigation, with papers 9\n",
      "\n",
      "\tWorking on Marine-robot-navigation\n",
      "\tSuccessfully loaded task marine-robot-navigation, with papers 1\n",
      "\n",
      "\tWorking on Trajectory-planning\n",
      "\tSuccessfully loaded task trajectory-planning, with papers 73\n",
      "\n",
      "\tWorking on Sequential-place-learning\n",
      "\tSuccessfully loaded task sequential-place-learning, with papers 3\n",
      "\n",
      "\tWorking on Industrial-robots\n",
      "\tSuccessfully loaded task industrial-robots, with papers 21\n",
      "\n",
      "\tWorking on Monocular-visual-odometry\n",
      "\tSuccessfully loaded task monocular-visual-odometry, with papers 44\n",
      "\n",
      "\tWorking on Gesture-generation\n",
      "\tSuccessfully loaded task gesture-generation, with papers 13\n",
      "\n",
      "\tWorking on Legged-robots\n",
      "\tSuccessfully loaded task legged-robots, with papers 38\n",
      "\n",
      "\tWorking on Robot-navigation\n",
      "\tSuccessfully loaded task robot-navigation, with papers 204\n",
      "\n",
      "\tWorking on Mental-stress-detection\n",
      "\tSuccessfully loaded task mental-stress-detection, with papers 2\n",
      "\n",
      "\tWorking on Curriculum-learning\n",
      "\tSuccessfully loaded task curriculum-learning, with papers 304\n",
      "\n",
      "\tWorking on Vision-based-navigation-with-language-based\n",
      "\tSuccessfully loaded task vision-based-navigation-with-language-based, with papers 1\n",
      "\n",
      "\tWorking on Voice-assistant\n",
      "\tSuccessfully loaded task voice-assistant, with papers 23\n",
      "\n",
      "--- Working on Speech ---\n",
      "\tWorking on Acoustic-echo-cancellation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task acoustic-echo-cancellation, with papers 18\n",
      "\n",
      "\tWorking on Speech-separation\n",
      "\tSuccessfully loaded task speech-separation, with papers 129\n",
      "\n",
      "\tWorking on Acoustic-unit-discovery\n",
      "\tSuccessfully loaded task acoustic-unit-discovery, with papers 10\n",
      "\n",
      "\tWorking on Speaker-recognition\n",
      "\tSuccessfully loaded task speaker-recognition, with papers 198\n",
      "\n",
      "\tWorking on Acoustic-question-answering\n",
      "\tSuccessfully loaded task acoustic-question-answering, with papers 2\n",
      "\n",
      "\tWorking on End-to-end-speech-recognition\n",
      "\tSuccessfully loaded task end-to-end-speech-recognition, with papers 230\n",
      "\n",
      "\tWorking on Speaker-diarization\n",
      "\tSuccessfully loaded task speaker-diarization, with papers 97\n",
      "\n",
      "\tWorking on Spoken-dialogue-systems\n",
      "\tSuccessfully loaded task spoken-dialogue-systems, with papers 189\n",
      "\n",
      "\tWorking on Speech-quality\n",
      "\tSuccessfully loaded task speech-quality, with papers 114\n",
      "\n",
      "\tWorking on Acoustic-modelling\n",
      "\tSuccessfully loaded task acoustic-modelling, with papers 37\n",
      "\n",
      "\tWorking on Sequence-to-sequence-speech-recognition\n",
      "\tSuccessfully loaded task sequence-to-sequence-speech-recognition, with papers 16\n",
      "\n",
      "\tWorking on Manner-of-articulation-detection\n",
      "\tSuccessfully loaded task manner-of-articulation-detection, with papers 2\n",
      "\n",
      "\tWorking on Speaker-verification\n",
      "\tSuccessfully loaded task speaker-verification, with papers 263\n",
      "\n",
      "\tWorking on Voice-query-recognition\n",
      "\tSuccessfully loaded task voice-query-recognition, with papers 1\n",
      "\n",
      "\tWorking on Speaker-separation\n",
      "\tSuccessfully loaded task speaker-separation, with papers 24\n",
      "\n",
      "\tWorking on Speech-dereverberation\n",
      "\tSuccessfully loaded task speech-dereverberation, with papers 16\n",
      "\n",
      "\tWorking on Speech-enhancement\n",
      "\tSuccessfully loaded task speech-enhancement, with papers 292\n",
      "\n",
      "\tWorking on Speech-denoising\n",
      "\tSuccessfully loaded task speech-denoising, with papers 18\n",
      "\n",
      "\tWorking on Speech-emotion-recognition\n",
      "\tSuccessfully loaded task speech-emotion-recognition, with papers 89\n",
      "\n",
      "\tWorking on Robust-speech-recognition\n",
      "\tSuccessfully loaded task robust-speech-recognition, with papers 46\n",
      "\n",
      "\tWorking on Text-dependent-speaker-verification\n",
      "\tSuccessfully loaded task text-dependent-speaker-verification, with papers 20\n",
      "\n",
      "\tWorking on Speech-synthesis\n",
      "\tSuccessfully loaded task speech-synthesis, with papers 462\n",
      "\n",
      "\tWorking on Spoken-language-understanding\n",
      "\tSuccessfully loaded task spoken-language-understanding, with papers 287\n",
      "\n",
      "\tWorking on Noisy-speech-recognition\n",
      "\tSuccessfully loaded task noisy-speech-recognition, with papers 9\n",
      "\n",
      "\tWorking on Voice-conversion\n",
      "\tSuccessfully loaded task voice-conversion, with papers 139\n",
      "\n",
      "\tWorking on Visual-speech-recognition\n",
      "\tSuccessfully loaded task visual-speech-recognition, with papers 56\n",
      "\n",
      "\tWorking on Text-independent-speaker-recognition\n",
      "\tSuccessfully loaded task text-independent-speaker-recognition, with papers 14\n",
      "\n",
      "\tWorking on Small-footprint-keyword-spotting\n",
      "\tSuccessfully loaded task small-footprint-keyword-spotting, with papers 14\n",
      "\n",
      "\tWorking on Keyword-spotting\n",
      "\tSuccessfully loaded task keyword-spotting, with papers 138\n",
      "\n",
      "\tWorking on Dialogue-generation\n",
      "\tSuccessfully loaded task dialogue-generation, with papers 186\n",
      "\n",
      "\tWorking on Expressive-speech-synthesis\n",
      "\tSuccessfully loaded task expressive-speech-synthesis, with papers 16\n",
      "\n",
      "\tWorking on Text-independent-speaker-verification\n",
      "\tSuccessfully loaded task text-independent-speaker-verification, with papers 40\n",
      "\n",
      "\tWorking on Spoken-language-identification\n",
      "\tSuccessfully loaded task spoken-language-identification, with papers 16\n",
      "\n",
      "\tWorking on Pronunciation-assessment\n",
      "\tSuccessfully loaded task pronunciation-assessment, with papers 0\n",
      "\n",
      "\tWorking on Speaker-profiling\n",
      "\tSuccessfully loaded task speaker-profiling, with papers 3\n",
      "\n",
      "\tWorking on Speech-recognition\n",
      "\tSuccessfully loaded task speech-recognition, with papers 2050\n",
      "\n",
      "\tWorking on Distant-speech-recognition\n",
      "\tSuccessfully loaded task distant-speech-recognition, with papers 22\n",
      "\n",
      "\tWorking on English-conversational-speech-recognition\n",
      "\tSuccessfully loaded task english-conversational-speech-recognition, with papers 4\n",
      "\n",
      "\tWorking on Speech-to-gesture-translation\n",
      "\tSuccessfully loaded task speech-to-gesture-translation, with papers 1\n",
      "\n",
      "\tWorking on Speaking-style-synthesis\n",
      "\tSuccessfully loaded task speaking-style-synthesis, with papers 0\n",
      "\n",
      "\tWorking on Speech-extraction\n",
      "\tSuccessfully loaded task speech-extraction, with papers 10\n",
      "\n",
      "\tWorking on Emotional-speech-synthesis\n",
      "\tSuccessfully loaded task emotional-speech-synthesis, with papers 6\n",
      "\n",
      "\tWorking on Phone-level-pronunciation-scoring\n",
      "\tSuccessfully loaded task phone-level-pronunciation-scoring, with papers 1\n",
      "\n",
      "\tWorking on Anomaly-detection\n",
      "\tSuccessfully loaded task anomaly-detection, with papers 1350\n",
      "\n",
      "\tWorking on Multi-speaker-source-separation\n",
      "\tSuccessfully loaded task multi-speaker-source-separation, with papers 5\n",
      "\n",
      "\tWorking on Unsupervised-speech-recognition\n",
      "\tSuccessfully loaded task unsupervised-speech-recognition, with papers 6\n",
      "\n",
      "\tWorking on Accented-speech-recognition\n",
      "\tSuccessfully loaded task accented-speech-recognition, with papers 6\n",
      "\n",
      "\tWorking on Text-to-speech-synthesis\n",
      "\tSuccessfully loaded task text-to-speech-synthesis, with papers 129\n",
      "\n",
      "\tWorking on Speaker-identification\n",
      "\tSuccessfully loaded task speaker-identification, with papers 100\n",
      "\n",
      "\tWorking on Large-vocabulary-continuous-speech\n",
      "\tSuccessfully loaded task large-vocabulary-continuous-speech, with papers 92\n",
      "\n",
      "--- Working on Time-series ---\n",
      "\tWorking on Moving-point-cloud-processing\n",
      "\tSuccessfully loaded task moving-point-cloud-processing, with papers 1\n",
      "\n",
      "\tWorking on Eeg\n",
      "\tSuccessfully loaded task eeg, with papers 100\n",
      "\n",
      "\tWorking on Time-series-denoising\n",
      "\tSuccessfully loaded task time-series-denoising, with papers 0\n",
      "\n",
      "\tWorking on Multivariate-time-series-imputation\n",
      "\tSuccessfully loaded task multivariate-time-series-imputation, with papers 18\n",
      "\n",
      "\tWorking on Time-series-analysis\n",
      "\tSuccessfully loaded task time-series-analysis, with papers 215\n",
      "\n",
      "\tWorking on Multivariate-time-series-forecasting\n",
      "\tSuccessfully loaded task multivariate-time-series-forecasting, with papers 40\n",
      "\n",
      "\tWorking on Seismic-source-localization\n",
      "\tSuccessfully loaded task seismic-source-localization, with papers 1\n",
      "\n",
      "\tWorking on Sleep-spindles-detection\n",
      "\tSuccessfully loaded task sleep-spindles-detection, with papers 1\n",
      "\n",
      "\tWorking on Time-series-alignment\n",
      "\tSuccessfully loaded task time-series-alignment, with papers 7\n",
      "\n",
      "\tWorking on Time-series-averaging\n",
      "\tSuccessfully loaded task time-series-averaging, with papers 7\n",
      "\n",
      "\tWorking on Lip-password-classification\n",
      "\tSuccessfully loaded task lip-password-classification, with papers 1\n",
      "\n",
      "\tWorking on Human-motion-prediction\n",
      "\tSuccessfully loaded task human-motion-prediction, with papers 53\n",
      "\n",
      "\tWorking on Spatio-temporal-forecasting\n",
      "\tSuccessfully loaded task spatio-temporal-forecasting, with papers 20\n",
      "\n",
      "\tWorking on Time-to-event-prediction\n",
      "\tSuccessfully loaded task time-to-event-prediction, with papers 8\n",
      "\n",
      "\tWorking on Time-series\n",
      "\tSuccessfully loaded task time-series, with papers 3503\n",
      "\n",
      "\tWorking on Traffic-prediction\n",
      "\tSuccessfully loaded task traffic-prediction, with papers 92\n",
      "\n",
      "\tWorking on Change-point-detection\n",
      "\tSuccessfully loaded task change-point-detection, with papers 120\n",
      "\n",
      "\tWorking on Irregular-time-series\n",
      "\tSuccessfully loaded task irregular-time-series, with papers 15\n",
      "\n",
      "\tWorking on Math-word-problem-solving\n",
      "\tSuccessfully loaded task math-word-problem-solving, with papers 21\n",
      "\n",
      "\tWorking on Time-series-regression\n",
      "\tSuccessfully loaded task time-series-regression, with papers 20\n",
      "\n",
      "\tWorking on Semanticity-prediction\n",
      "\tSuccessfully loaded task semanticity-prediction, with papers 1\n",
      "\n",
      "\tWorking on Imputation\n",
      "\tSuccessfully loaded task imputation, with papers 361\n",
      "\n",
      "\tWorking on Stock-trend-prediction\n",
      "\tSuccessfully loaded task stock-trend-prediction, with papers 6\n",
      "\n",
      "\tWorking on Attention-score-prediction\n",
      "\tSuccessfully loaded task attention-score-prediction, with papers 1\n",
      "\n",
      "\tWorking on Time-series-forecasting\n",
      "\tSuccessfully loaded task time-series-forecasting, with papers 276\n",
      "\n",
      "\tWorking on Semi-supervised-semantic-segmentation\n",
      "\tSuccessfully loaded task semi-supervised-semantic-segmentation, with papers 38\n",
      "\n",
      "\tWorking on Eeg-decoding\n",
      "\tSuccessfully loaded task eeg-decoding, with papers 13\n",
      "\n",
      "\tWorking on Covid-19-modelling\n",
      "\tSuccessfully loaded task covid-19-modelling, with papers 1\n",
      "\n",
      "\tWorking on Predictive-process-monitoring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded task predictive-process-monitoring, with papers 14\n",
      "\n",
      "\tWorking on Stock-price-prediction\n",
      "\tSuccessfully loaded task stock-price-prediction, with papers 47\n",
      "\n",
      "\tWorking on Edge-computing\n",
      "\tSuccessfully loaded task edge-computing, with papers 308\n",
      "\n",
      "\tWorking on Clustering-multivariate-time-series\n",
      "\tSuccessfully loaded task clustering-multivariate-time-series, with papers 4\n",
      "\n",
      "\tWorking on Sequential-skip-prediction\n",
      "\tSuccessfully loaded task sequential-skip-prediction, with papers 5\n",
      "\n",
      "\tWorking on Covid-19-tracking\n",
      "\tSuccessfully loaded task covid-19-tracking, with papers 1\n",
      "\n",
      "\tWorking on Unsupervised-spatial-clustering\n",
      "\tSuccessfully loaded task unsupervised-spatial-clustering, with papers 5\n",
      "\n",
      "\tWorking on Portfolio-optimization\n",
      "\tSuccessfully loaded task portfolio-optimization, with papers 119\n",
      "\n",
      "\tWorking on Univariate-time-series-forecasting\n",
      "\tSuccessfully loaded task univariate-time-series-forecasting, with papers 4\n",
      "\n",
      "\tWorking on Stock-market-prediction\n",
      "\tSuccessfully loaded task stock-market-prediction, with papers 55\n",
      "\n",
      "\tWorking on Noise-level-prediction\n",
      "\tSuccessfully loaded task noise-level-prediction, with papers 1\n",
      "\n",
      "\tWorking on Time-series-classification\n",
      "\tSuccessfully loaded task time-series-classification, with papers 243\n",
      "\n",
      "\tWorking on Non-intrusive-load-monitoring\n",
      "\tSuccessfully loaded task non-intrusive-load-monitoring, with papers 33\n",
      "\n",
      "\tWorking on Traffic-data-imputation\n",
      "\tSuccessfully loaded task traffic-data-imputation, with papers 5\n",
      "\n",
      "\tWorking on Time-series-prediction\n",
      "\tSuccessfully loaded task time-series-prediction, with papers 168\n",
      "\n",
      "\tWorking on Probabilistic-time-series-forecasting\n",
      "\tSuccessfully loaded task probabilistic-time-series-forecasting, with papers 11\n",
      "\n",
      "\tWorking on Lwr-classification\n",
      "\tSuccessfully loaded task lwr-classification, with papers 1\n",
      "\n",
      "\tWorking on Time-series-clustering\n",
      "\tSuccessfully loaded task time-series-clustering, with papers 47\n",
      "\n",
      "\tWorking on Stock-prediction\n",
      "\tSuccessfully loaded task stock-prediction, with papers 48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "areas_id = list(map(get_id, client.area_list().results))\n",
    "area_paper_dict = {area: [] for area in areas_id}\n",
    "for area in areas_id:\n",
    "    \n",
    "    print(f\"--- Working on {area.capitalize()} ---\")\n",
    "    try:\n",
    "        task_id_lists = list(map(get_id, client.area_task_list(area).results))\n",
    "        \n",
    "    except:\n",
    "        print(f\"**Error occurred with area {area}.**\")\n",
    "        continue\n",
    "        \n",
    "    for task_id in task_id_lists:\n",
    "        \n",
    "        page_idx, papers = 1, []\n",
    "        print(f\"\\tWorking on {task_id.capitalize()}\")\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                results = http.get(f\"/tasks/{task_id}/papers/?page={page_idx}\")['results']\n",
    "                _tmp = [p['id'] for p in results]\n",
    "                papers.extend(_tmp)\n",
    "                page_idx += 1\n",
    "                \n",
    "            except:\n",
    "                print(f\"\\tSuccessfully loaded task {task_id}, with papers {len(papers)}\\n\")\n",
    "                break\n",
    "\n",
    "            area_paper_dict[area].extend(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:40:07.413477Z",
     "start_time": "2021-04-21T08:40:04.782092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'open-set-adversarial-defense',\n",
       "  'arxiv_id': '2009.00814',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2009.00814v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2009.00814v1.pdf',\n",
       "  'title': 'Open-set Adversarial Defense',\n",
       "  'abstract': 'Open-set recognition and adversarial defense study two key aspects of deep learning that are vital for real-world deployment. The objective of open-set recognition is to identify samples from open-set classes during testing, while adversarial defense aims to defend the network against images with imperceptible adversarial perturbations. In this paper, we show that open-set recognition systems are vulnerable to adversarial attacks. Furthermore, we show that adversarial defense mechanisms trained on known classes do not generalize well to open-set samples. Motivated by this observation, we emphasize the need of an Open-Set Adversarial Defense (OSAD) mechanism. This paper proposes an Open-Set Defense Network (OSDN) as a solution to the OSAD problem. The proposed network uses an encoder with feature-denoising layers coupled with a classifier to learn a noise-free latent feature representation. Two techniques are employed to obtain an informative latent feature space with the objective of improving open-set performance. First, a decoder is used to ensure that clean images can be reconstructed from the obtained latent features. Then, self-supervision is used to ensure that the latent features are informative enough to carry out an auxiliary task. We introduce a testing protocol to evaluate OSAD performance and show the effectiveness of the proposed method in multiple object classification datasets. The implementation code of the proposed method is available at: https://github.com/rshaojimmy/ECCV2020-OSAD.',\n",
       "  'authors': ['Rui Shao',\n",
       "   'Pramuditha Perera',\n",
       "   'Pong C. Yuen',\n",
       "   'Vishal M. Patel'],\n",
       "  'published': '2020-09-02',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': 'https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/2865_ECCV_2020_paper.php',\n",
       "  'conference_url_pdf': 'https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620664.pdf',\n",
       "  'proceeding': 'eccv-2020-8'},\n",
       " {'id': 'benchmarking-adversarial-attacks-and-defenses',\n",
       "  'arxiv_id': '2008.13261',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2008.13261v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2008.13261v1.pdf',\n",
       "  'title': 'Benchmarking adversarial attacks and defenses for time-series data',\n",
       "  'abstract': 'The adversarial vulnerability of deep networks has spurred the interest of researchers worldwide. Unsurprisingly, like images, adversarial examples also translate to time-series data as they are an inherent weakness of the model itself rather than the modality. Several attempts have been made to defend against these adversarial attacks, particularly for the visual modality. In this paper, we perform detailed benchmarking of well-proven adversarial defense methodologies on time-series data. We restrict ourselves to the $L_{\\\\infty}$ threat model. We also explore the trade-off between smoothness and clean accuracy for regularization-based defenses to better understand the trade-offs that they offer. Our analysis shows that the explored adversarial defenses offer robustness against both strong white-box as well as black-box attacks. This paves the way for future research in the direction of adversarial attacks and defenses, particularly for time-series data.',\n",
       "  'authors': ['Shoaib Ahmed Siddiqui', 'Andreas Dengel', 'Sheraz Ahmed'],\n",
       "  'published': '2020-08-30',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'likelihood-landscapes-a-unifying-principle',\n",
       "  'arxiv_id': '2008.11300',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2008.11300v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2008.11300v1.pdf',\n",
       "  'title': 'Likelihood Landscapes: A Unifying Principle Behind Many Adversarial Defenses',\n",
       "  'abstract': 'Convolutional Neural Networks have been shown to be vulnerable to adversarial examples, which are known to locate in subspaces close to where normal data lies but are not naturally occurring and of low probability. In this work, we investigate the potential effect defense techniques have on the geometry of the likelihood landscape - likelihood of the input images under the trained model. We first propose a way to visualize the likelihood landscape leveraging an energy-based model interpretation of discriminative classifiers. Then we introduce a measure to quantify the flatness of the likelihood landscape. We observe that a subset of adversarial defense techniques results in a similar effect of flattening the likelihood landscape. We further explore directly regularizing towards a flat landscape for adversarial robustness.',\n",
       "  'authors': ['Fu Lin',\n",
       "   'Rohit Mittapalli',\n",
       "   'Prithvijit Chattopadhyay',\n",
       "   'Daniel Bolya',\n",
       "   'Judy Hoffman'],\n",
       "  'published': '2020-08-25',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'cassandra-detecting-trojaned-networks-from',\n",
       "  'arxiv_id': '2007.14433',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2007.14433v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2007.14433v1.pdf',\n",
       "  'title': 'Cassandra: Detecting Trojaned Networks from Adversarial Perturbations',\n",
       "  'abstract': \"Deep neural networks are being widely deployed for many critical tasks due to their high classification accuracy. In many cases, pre-trained models are sourced from vendors who may have disrupted the training pipeline to insert Trojan behaviors into the models. These malicious behaviors can be triggered at the adversary's will and hence, cause a serious threat to the widespread deployment of deep models. We propose a method to verify if a pre-trained model is Trojaned or benign. Our method captures fingerprints of neural networks in the form of adversarial perturbations learned from the network gradients. Inserting backdoors into a network alters its decision boundaries which are effectively encoded in their adversarial perturbations. We train a two stream network for Trojan detection from its global ($L_\\\\infty$ and $L_2$ bounded) perturbations and the localized region of high energy within each perturbation. The former encodes decision boundaries of the network and latter encodes the unknown trigger shape. We also propose an anomaly detection method to identify the target class in a Trojaned network. Our methods are invariant to the trigger type, trigger size, training data and network architecture. We evaluate our methods on MNIST, NIST-Round0 and NIST-Round1 datasets, with up to 1,000 pre-trained models making this the largest study to date on Trojaned network detection, and achieve over 92\\\\% detection accuracy to set the new state-of-the-art.\",\n",
       "  'authors': ['Xiaoyu Zhang',\n",
       "   'Ajmal Mian',\n",
       "   'Rohit Gupta',\n",
       "   'Nazanin Rahnavard',\n",
       "   'Mubarak Shah'],\n",
       "  'published': '2020-07-28',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'stylized-adversarial-defense',\n",
       "  'arxiv_id': '2007.14672',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2007.14672v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2007.14672v1.pdf',\n",
       "  'title': 'Stylized Adversarial Defense',\n",
       "  'abstract': 'Deep Convolution Neural Networks (CNNs) can easily be fooled by subtle, imperceptible changes to the input images. To address this vulnerability, adversarial training creates perturbation patterns and includes them in the training set to robustify the model. In contrast to existing adversarial training methods that only use class-boundary information (e.g., using a cross entropy loss), we propose to exploit additional information from the feature space to craft stronger adversaries that are in turn used to learn a robust model. Specifically, we use the style and content information of the target sample from another class, alongside its class boundary information to create adversarial perturbations. We apply our proposed multi-task objective in a deeply supervised manner, extracting multi-scale feature knowledge to create maximally separating adversaries. Subsequently, we propose a max-margin adversarial training approach that minimizes the distance between source image and its adversary and maximizes the distance between the adversary and the target image. Our adversarial training approach demonstrates strong robustness compared to state of the art defenses, generalizes well to naturally occurring corruptions and data distributional shifts, and retains the model accuracy on clean examples.',\n",
       "  'authors': ['Muzammal Naseer',\n",
       "   'Salman Khan',\n",
       "   'Munawar Hayat',\n",
       "   'Fahad Shahbaz Khan',\n",
       "   'Fatih Porikli'],\n",
       "  'published': '2020-07-29',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'anomaly-detection-in-unsupervised',\n",
       "  'arxiv_id': '2007.10812',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2007.10812v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2007.10812v1.pdf',\n",
       "  'title': 'Anomaly Detection in Unsupervised Surveillance Setting Using Ensemble of Multimodal Data with Adversarial Defense',\n",
       "  'abstract': 'Autonomous aerial surveillance using drone feed is an interesting and challenging research domain. To ensure safety from intruders and potential objects posing threats to the zone being protected, it is crucial to be able to distinguish between normal and abnormal states in real-time. Additionally, we also need to consider any device malfunction. However, the inherent uncertainty embedded within the type and level of abnormality makes supervised techniques less suitable since the adversary may present a unique anomaly for intrusion. As a result, an unsupervised method for anomaly detection is preferable taking the unpredictable nature of attacks into account. Again in our case, the autonomous drone provides heterogeneous data streams consisting of images and other analog or digital sensor data, all of which can play a role in anomaly detection if they are ensembled synergistically. To that end, an ensemble detection mechanism is proposed here which estimates the degree of abnormality of analyzing the real-time image and IMU (Inertial Measurement Unit) sensor data in an unsupervised manner. First, we have implemented a Convolutional Neural Network (CNN) regression block, named AngleNet to estimate the angle between a reference image and current test image, which provides us with a measure of the anomaly of the device. Moreover, the IMU data are used in autoencoders to predict abnormality. Finally, the results from these two pipelines are ensembled to estimate the final degree of abnormality. Furthermore, we have applied adversarial attack to test the robustness and security of the proposed approach and integrated defense mechanism. The proposed method performs satisfactorily on the IEEE SP Cup-2020 dataset with an accuracy of 97.8%. Additionally, we have also tested this approach on an in-house dataset to validate its robustness.',\n",
       "  'authors': ['Sayeed Shafayet Chowdhury',\n",
       "   'Kaji Mejbaul Islam',\n",
       "   'Rouhan Noor'],\n",
       "  'published': '2020-07-17',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'multitask-learning-strengthens-adversarial',\n",
       "  'arxiv_id': '2007.07236',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2007.07236v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2007.07236v2.pdf',\n",
       "  'title': 'Multitask Learning Strengthens Adversarial Robustness',\n",
       "  'abstract': 'Although deep networks achieve strong accuracy on a range of computer vision benchmarks, they remain vulnerable to adversarial attacks, where imperceptible input perturbations fool the network. We present both theoretical and empirical analyses that connect the adversarial robustness of a model to the number of tasks that it is trained on. Experiments on two datasets show that attack difficulty increases as the number of target tasks increase. Moreover, our results suggest that when models are trained on multiple tasks at once, they become more robust to adversarial attacks on individual tasks. While adversarial defense remains an open challenge, our results suggest that deep networks are vulnerable partly because they are trained on too few tasks.',\n",
       "  'authors': ['Chengzhi Mao',\n",
       "   'Amogh Gupta',\n",
       "   'Vikram Nitin',\n",
       "   'Baishakhi Ray',\n",
       "   'Shuran Song',\n",
       "   'Junfeng Yang',\n",
       "   'Carl Vondrick'],\n",
       "  'published': '2020-07-14',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': 'https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/3047_ECCV_2020_paper.php',\n",
       "  'conference_url_pdf': 'https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470154.pdf',\n",
       "  'proceeding': 'eccv-2020-8'},\n",
       " {'id': 'a-unified-framework-for-analyzing-and',\n",
       "  'arxiv_id': '2006.14871',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.14871v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.14871v1.pdf',\n",
       "  'title': 'A Unified Framework for Analyzing and Detecting Malicious Examples of DNN Models',\n",
       "  'abstract': 'Deep Neural Networks are well known to be vulnerable to adversarial attacks and backdoor attacks, where minor modifications on the input can mislead the models to give wrong results. Although defenses against adversarial attacks have been widely studied, research on mitigating backdoor attacks is still at an early stage. It is unknown whether there are any connections and common characteristics between the defenses against these two attacks. In this paper, we present a unified framework for detecting malicious examples and protecting the inference results of Deep Learning models. This framework is based on our observation that both adversarial examples and backdoor examples have anomalies during the inference process, highly distinguishable from benign samples. As a result, we repurpose and revise four existing adversarial defense methods for detecting backdoor examples. Extensive evaluations indicate these approaches provide reliable protection against backdoor attacks, with a higher accuracy than detecting adversarial examples. These solutions also reveal the relations of adversarial examples, backdoor examples and normal samples in model sensitivity, activation space and feature space. This can enhance our understanding about the inherent features of these two attacks, as well as the defense opportunities.',\n",
       "  'authors': ['Kaidi Jin',\n",
       "   'Tianwei Zhang',\n",
       "   'Chao Shen',\n",
       "   'Yufei Chen',\n",
       "   'Ming Fan',\n",
       "   'Chenhao Lin',\n",
       "   'Ting Liu'],\n",
       "  'published': '2020-06-26',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'defending-against-adversarial-attacks-on',\n",
       "  'arxiv_id': '2006.13555',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.13555v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.13555v1.pdf',\n",
       "  'title': 'Defending against adversarial attacks on medical imaging AI system, classification or detection?',\n",
       "  'abstract': 'Medical imaging AI systems such as disease classification and segmentation are increasingly inspired and transformed from computer vision based AI systems. Although an array of adversarial training and/or loss function based defense techniques have been developed and proved to be effective in computer vision, defending against adversarial attacks on medical images remains largely an uncharted territory due to the following unique challenges: 1) label scarcity in medical images significantly limits adversarial generalizability of the AI system; 2) vastly similar and dominant fore- and background in medical images make it hard samples for learning the discriminating features between different disease classes; and 3) crafted adversarial noises added to the entire medical image as opposed to the focused organ target can make clean and adversarial examples more discriminate than that between different disease classes. In this paper, we propose a novel robust medical imaging AI framework based on Semi-Supervised Adversarial Training (SSAT) and Unsupervised Adversarial Detection (UAD), followed by designing a new measure for assessing systems adversarial risk. We systematically demonstrate the advantages of our robust medical imaging AI system over the existing adversarial defense techniques under diverse real-world settings of adversarial attacks using a benchmark OCT imaging data set.',\n",
       "  'authors': ['Xin Li', 'Deng Pan', 'Dongxiao Zhu'],\n",
       "  'published': '2020-06-24',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'perceptual-adversarial-robustness-defense',\n",
       "  'arxiv_id': '2006.12655',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.12655v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.12655v3.pdf',\n",
       "  'title': 'Perceptual Adversarial Robustness: Defense Against Unseen Threat Models',\n",
       "  'abstract': 'A key challenge in adversarial robustness is the lack of a precise mathematical characterization of human perception, used in the very definition of adversarial attacks that are imperceptible to human eyes. Most current attacks and defenses try to avoid this issue by considering restrictive adversarial threat models such as those bounded by $L_2$ or $L_\\\\infty$ distance, spatial perturbations, etc. However, models that are robust against any of these restrictive threat models are still fragile against other threat models. To resolve this issue, we propose adversarial training against the set of all imperceptible adversarial examples, approximated using deep neural networks. We call this threat model the neural perceptual threat model (NPTM); it includes adversarial examples with a bounded neural perceptual distance (a neural network-based approximation of the true perceptual distance) to natural images. Through an extensive perceptual study, we show that the neural perceptual distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model. Under the NPTM, we develop novel perceptual adversarial attacks and defenses. Because the NPTM is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five diverse adversarial attacks. We find that PAT achieves state-of-the-art robustness against the union of these five attacks, more than doubling the accuracy over the next best model, without training against any of them. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial defense with this property.',\n",
       "  'authors': ['Cassidy Laidlaw', 'Sahil Singla', 'Soheil Feizi'],\n",
       "  'published': '2020-06-22',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'adversarial-defense-by-latent-style',\n",
       "  'arxiv_id': '2006.09701',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.09701v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.09701v1.pdf',\n",
       "  'title': 'Adversarial Defense by Latent Style Transformations',\n",
       "  'abstract': 'Machine learning models have demonstrated vulnerability to adversarial attacks, more specifically misclassification of adversarial examples. In this paper, we investigate an attack-agnostic defense against adversarial attacks on high-resolution images by detecting suspicious inputs. The intuition behind our approach is that the essential characteristics of a normal image are generally consistent with non-essential style transformations, e.g., slightly changing the facial expression of human portraits. In contrast, adversarial examples are generally sensitive to such transformations. In our approach to detect adversarial instances, we propose an in\\\\underline{V}ertible \\\\underline{A}utoencoder based on the \\\\underline{S}tyleGAN2 generator via \\\\underline{A}dversarial training (VASA) to inverse images to disentangled latent codes that reveal hierarchical styles. We then build a set of edited copies with non-essential style transformations by performing latent shifting and reconstruction, based on the correspondences between latent codes and style transformations. The classification-based consistency of these edited copies is used to distinguish adversarial instances.',\n",
       "  'authors': ['Shuo Wang',\n",
       "   'Surya Nepal',\n",
       "   'Marthie Grobler',\n",
       "   'Carsten Rudolph',\n",
       "   'Tianle Chen',\n",
       "   'Shangyu Chen'],\n",
       "  'published': '2020-06-17',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'improved-detection-of-adversarial-attacks-via-1',\n",
       "  'arxiv_id': '1911.00870',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1911.00870v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1911.00870v2.pdf',\n",
       "  'title': 'MadNet: Using a MAD Optimization for Defending Against Adversarial Attacks',\n",
       "  'abstract': 'This paper is concerned with the defense of deep models against adversarial attacks. Inspired by the certificate defense approach, we propose a maximal adversarial distortion (MAD) optimization method for robustifying deep networks. MAD captures the idea of increasing separability of class clusters in the embedding space while decreasing the network sensitivity to small distortions. Given a deep neural network (DNN) for a classification problem, an application of MAD optimization results in MadNet, a version of the original network, now equipped with an adversarial defense mechanism. MAD optimization is intuitive, effective and scalable, and the resulting MadNet can improve the original accuracy. We present an extensive empirical study demonstrating that MadNet improves adversarial robustness performance compared to state-of-the-art methods.',\n",
       "  'authors': ['Shai Rozenberg', 'Gal Elidan', 'Ran El-Yaniv'],\n",
       "  'published': '2019-11-03',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'tricking-adversarial-attacks-to-fail',\n",
       "  'arxiv_id': '2006.04504',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.04504v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.04504v1.pdf',\n",
       "  'title': 'Tricking Adversarial Attacks To Fail',\n",
       "  'abstract': 'Recent adversarial defense approaches have failed. Untargeted gradient-based attacks cause classifiers to choose any wrong class. Our novel white-box defense tricks untargeted attacks into becoming attacks targeted at designated target classes. From these target classes, we can derive the real classes. Our Target Training defense tricks the minimization at the core of untargeted, gradient-based adversarial attacks: minimize the sum of (1) perturbation and (2) classifier adversarial loss. Target Training changes the classifier minimally, and trains it with additional duplicated points (at 0 distance) labeled with designated classes. These differently-labeled duplicated samples minimize both terms (1) and (2) of the minimization, steering attack convergence to samples of designated classes, from which correct classification is derived. Importantly, Target Training eliminates the need to know the attack and the overhead of generating adversarial samples of attacks that minimize perturbations. We obtain an 86.2% accuracy for CW-L2 (confidence=0) in CIFAR10, exceeding even unsecured classifier accuracy on non-adversarial samples. Target Training presents a fundamental change in adversarial defense strategy.',\n",
       "  'authors': ['Blerta Lindqvist'],\n",
       "  'published': '2020-06-08',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'adversarial-image-generation-and-training-for',\n",
       "  'arxiv_id': '2006.03243',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.03243v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.03243v2.pdf',\n",
       "  'title': 'Adversarial Image Generation and Training for Deep Neural Networks',\n",
       "  'abstract': 'Deep neural networks (DNNs) have achieved great success in image classification, but they may be very vulnerable to adversarial attacks with small perturbations to images. Moreover, the adversarial training based on adversarial image samples has been shown to improve the robustness and generalization of DNNs. The aim of this paper is to develop a novel framework based on information-geometry sensitivity analysis and the particle swarm optimization to improve two aspects of adversarial image generation and training for DNNs. The first one is customized generation of adversarial examples. It can design adversarial attacks from options of the number of perturbed pixels, the misclassification probability, and the targeted incorrect class, and hence it is more flexible and effective to locate vulnerable pixels and also enjoys certain adversarial universality. The other is targeted adversarial training. DNN models can be improved in training with the adversarial information using a manifold-based influence measure effective in vulnerable image/pixel detection as well as allowing for targeted attacks, thereby exhibiting an enhanced adversarial defense in testing.',\n",
       "  'authors': ['Hai Shu', 'Ronghua Shi', 'Hongtu Zhu', 'Ziqi Chen'],\n",
       "  'published': '2020-06-05',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'exploring-the-role-of-input-and-output-layers',\n",
       "  'arxiv_id': '2006.01408',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2006.01408v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2006.01408v1.pdf',\n",
       "  'title': 'Exploring the role of Input and Output Layers of a Deep Neural Network in Adversarial Defense',\n",
       "  'abstract': 'Deep neural networks are learning models having achieved state of the art performance in many fields like prediction, computer vision, language processing and so on. However, it has been shown that certain inputs exist which would not trick a human normally, but may mislead the model completely. These inputs are known as adversarial inputs. These inputs pose a high security threat when such models are used in real world applications. In this work, we have analyzed the resistance of three different classes of fully connected dense networks against the rarely tested non-gradient based adversarial attacks. These classes are created by manipulating the input and output layers. We have proven empirically that owing to certain characteristics of the network, they provide a high robustness against these attacks, and can be used in fine tuning other models to increase defense against adversarial attacks.',\n",
       "  'authors': ['Jay N. Paranjape', 'Rahul Kumar Dubey', 'Vijendran V Gopalan'],\n",
       "  'published': '2020-06-02',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'stochastic-security-adversarial-defense-using',\n",
       "  'arxiv_id': '2005.13525',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2005.13525v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2005.13525v2.pdf',\n",
       "  'title': 'Stochastic Security: Adversarial Defense Using Long-Run Dynamics of Energy-Based Models',\n",
       "  'abstract': \"The vulnerability of deep networks to adversarial attacks is a central problem for deep learning from the perspective of both cognition and security. The current most successful defense method is to train a classifier using adversarial images created during learning. Another defense approach involves transformation or purification of the original input to remove adversarial signals before the image is classified. We focus on defending naturally-trained classifiers using Markov Chain Monte Carlo (MCMC) sampling with an Energy-Based Model (EBM) for adversarial purification. In contrast to adversarial training, our approach is intended to secure pre-existing and highly vulnerable classifiers. The memoryless behavior of long-run MCMC sampling will eventually remove adversarial signals, while metastable behavior preserves consistent appearance of MCMC samples after many steps to allow accurate long-run prediction. Balancing these factors can lead to effective purification and robust classification. We evaluate adversarial defense with an EBM using the strongest known attacks against purification. Our contributions are 1) an improved method for training EBM's with realistic long-run MCMC samples, 2) an Expectation-Over-Transformation (EOT) defense that resolves theoretical ambiguities for stochastic defenses and from which the EOT attack naturally follows, and 3) state-of-the-art adversarial defense for naturally-trained classifiers and competitive defense compared to adversarially-trained classifiers on Cifar-10, SVHN, and Cifar-100. Code and pre-trained models are available at https://github.com/point0bar1/ebm-defense.\",\n",
       "  'authors': ['Mitch Hill', 'Jonathan Mitchell', 'Song-Chun Zhu'],\n",
       "  'published': '2020-05-27',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': 'https://openreview.net/forum?id=gwFTuzxJW0',\n",
       "  'conference_url_pdf': 'https://openreview.net/pdf?id=gwFTuzxJW0',\n",
       "  'proceeding': 'iclr-2021-1'},\n",
       " {'id': 'revisiting-role-of-autoencoders-in',\n",
       "  'arxiv_id': '2005.10750',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2005.10750v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2005.10750v1.pdf',\n",
       "  'title': 'Revisiting Role of Autoencoders in Adversarial Settings',\n",
       "  'abstract': 'To combat against adversarial attacks, autoencoder structure is widely used to perform denoising which is regarded as gradient masking. In this paper, we revisit the role of autoencoders in adversarial settings. Through the comprehensive experimental results and analysis, this paper presents the inherent property of adversarial robustness in the autoencoders. We also found that autoencoders may use robust features that cause inherent adversarial robustness. We believe that our discovery of the adversarial robustness of the autoencoders can provide clues to the future research and applications for adversarial defense.',\n",
       "  'authors': ['Byeong Cheon Kim', 'Jung Uk Kim', 'Hakmin Lee', 'Yong Man Ro'],\n",
       "  'published': '2020-05-21',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'encryption-inspired-adversarial-defense-for',\n",
       "  'arxiv_id': '2005.07998',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2005.07998v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2005.07998v1.pdf',\n",
       "  'title': 'Encryption Inspired Adversarial Defense for Visual Classification',\n",
       "  'abstract': 'Conventional adversarial defenses reduce classification accuracy whether or not a model is under attacks. Moreover, most of image processing based defenses are defeated due to the problem of obfuscated gradients. In this paper, we propose a new adversarial defense which is a defensive transform for both training and test images inspired by perceptual image encryption methods. The proposed method utilizes a block-wise pixel shuffling method with a secret key. The experiments are carried out on both adaptive and non-adaptive maximum-norm bounded white-box attacks while considering obfuscated gradients. The results show that the proposed defense achieves high accuracy (91.55 %) on clean images and (89.66 %) on adversarial examples with noise distance of 8/255 on CIFAR-10 dataset. Thus, the proposed defense outperforms state-of-the-art adversarial defenses including latent adversarial training, adversarial training and thermometer encoding.',\n",
       "  'authors': ['MaungMaung AprilPyone', 'Hitoshi Kiya'],\n",
       "  'published': '2020-05-16',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'class-aware-domain-adaptation-for-improving',\n",
       "  'arxiv_id': '2005.04564',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2005.04564v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2005.04564v1.pdf',\n",
       "  'title': 'Class-Aware Domain Adaptation for Improving Adversarial Robustness',\n",
       "  'abstract': 'Recent works have demonstrated convolutional neural networks are vulnerable to adversarial examples, i.e., inputs to machine learning models that an attacker has intentionally designed to cause the models to make a mistake. To improve the adversarial robustness of neural networks, adversarial training has been proposed to train networks by injecting adversarial examples into the training data. However, adversarial training could overfit to a specific type of adversarial attack and also lead to standard accuracy drop on clean images. To this end, we propose a novel Class-Aware Domain Adaptation (CADA) method for adversarial defense without directly applying adversarial training. Specifically, we propose to learn domain-invariant features for adversarial examples and clean images via a domain discriminator. Furthermore, we introduce a class-aware component into the discriminator to increase the discriminative power of the network for adversarial examples. We evaluate our newly proposed approach using multiple benchmark datasets. The results demonstrate that our method can significantly improve the state-of-the-art of adversarial robustness for various attacks and maintain high performances on clean images.',\n",
       "  'authors': ['Xianxu Hou',\n",
       "   'Jingxin Liu',\n",
       "   'Bolei Xu',\n",
       "   'Xiaolong Wang',\n",
       "   'Bozhi Liu',\n",
       "   'Guoping Qiu'],\n",
       "  'published': '2020-05-10',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'parot-a-practical-framework-for-robust-deep',\n",
       "  'arxiv_id': '2001.02152',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2001.02152v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2001.02152v3.pdf',\n",
       "  'title': 'PaRoT: A Practical Framework for Robust Deep Neural Network Training',\n",
       "  'abstract': \"Deep Neural Networks (DNNs) are finding important applications in safety-critical systems such as Autonomous Vehicles (AVs), where perceiving the environment correctly and robustly is necessary for safe operation. Raising unique challenges for assurance due to their black-box nature, DNNs pose a fundamental problem for regulatory acceptance of these types of systems. Robust training --- training to minimize excessive sensitivity to small changes in input --- has emerged as one promising technique to address this challenge. However, existing robust training tools are inconvenient to use or apply to existing codebases and models: they typically only support a small subset of model elements and require users to extensively rewrite the training code. In this paper we introduce a novel framework, PaRoT, developed on the popular TensorFlow platform, that greatly reduces the barrier to entry. Our framework enables robust training to be performed on arbitrary DNNs without any rewrites to the model. We demonstrate that our framework's performance is comparable to prior art, and exemplify its ease of use on off-the-shelf, trained models and its testing capabilities on a real-world industrial application: a traffic light detection network.\",\n",
       "  'authors': ['Edward Ayers',\n",
       "   'Francisco Eiras',\n",
       "   'Majd Hawasly',\n",
       "   'Iain Whiteside'],\n",
       "  'published': '2020-01-07',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'rain-robust-and-accurate-classification',\n",
       "  'arxiv_id': '2004.14798',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2004.14798v4',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2004.14798v4.pdf',\n",
       "  'title': 'RAIN: A Simple Approach for Robust and Accurate Image Classification Networks',\n",
       "  'abstract': \"It has been shown that the majority of existing adversarial defense methods achieve robustness at the cost of sacrificing prediction accuracy. The undesirable severe drop in accuracy adversely affects the reliability of machine learning algorithms and prohibits their deployment in realistic applications. This paper aims to address this dilemma by proposing a novel preprocessing framework, which we term Robust and Accurate Image classificatioN(RAIN), to improve the robustness of given CNN classifiers and, at the same time, preserve their high prediction accuracies. RAIN introduces a new randomization-enhancement scheme. It applies randomization over inputs to break the ties between the model forward prediction path and the backward gradient path, thus improving the model robustness. However, similar to existing preprocessing-based methods, the randomized process will degrade the prediction accuracy. To understand why this is the case, we compare the difference between original and processed images, and find it is the loss of high-frequency components in the input image that leads to accuracy drop of the classifier. Based on this finding, RAIN enhances the input's high-frequency details to retain the CNN's high prediction accuracy. Concretely, RAIN consists of two novel randomization modules: randomized small circular shift (RdmSCS) and randomized down-upsampling (RdmDU). The RdmDU module randomly downsamples the input image, and then the RdmSCS module circularly shifts the input image along a randomly chosen direction by a small but random number of pixels. Finally, the RdmDU module performs upsampling with a detail-enhancement model, such as deep super-resolution networks. We conduct extensive experiments on the STL10 and ImageNet datasets to verify the effectiveness of RAIN against various types of adversarial attacks.\",\n",
       "  'authors': ['Jiawei Du',\n",
       "   'Hanshu Yan',\n",
       "   'Vincent Y. F. Tan',\n",
       "   'Joey Tianyi Zhou',\n",
       "   'Rick Siow Mong Goh',\n",
       "   'Jiashi Feng'],\n",
       "  'published': '2020-04-24',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'patchattack-a-black-box-texture-based-attack',\n",
       "  'arxiv_id': '2004.05682',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2004.05682v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2004.05682v2.pdf',\n",
       "  'title': 'PatchAttack: A Black-box Texture-based Attack with Reinforcement Learning',\n",
       "  'abstract': 'Patch-based attacks introduce a perceptible but localized change to the input that induces misclassification. A limitation of current patch-based black-box attacks is that they perform poorly for targeted attacks, and even for the less challenging non-targeted scenarios, they require a large number of queries. Our proposed PatchAttack is query efficient and can break models for both targeted and non-targeted attacks. PatchAttack induces misclassifications by superimposing small textured patches on the input image. We parametrize the appearance of these patches by a dictionary of class-specific textures. This texture dictionary is learned by clustering Gram matrices of feature activations from a VGG backbone. PatchAttack optimizes the position and texture parameters of each patch using reinforcement learning. Our experiments show that PatchAttack achieves > 99% success rate on ImageNet for a wide range of architectures, while only manipulating 3% of the image for non-targeted attacks and 10% on average for targeted attacks. Furthermore, we show that PatchAttack circumvents state-of-the-art adversarial defense methods successfully.',\n",
       "  'authors': ['Chenglin Yang',\n",
       "   'Adam Kortylewski',\n",
       "   'Cihang Xie',\n",
       "   'Yinzhi Cao',\n",
       "   'Alan Yuille'],\n",
       "  'published': '2020-04-12',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': 'https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5563_ECCV_2020_paper.php',\n",
       "  'conference_url_pdf': 'https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710681.pdf',\n",
       "  'proceeding': 'eccv-2020-8'},\n",
       " {'id': 'generative-adversarial-trainer-defense-to',\n",
       "  'arxiv_id': '1705.03387',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'http://arxiv.org/abs/1705.03387v2',\n",
       "  'url_pdf': 'http://arxiv.org/pdf/1705.03387v2.pdf',\n",
       "  'title': 'Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN',\n",
       "  'abstract': 'We propose a novel technique to make neural network robust to adversarial\\nexamples using a generative adversarial network. We alternately train both\\nclassifier and generator networks. The generator network generates an\\nadversarial perturbation that can easily fool the classifier network by using a\\ngradient of each image. Simultaneously, the classifier network is trained to\\nclassify correctly both original and adversarial images generated by the\\ngenerator. These procedures help the classifier network to become more robust\\nto adversarial perturbations. Furthermore, our adversarial training framework\\nefficiently reduces overfitting and outperforms other regularization methods\\nsuch as Dropout. We applied our method to supervised learning for CIFAR\\ndatasets, and experimantal results show that our method significantly lowers\\nthe generalization error of the network. To the best of our knowledge, this is\\nthe first method which uses GAN to improve supervised learning.',\n",
       "  'authors': ['Hyeungill Lee', 'Sungyeob Han', 'Jungwoo Lee'],\n",
       "  'published': '2017-05-09',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'physically-realizable-adversarial-examples',\n",
       "  'arxiv_id': '2004.00543',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2004.00543v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2004.00543v2.pdf',\n",
       "  'title': 'Physically Realizable Adversarial Examples for LiDAR Object Detection',\n",
       "  'abstract': 'Modern autonomous driving systems rely heavily on deep learning models to process point cloud sensory data; meanwhile, deep models have been shown to be susceptible to adversarial attacks with visually imperceptible perturbations. Despite the fact that this poses a security concern for the self-driving industry, there has been very little exploration in terms of 3D perception, as most adversarial attacks have only been applied to 2D flat images. In this paper, we address this issue and present a method to generate universal 3D adversarial objects to fool LiDAR detectors. In particular, we demonstrate that placing an adversarial object on the rooftop of any target vehicle to hide the vehicle entirely from LiDAR detectors with a success rate of 80%. We report attack results on a suite of detectors using various input representation of point clouds. We also conduct a pilot study on adversarial defense using data augmentation. This is one step closer towards safer self-driving under unseen conditions from limited training data.',\n",
       "  'authors': ['James Tu',\n",
       "   'Mengye Ren',\n",
       "   'Siva Manivasagam',\n",
       "   'Ming Liang',\n",
       "   'Bin Yang',\n",
       "   'Richard Du',\n",
       "   'Frank Cheng',\n",
       "   'Raquel Urtasun'],\n",
       "  'published': '2020-04-01',\n",
       "  'conference': 'physically-realizable-adversarial-examples-1',\n",
       "  'conference_url_abs': 'http://openaccess.thecvf.com/content_CVPR_2020/html/Tu_Physically_Realizable_Adversarial_Examples_for_LiDAR_Object_Detection_CVPR_2020_paper.html',\n",
       "  'conference_url_pdf': 'http://openaccess.thecvf.com/content_CVPR_2020/papers/Tu_Physically_Realizable_Adversarial_Examples_for_LiDAR_Object_Detection_CVPR_2020_paper.pdf',\n",
       "  'proceeding': 'cvpr-2020-6'},\n",
       " {'id': 'toward-adversarial-robustness-via-semi',\n",
       "  'arxiv_id': '2003.06974',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2003.06974v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2003.06974v3.pdf',\n",
       "  'title': 'Toward Adversarial Robustness via Semi-supervised Robust Training',\n",
       "  'abstract': 'Adversarial examples have been shown to be the severe threat to deep neural networks (DNNs). One of the most effective adversarial defense methods is adversarial training (AT) through minimizing the adversarial risk $R_{adv}$, which encourages both the benign example $x$ and its adversarially perturbed neighborhoods within the $\\\\ell_{p}$-ball to be predicted as the ground-truth label. In this work, we propose a novel defense method, the robust training (RT), by jointly minimizing two separated risks ($R_{stand}$ and $R_{rob}$), which is with respect to the benign example and its neighborhoods respectively. The motivation is to explicitly and jointly enhance the accuracy and the adversarial robustness. We prove that $R_{adv}$ is upper-bounded by $R_{stand} + R_{rob}$, which implies that RT has similar effect as AT. Intuitively, minimizing the standard risk enforces the benign example to be correctly predicted, and the robust risk minimization encourages the predictions of the neighbor examples to be consistent with the prediction of the benign example. Besides, since $R_{rob}$ is independent of the ground-truth label, RT is naturally extended to the semi-supervised mode ($i.e.$, SRT), to further enhance the adversarial robustness. Moreover, we extend the $\\\\ell_{p}$-bounded neighborhood to a general case, which covers different types of perturbations, such as the pixel-wise ($i.e.$, $x + \\\\delta$) or the spatial perturbation ($i.e.$, $ AX + b$). Extensive experiments on benchmark datasets not only verify the superiority of the proposed SRT method to state-of-the-art methods for defensing pixel-wise or spatial perturbations separately, but also demonstrate its robustness to both perturbations simultaneously. The code for reproducing main results is available at \\\\url{https://github.com/THUYimingLi/Semi-supervised_Robust_Training}.',\n",
       "  'authors': ['Yiming Li',\n",
       "   'Baoyuan Wu',\n",
       "   'Yan Feng',\n",
       "   'Yanbo Fan',\n",
       "   'Yong Jiang',\n",
       "   'Zhifeng Li',\n",
       "   'Shutao Xia'],\n",
       "  'published': '2020-03-16',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'learn2perturb-an-end-to-end-feature',\n",
       "  'arxiv_id': '2003.01090',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/2003.01090v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/2003.01090v2.pdf',\n",
       "  'title': 'Learn2Perturb: an End-to-end Feature Perturbation Learning to Improve Adversarial Robustness',\n",
       "  'abstract': 'While deep neural networks have been achieving state-of-the-art performance across a wide variety of applications, their vulnerability to adversarial attacks limits their widespread deployment for safety-critical applications. Alongside other adversarial defense approaches being investigated, there has been a very recent interest in improving adversarial robustness in deep neural networks through the introduction of perturbations during the training process. However, such methods leverage fixed, pre-defined perturbations and require significant hyper-parameter tuning that makes them very difficult to leverage in a general fashion. In this study, we introduce Learn2Perturb, an end-to-end feature perturbation learning approach for improving the adversarial robustness of deep neural networks. More specifically, we introduce novel perturbation-injection modules that are incorporated at each layer to perturb the feature space and increase uncertainty in the network. This feature perturbation is performed at both the training and the inference stages. Furthermore, inspired by the Expectation-Maximization, an alternating back-propagation training algorithm is introduced to train the network and noise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100 datasets show that the proposed Learn2Perturb method can result in deep neural networks which are $4-7\\\\%$ more robust on $l_{\\\\infty}$ FGSM and PDG adversarial attacks and significantly outperforms the state-of-the-art against $l_2$ $C\\\\&W$ attack and a wide range of well-known black-box attacks.',\n",
       "  'authors': ['Ahmadreza Jeddi',\n",
       "   'Mohammad Javad Shafiee',\n",
       "   'Michelle Karg',\n",
       "   'Christian Scharfenberger',\n",
       "   'Alexander Wong'],\n",
       "  'published': '2020-03-02',\n",
       "  'conference': 'learn2perturb-an-end-to-end-feature-1',\n",
       "  'conference_url_abs': 'http://openaccess.thecvf.com/content_CVPR_2020/html/Jeddi_Learn2Perturb_An_End-to-End_Feature_Perturbation_Learning_to_Improve_Adversarial_Robustness_CVPR_2020_paper.html',\n",
       "  'conference_url_pdf': 'http://openaccess.thecvf.com/content_CVPR_2020/papers/Jeddi_Learn2Perturb_An_End-to-End_Feature_Perturbation_Learning_to_Improve_Adversarial_Robustness_CVPR_2020_paper.pdf',\n",
       "  'proceeding': 'cvpr-2020-6'},\n",
       " {'id': 'smoothed-inference-for-adversarially-trained',\n",
       "  'arxiv_id': '1911.07198',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1911.07198v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1911.07198v2.pdf',\n",
       "  'title': 'Smoothed Inference for Adversarially-Trained Models',\n",
       "  'abstract': 'Deep neural networks are known to be vulnerable to adversarial attacks. Current methods of defense from such attacks are based on either implicit or explicit regularization, e.g., adversarial training. Randomized smoothing, the averaging of the classifier outputs over a random distribution centered in the sample, has been shown to guarantee the performance of a classifier subject to bounded perturbations of the input. In this work, we study the application of randomized smoothing as a way to improve performance on unperturbed data as well as to increase robustness to adversarial attacks. The proposed technique can be applied on top of any existing adversarial defense, but works particularly well with the randomized approaches. We examine its performance on common white-box (PGD) and black-box (transfer and NAttack) attacks on CIFAR-10 and CIFAR-100, substantially outperforming previous art for most scenarios and comparable on others. For example, we achieve 60.4% accuracy under a PGD attack on CIFAR-10 using ResNet-20, outperforming previous art by 11.7%. Since our method is based on sampling, it lends itself well for trading-off between the model inference complexity and its performance. A reference implementation of the proposed techniques is provided at https://github.com/yanemcovsky/SIAM',\n",
       "  'authors': ['Yaniv Nemcovsky',\n",
       "   'Evgenii Zheltonozhskii',\n",
       "   'Chaim Baskin',\n",
       "   'Brian Chmiel',\n",
       "   'Maxim Fishman',\n",
       "   'Alex M. Bronstein',\n",
       "   'Avi Mendelson'],\n",
       "  'published': '2019-11-17',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'enforcing-linearity-in-dnn-succours',\n",
       "  'arxiv_id': '1910.08108',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1910.08108v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1910.08108v2.pdf',\n",
       "  'title': 'Enforcing Linearity in DNN succours Robustness and Adversarial Image Generation',\n",
       "  'abstract': 'Recent studies on the adversarial vulnerability of neural networks have shown that models trained with the objective of minimizing an upper bound on the worst-case loss over all possible adversarial perturbations improve robustness against adversarial attacks. Beside exploiting adversarial training framework, we show that by enforcing a Deep Neural Network (DNN) to be linear in transformed input and feature space improves robustness significantly. We also demonstrate that by augmenting the objective function with Local Lipschitz regularizer boost robustness of the model further. Our method outperforms most sophisticated adversarial training methods and achieves state of the art adversarial accuracy on MNIST, CIFAR10 and SVHN dataset. In this paper, we also propose a novel adversarial image generation method by leveraging Inverse Representation Learning and Linearity aspect of an adversarially trained deep neural network classifier.',\n",
       "  'authors': ['Anindya Sarkar', 'Nikhil Kumar Gupta', 'Raghu Iyengar'],\n",
       "  'published': '2019-10-17',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'parametric-noise-injection-trainable',\n",
       "  'arxiv_id': '1811.09310',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'http://arxiv.org/abs/1811.09310v1',\n",
       "  'url_pdf': 'http://arxiv.org/pdf/1811.09310v1.pdf',\n",
       "  'title': 'Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness against Adversarial Attack',\n",
       "  'abstract': \"Recent development in the field of Deep Learning have exposed the underlying\\nvulnerability of Deep Neural Network (DNN) against adversarial examples. In\\nimage classification, an adversarial example is a carefully modified image that\\nis visually imperceptible to the original image but can cause DNN model to\\nmisclassify it. Training the network with Gaussian noise is an effective\\ntechnique to perform model regularization, thus improving model robustness\\nagainst input variation. Inspired by this classical method, we explore to\\nutilize the regularization characteristic of noise injection to improve DNN's\\nrobustness against adversarial attack. In this work, we propose\\nParametric-Noise-Injection (PNI) which involves trainable Gaussian noise\\ninjection at each layer on either activation or weights through solving the\\nmin-max optimization problem, embedded with adversarial training. These\\nparameters are trained explicitly to achieve improved robustness. To the best\\nof our knowledge, this is the first work that uses trainable noise injection to\\nimprove network robustness against adversarial attacks, rather than manually\\nconfiguring the injected noise level through cross-validation. The extensive\\nresults show that our proposed PNI technique effectively improves the\\nrobustness against a variety of powerful white-box and black-box attacks such\\nas PGD, C & W, FGSM, transferable attack and ZOO attack. Last but not the\\nleast, PNI method improves both clean- and perturbed-data accuracy in\\ncomparison to the state-of-the-art defense methods, which outperforms current\\nunbroken PGD defense by 1.1 % and 6.8 % on clean test data and perturbed test\\ndata respectively using Resnet-20 architecture.\",\n",
       "  'authors': ['Adnan Siraj Rakin', 'Zhezhi He', 'Deliang Fan'],\n",
       "  'published': '2018-11-22',\n",
       "  'conference': 'parametric-noise-injection-trainable-1',\n",
       "  'conference_url_abs': 'http://openaccess.thecvf.com/content_CVPR_2019/html/He_Parametric_Noise_Injection_Trainable_Randomness_to_Improve_Deep_Neural_Network_CVPR_2019_paper.html',\n",
       "  'conference_url_pdf': 'http://openaccess.thecvf.com/content_CVPR_2019/papers/He_Parametric_Noise_Injection_Trainable_Randomness_to_Improve_Deep_Neural_Network_CVPR_2019_paper.pdf',\n",
       "  'proceeding': 'cvpr-2019-6'},\n",
       " {'id': 'learning-to-defense-by-learning-to-attack',\n",
       "  'arxiv_id': '1811.01213',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1811.01213v4',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1811.01213v4.pdf',\n",
       "  'title': 'Learning to Defense by Learning to Attack',\n",
       "  'abstract': 'Adversarial training is a principled approach for training robust neural networks. From an optimization perspective, adversarial training is solving a bilevel optimization problem (a general form of minimax approaches): The leader problem targets on learning a robust classifier; The follower problem tries to generate adversarial samples. Unfortunately, such a bilevel problem is very challenging to solve due to its highly complicated structure. This work proposes a new adversarial training method based on a generic learning-to-learn (L2L) framework. Specifically, instead of applying hand-designed algorithms for the follower problem, we learn an optimizer, which is parametrized by a convolutional neural network. Meanwhile, a robust classifier is learned to defense the adversarial attacks generated by the learned optimizer. Our experiments over CIFAR datasets demonstrate that L2L improves upon existing methods in both robust accuracy and computational efficiency. Moreover, the L2L framework can be extended to other popular bilevel problems in machine learning.',\n",
       "  'authors': ['Haoming Jiang',\n",
       "   'Zhehui Chen',\n",
       "   'Yuyang Shi',\n",
       "   'Bo Dai',\n",
       "   'Tuo Zhao'],\n",
       "  'published': '2018-11-03',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'mimicgan-robust-projection-onto-image',\n",
       "  'arxiv_id': '1912.07748',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1912.07748v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1912.07748v3.pdf',\n",
       "  'title': 'MimicGAN: Robust Projection onto Image Manifolds with Corruption Mimicking',\n",
       "  'abstract': 'In the past few years, Generative Adversarial Networks (GANs) have dramatically advanced our ability to represent and parameterize high-dimensional, non-linear image manifolds. As a result, they have been widely adopted across a variety of applications, ranging from challenging inverse problems like image completion, to problems such as anomaly detection and adversarial defense. A recurring theme in many of these applications is the notion of projecting an image observation onto the manifold that is inferred by the generator. In this context, Projected Gradient Descent (PGD) has been the most popular approach, which essentially optimizes for a latent vector that minimizes the discrepancy between a generated image and the given observation. However, PGD is a brittle optimization technique that fails to identify the right projection (or latent vector) when the observation is corrupted, or perturbed even by a small amount. Such corruptions are common in the real world, for example images in the wild come with unknown crops, rotations, missing pixels, or other kinds of non-linear distributional shifts which break current encoding methods, rendering downstream applications unusable. To address this, we propose corruption mimicking -- a new robust projection technique, that utilizes a surrogate network to approximate the unknown corruption directly at test time, without the need for additional supervision or data augmentation. The proposed method is significantly more robust than PGD and other competing methods under a wide variety of corruptions, thereby enabling a more effective use of GANs in real-world applications. More importantly, we show that our approach produces state-of-the-art performance in several GAN-based applications -- anomaly detection, domain adaptation, and adversarial defense, that benefit from an accurate projection.',\n",
       "  'authors': ['Rushil Anirudh',\n",
       "   'Jayaraman J. Thiagarajan',\n",
       "   'Bhavya Kailkhura',\n",
       "   'Timo Bremer'],\n",
       "  'published': '2019-12-16',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'gated-convolutional-networks-with-hybrid',\n",
       "  'arxiv_id': '1908.09699',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1908.09699v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1908.09699v3.pdf',\n",
       "  'title': 'Gated Convolutional Networks with Hybrid Connectivity for Image Classification',\n",
       "  'abstract': 'We propose a simple yet effective method to reduce the redundancy of DenseNet by substantially decreasing the number of stacked modules by replacing the original bottleneck by our SMG module, which is augmented by local residual. Furthermore, SMG module is equipped with an efficient two-stage pipeline, which aims to DenseNet-like architectures that need to integrate all previous outputs, i.e., squeezing the incoming informative but redundant features gradually by hierarchical convolutions as a hourglass shape and then exciting it by multi-kernel depthwise convolutions, the output of which would be compact and hold more informative multi-scale features. We further develop a forget and an update gate by introducing the popular attention modules to implement the effective fusion instead of a simple addition between reused and new features. Due to the Hybrid Connectivity (nested combination of global dense and local residual) and Gated mechanisms, we called our network as the HCGNet. Experimental results on CIFAR and ImageNet datasets show that HCGNet is more prominently efficient than DenseNet, and can also significantly outperform state-of-the-art networks with less complexity. Moreover, HCGNet also shows the remarkable interpretability and robustness by network dissection and adversarial defense, respectively. On MS-COCO, HCGNet can consistently learn better features than popular backbones.',\n",
       "  'authors': ['Chuanguang Yang',\n",
       "   'Zhulin An',\n",
       "   'Hui Zhu',\n",
       "   'Xiaolong Hu',\n",
       "   'Kun Zhang',\n",
       "   'Kaiqiang Xu',\n",
       "   'Chao Li',\n",
       "   'Yongjun Xu'],\n",
       "  'published': '2019-08-26',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'defensive-few-shot-adversarial-learning',\n",
       "  'arxiv_id': '1911.06968',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1911.06968v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1911.06968v1.pdf',\n",
       "  'title': 'Defensive Few-shot Adversarial Learning',\n",
       "  'abstract': 'The robustness of deep learning models against adversarial attacks has received increasing attention in recent years. However, both deep learning and adversarial training rely on the availability of a large amount of labeled data and usually do not generalize well to new, unseen classes when only a few training samples are accessible. To address this problem, we explicitly introduce a new challenging problem -- how to learn a robust deep model with limited training samples per class, called defensive few-shot learning in this paper. Simply employing the existing adversarial training techniques in the literature cannot solve this problem. This is because few-shot learning needs to learn transferable knowledge from disjoint auxiliary data, and thus it is invalid to assume the sample-level distribution consistency between the training and test sets as commonly assumed in existing adversarial training techniques. In this paper, instead of assuming such a distribution consistency, we propose to make this assumption at a task-level in the episodic training paradigm in order to better transfer the defense knowledge. Furthermore, inside each task, we design a task-conditioned distribution constraint to narrow the distribution gap between clean and adversarial examples at a sample-level. These give rise to a novel mechanism called multi-level distribution based adversarial training (MDAT) for learning transferable adversarial defense. In addition, a unified $\\\\mathcal{F}_{\\\\beta}$ score is introduced to evaluate different defense methods under the same principle. Extensive experiments demonstrate that MDAT achieves higher effectiveness and robustness over existing alternatives in the few-shot case.',\n",
       "  'authors': ['Wenbin Li',\n",
       "   'Lei Wang',\n",
       "   'Xingxing Zhang',\n",
       "   'Jing Huo',\n",
       "   'Yang Gao',\n",
       "   'Jiebo Luo'],\n",
       "  'published': '2019-11-16',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'error-correcting-output-codes-improve',\n",
       "  'arxiv_id': None,\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'http://papers.nips.cc/paper/9070-error-correcting-output-codes-improve-probability-estimation-and-adversarial-robustness-of-deep-neural-networks',\n",
       "  'url_pdf': 'http://papers.nips.cc/paper/9070-error-correcting-output-codes-improve-probability-estimation-and-adversarial-robustness-of-deep-neural-networks.pdf',\n",
       "  'title': 'Error Correcting Output Codes Improve Probability Estimation and Adversarial Robustness of Deep Neural Networks',\n",
       "  'abstract': 'Modern machine learning systems are susceptible to adversarial examples; inputs\\nwhich clearly preserve the characteristic semantics of a given class, but whose\\nclassification is (usually confidently) incorrect. Existing approaches to adversarial\\ndefense generally rely on modifying the input, e.g. quantization, or the learned\\nmodel parameters, e.g. via adversarial training. However, recent research has\\nshown that most such approaches succumb to adversarial examples when different norms or more sophisticated adaptive attacks are considered. In this paper, we propose a fundamentally different approach which instead changes the way the output is represented and decoded. This simple approach achieves state-of-the-art robustness to adversarial examples for L 2 and L  based adversarial perturbations on MNIST and CIFAR10. In addition, even under strong white-box attacks, we find that our model often assigns adversarial examples a low probability; those with high probability are usually interpretable, i.e. perturbed towards the perceptual boundary between the original and adversarial class. Our approach has several advantages: it yields more meaningful probability estimates, is extremely fast during training and testing, requires essentially no architectural changes to existing discriminative learning pipelines, is wholly complementary to other defense approaches including adversarial training, and does not sacrifice benign test set performance',\n",
       "  'authors': ['Gunjan Verma', 'Ananthram Swami'],\n",
       "  'published': '2019-12-01',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': 'neurips-2019-12'},\n",
       " {'id': 'graphdefense-towards-robust-graph',\n",
       "  'arxiv_id': '1911.04429',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1911.04429v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1911.04429v1.pdf',\n",
       "  'title': 'GraphDefense: Towards Robust Graph Convolutional Networks',\n",
       "  'abstract': 'In this paper, we study the robustness of graph convolutional networks (GCNs). Despite the good performance of GCNs on graph semi-supervised learning tasks, previous works have shown that the original GCNs are very unstable to adversarial perturbations. In particular, we can observe a severe performance degradation by slightly changing the graph adjacency matrix or the features of a few nodes, making it unsuitable for security-critical applications. Inspired by the previous works on adversarial defense for deep neural networks, and especially adversarial training algorithm, we propose a method called GraphDefense to defend against the adversarial perturbations. In addition, for our defense method, we could still maintain semi-supervised learning settings, without a large label rate. We also show that adversarial training in features is equivalent to adversarial training for edges with a small perturbation. Our experiments show that the proposed defense methods successfully increase the robustness of Graph Convolutional Networks. Furthermore, we show that with careful design, our proposed algorithm can scale to large graphs, such as Reddit dataset.',\n",
       "  'authors': ['Xiaoyun Wang', 'Xuanqing Liu', 'Cho-Jui Hsieh'],\n",
       "  'published': '2019-11-11',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'the-vulnerabilities-of-graph-convolutional',\n",
       "  'arxiv_id': '1903.01610',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1903.01610v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1903.01610v3.pdf',\n",
       "  'title': 'Adversarial Examples on Graph Data: Deep Insights into Attack and Defense',\n",
       "  'abstract': 'Graph deep learning models, such as graph convolutional networks (GCN) achieve remarkable performance for tasks on graph data. Similar to other types of deep models, graph deep learning models often suffer from adversarial attacks. However, compared with non-graph data, the discrete features, graph connections and different definitions of imperceptible perturbations bring unique challenges and opportunities for the adversarial attacks and defenses for graph data. In this paper, we propose both attack and defense techniques. For attack, we show that the discreteness problem could easily be resolved by introducing integrated gradients which could accurately reflect the effect of perturbing certain features or edges while still benefiting from the parallel computations. For defense, we observe that the adversarially manipulated graph for the targeted attack differs from normal graphs statistically. Based on this observation, we propose a defense approach which inspects the graph and recovers the potential adversarial perturbations. Our experiments on a number of datasets show the effectiveness of the proposed methods.',\n",
       "  'authors': ['Huijun Wu',\n",
       "   'Chen Wang',\n",
       "   'Yuriy Tyshetskiy',\n",
       "   'Andrew Docherty',\n",
       "   'Kai Lu',\n",
       "   'Liming Zhu'],\n",
       "  'published': '2019-03-05',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'adversarial-defense-via-local-flatness',\n",
       "  'arxiv_id': '1910.12165',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1910.12165v4',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1910.12165v4.pdf',\n",
       "  'title': 'Adversarial Defense via Local Flatness Regularization',\n",
       "  'abstract': 'Adversarial defense is a popular and important research area. Due to its intrinsic mechanism, one of the most straightforward and effective ways of defending attacks is to analyze the property of loss surface in the input space. In this paper, we define the local flatness of the loss surface as the maximum value of the chosen norm of the gradient regarding to the input within a neighborhood centered on the benign sample, and discuss the relationship between the local flatness and adversarial vulnerability. Based on the analysis, we propose a novel defense approach via regularizing the local flatness, dubbed local flatness regularization (LFR). We also demonstrate the effectiveness of the proposed method from other perspectives, such as human visual mechanism, and analyze the relationship between LFR and other related methods theoretically. Experiments are conducted to verify our theory and demonstrate the superiority of the proposed method.',\n",
       "  'authors': ['Jia Xu', 'Yiming Li', 'Yong Jiang', 'Shu-Tao Xia'],\n",
       "  'published': '2019-10-27',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'adversarial-defense-via-learning-to-generate',\n",
       "  'arxiv_id': None,\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'http://openaccess.thecvf.com/content_ICCV_2019/html/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.html',\n",
       "  'url_pdf': 'http://openaccess.thecvf.com/content_ICCV_2019/papers/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.pdf',\n",
       "  'title': 'Adversarial Defense via Learning to Generate Diverse Attacks',\n",
       "  'abstract': 'With the remarkable success of deep learning, Deep Neural Networks (DNNs) have been applied as dominant tools to various machine learning domains. Despite this success, however, it has been found that DNNs are surprisingly vulnerable to malicious attacks; adding a small, perceptually indistinguishable perturbations to the data can easily degrade classification performance. Adversarial training is an effective defense strategy to train a robust classifier. In this work, we propose to utilize the generator to learn how to create adversarial examples. Unlike the existing approaches that create a one-shot perturbation by a deterministic generator, we propose a recursive and stochastic generator that produces much stronger and diverse perturbations that comprehensively reveal the vulnerability of the target classifier. Our experiment results on MNIST and CIFAR-10 datasets show that the classifier adversarially trained with our method yields more robust performance over various white-box and black-box attacks.\\r',\n",
       "  'authors': ['Yunseok Jang',\n",
       "   ' Tianchen Zhao',\n",
       "   ' Seunghoon Hong',\n",
       "   ' Honglak Lee'],\n",
       "  'published': '2019-10-01',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': 'iccv-2019-10'},\n",
       " {'id': 'a-new-defense-against-adversarial-images',\n",
       "  'arxiv_id': '1910.07629',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1910.07629v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1910.07629v2.pdf',\n",
       "  'title': 'A New Defense Against Adversarial Images: Turning a Weakness into a Strength',\n",
       "  'abstract': 'Natural images are virtually surrounded by low-density misclassified regions that can be efficiently discovered by gradient-guided search --- enabling the generation of adversarial images. While many techniques for detecting these attacks have been proposed, they are easily bypassed when the adversary has full knowledge of the detection mechanism and adapts the attack strategy accordingly. In this paper, we adopt a novel perspective and regard the omnipresence of adversarial perturbations as a strength rather than a weakness. We postulate that if an image has been tampered with, these adversarial directions either become harder to find with gradient methods or have substantially higher density than for natural images. We develop a practical test for this signature characteristic to successfully detect adversarial attacks, achieving unprecedented accuracy under the white-box setting where the adversary is given full knowledge of our detection mechanism.',\n",
       "  'authors': ['Tao Yu',\n",
       "   'Shengyuan Hu',\n",
       "   'Chuan Guo',\n",
       "   'Wei-Lun Chao',\n",
       "   'Kilian Q. Weinberger'],\n",
       "  'published': '2019-10-16',\n",
       "  'conference': 'a-new-defense-against-adversarial-images-1',\n",
       "  'conference_url_abs': 'http://papers.nips.cc/paper/8441-a-new-defense-against-adversarial-images-turning-a-weakness-into-a-strength',\n",
       "  'conference_url_pdf': 'http://papers.nips.cc/paper/8441-a-new-defense-against-adversarial-images-turning-a-weakness-into-a-strength.pdf',\n",
       "  'proceeding': 'neurips-2019-12'},\n",
       " {'id': 'the-limitations-of-deep-learning-in',\n",
       "  'arxiv_id': '1511.07528',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'http://arxiv.org/abs/1511.07528v1',\n",
       "  'url_pdf': 'http://arxiv.org/pdf/1511.07528v1.pdf',\n",
       "  'title': 'The Limitations of Deep Learning in Adversarial Settings',\n",
       "  'abstract': 'Deep learning takes advantage of large datasets and computationally efficient\\ntraining algorithms to outperform other approaches at various machine learning\\ntasks. However, imperfections in the training phase of deep neural networks\\nmake them vulnerable to adversarial samples: inputs crafted by adversaries with\\nthe intent of causing deep neural networks to misclassify. In this work, we\\nformalize the space of adversaries against deep neural networks (DNNs) and\\nintroduce a novel class of algorithms to craft adversarial samples based on a\\nprecise understanding of the mapping between inputs and outputs of DNNs. In an\\napplication to computer vision, we show that our algorithms can reliably\\nproduce samples correctly classified by human subjects but misclassified in\\nspecific targets by a DNN with a 97% adversarial success rate while only\\nmodifying on average 4.02% of the input features per sample. We then evaluate\\nthe vulnerability of different sample classes to adversarial perturbations by\\ndefining a hardness measure. Finally, we describe preliminary work outlining\\ndefenses against adversarial samples by defining a predictive measure of\\ndistance between a benign input and a target classification.',\n",
       "  'authors': ['Nicolas Papernot',\n",
       "   'Patrick McDaniel',\n",
       "   'Somesh Jha',\n",
       "   'Matt Fredrikson',\n",
       "   'Z. Berkay Celik',\n",
       "   'Ananthram Swami'],\n",
       "  'published': '2015-11-24',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'adversarial-examples-for-electrocardiograms',\n",
       "  'arxiv_id': '1905.05163',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1905.05163v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1905.05163v2.pdf',\n",
       "  'title': 'Adversarial Examples for Electrocardiograms',\n",
       "  'abstract': 'In recent years, the electrocardiogram (ECG) has seen a large diffusion in both medical and commercial applications, fueled by the rise of single-lead versions. Single-lead ECG can be embedded in medical devices and wearable products such as the injectable Medtronic Linq monitor, the iRhythm Ziopatch wearable monitor, and the Apple Watch Series 4. Recently, deep neural networks have been used to automatically analyze ECG tracings, outperforming even physicians specialized in cardiac electrophysiology in detecting certain rhythm irregularities. However, deep learning classifiers have been shown to be brittle to adversarial examples, which are examples created to look incontrovertibly belonging to a certain class to a human eye but contain subtle features that fool the classifier into misclassifying them into the wrong class. Very recently, adversarial examples have also been created for medical-related tasks. Yet, traditional attack methods to create adversarial examples, such as projected gradient descent (PGD) do not extend directly to ECG signals, as they generate examples that introduce square wave artifacts that are not physiologically plausible. Here, we developed a method to construct smoothed adversarial examples for single-lead ECG. First, we implemented a neural network model achieving state-of-the-art performance on the data from the 2017 PhysioNet/Computing-in-Cardiology Challenge for arrhythmia detection from single lead ECG classification. For this model, we utilized a new technique to generate smoothed examples to produce signals that are 1) indistinguishable to cardiologists from the original examples and 2) incorrectly classified by the neural network. Finally, we show that adversarial examples are not unique and provide a general technique to collate and perturb known adversarial examples to create new ones.',\n",
       "  'authors': ['Xintian Han',\n",
       "   'Yuxuan Hu',\n",
       "   'Luca Foschini',\n",
       "   'Larry Chinitz',\n",
       "   'Lior Jankelson',\n",
       "   'Rajesh Ranganath'],\n",
       "  'published': '2019-05-13',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'training-robust-deep-neural-networks-via',\n",
       "  'arxiv_id': '1909.09034',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1909.09034v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1909.09034v2.pdf',\n",
       "  'title': 'Training Robust Deep Neural Networks via Adversarial Noise Propagation',\n",
       "  'abstract': 'In practice, deep neural networks have been found to be vulnerable to various types of noise, such as adversarial examples and corruption. Various adversarial defense methods have accordingly been developed to improve adversarial robustness for deep models. However, simply training on data mixed with adversarial examples, most of these models still fail to defend against the generalized types of noise. Motivated by the fact that hidden layers play a highly important role in maintaining a robust model, this paper proposes a simple yet powerful training algorithm, named \\\\emph{Adversarial Noise Propagation} (ANP), which injects noise into the hidden layers in a layer-wise manner. ANP can be implemented efficiently by exploiting the nature of the backward-forward training style. Through thorough investigations, we determine that different hidden layers make different contributions to model robustness and clean accuracy, while shallow layers are comparatively more critical than deep layers. Moreover, our framework can be easily combined with other adversarial training methods to further improve model robustness by exploiting the potential of hidden layers. Extensive experiments on MNIST, CIFAR-10, CIFAR-10-C, CIFAR-10-P, and ImageNet demonstrate that ANP enables the strong robustness for deep models against both adversarial and corrupted ones, and also significantly outperforms various adversarial defense methods.',\n",
       "  'authors': ['Aishan Liu',\n",
       "   'Xianglong Liu',\n",
       "   'Chongzhi Zhang',\n",
       "   'Hang Yu',\n",
       "   'Qiang Liu',\n",
       "   'Dacheng Tao'],\n",
       "  'published': '2019-09-19',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'natural-language-adversarial-attacks-and',\n",
       "  'arxiv_id': '1909.06723',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1909.06723v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1909.06723v3.pdf',\n",
       "  'title': 'Natural Language Adversarial Attacks and Defenses in Word Level',\n",
       "  'abstract': 'In recent years, inspired by a mass of researches on adversarial examples for computer vision, there has been a growing interest in designing adversarial attacks for Natural Language Processing (NLP) tasks, followed by very few works of adversarial defenses for NLP. To our knowledge, there exists no defense method against the successful synonym substitution based attacks that aim to satisfy all the lexical, grammatical, semantic constraints and thus are hard to be perceived by humans. We contribute to fill this gap and propose a novel adversarial defense method called \\\\textit{Synonym Encoding Method} (SEM), which inserts an encoder before the input layer of the model and then trains the model to eliminate adversarial perturbations. Extensive experiments demonstrate that SEM can efficiently defend current best synonym substitution based adversarial attacks with little decay on the accuracy for benign examples. To better evaluate SEM, we also design a strong attack method called Improved Genetic Algorithm (IGA) that adopts the genetic metaheuristic for synonym substitution based attacks. Compared with the first genetic based adversarial attack proposed in 2018, IGA can achieve higher attack success rate with lower word substitution rate, at the same time maintain the transferability of adversarial examples.',\n",
       "  'authors': ['Xiaosen Wang', 'Hao Jin', 'Kun He'],\n",
       "  'published': '2019-09-15',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'defending-against-adversarial-attacks-by-3',\n",
       "  'arxiv_id': '1909.06137',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1909.06137v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1909.06137v1.pdf',\n",
       "  'title': 'Defending Against Adversarial Attacks by Suppressing the Largest Eigenvalue of Fisher Information Matrix',\n",
       "  'abstract': 'We propose a scheme for defending against adversarial attacks by suppressing the largest eigenvalue of the Fisher information matrix (FIM). Our starting point is one explanation on the rationale of adversarial examples. Based on the idea of the difference between a benign sample and its adversarial example is measured by the Euclidean norm, while the difference between their classification probability densities at the last (softmax) layer of the network could be measured by the Kullback-Leibler (KL) divergence, the explanation shows that the output difference is a quadratic form of the input difference. If the eigenvalue of this quadratic form (a.k.a. FIM) is large, the output difference becomes large even when the input difference is small, which explains the adversarial phenomenon. This makes the adversarial defense possible by controlling the eigenvalues of the FIM. Our solution is adding one term representing the trace of the FIM to the loss function of the original network, as the largest eigenvalue is bounded by the trace. Our defensive scheme is verified by experiments using a variety of common attacking methods on typical deep neural networks, e.g. LeNet, VGG and ResNet, with datasets MNIST, CIFAR-10, and German Traffic Sign Recognition Benchmark (GTSRB). Our new network, after adopting the novel loss function and retraining, has an effective and robust defensive capability, as it decreases the fooling ratio of the generated adversarial examples, and remains the classification accuracy of the original network.',\n",
       "  'authors': ['Chaomin Shen', 'Yaxin Peng', 'Guixu Zhang', 'Jinsong Fan'],\n",
       "  'published': '2019-09-13',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'white-box-adversarial-defense-via-self',\n",
       "  'arxiv_id': '1909.06271',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1909.06271v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1909.06271v1.pdf',\n",
       "  'title': 'White-Box Adversarial Defense via Self-Supervised Data Estimation',\n",
       "  'abstract': 'In this paper, we study the problem of how to defend classifiers against adversarial attacks that fool the classifiers using subtly modified input data. In contrast to previous works, here we focus on the white-box adversarial defense where the attackers are granted full access to not only the classifiers but also defenders to produce as strong attacks as possible. In such a context we propose viewing a defender as a functional, a higher-order function that takes functions as its argument to represent a function space, rather than fixed functions conventionally. From this perspective, a defender should be realized and optimized individually for each adversarial input. To this end, we propose RIDE, an efficient and provably convergent self-supervised learning algorithm for individual data estimation to protect the predictions from adversarial attacks. We demonstrate the significant improvement of adversarial defense performance on image recognition, eg, 98%, 76%, 43% test accuracy on MNIST, CIFAR-10, and ImageNet datasets respectively under the state-of-the-art BPDA attacker.',\n",
       "  'authors': ['Zudi Lin', 'Hanspeter Pfister', 'Ziming Zhang'],\n",
       "  'published': '2019-09-13',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'transferable-adversarial-robustness-using',\n",
       "  'arxiv_id': '1909.05921',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1909.05921v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1909.05921v3.pdf',\n",
       "  'title': 'Towards Model-Agnostic Adversarial Defenses using Adversarially Trained Autoencoders',\n",
       "  'abstract': 'Adversarial machine learning is a well-studied field of research where an adversary causes predictable errors in a machine learning algorithm through precise manipulation of the input. Numerous techniques have been proposed to harden machine learning algorithms and mitigate the effect of adversarial attacks. Of these techniques, adversarial training, which augments the training data with adversarial samples, has proven to be an effective defense with respect to a certain class of attacks. However, adversarial training is computationally expensive and its improvements are limited to a single model. In this work, we take a first step toward creating a model-agnostic adversarial defense. We propose Adversarially-Trained Autoencoder Augmentation (AAA), the first model-agnostic adversarial defense that is robust against certain adaptive adversaries. We show that AAA allows us to achieve a partially model-agnostic defense by training a single autoencoder to protect multiple pre-trained classifiers; achieving adversarial performance on par or better than adversarial training without modifying the classifiers. Furthermore, we demonstrate that AAA can be used to create a fully model-agnostic defense for MNIST and Fashion MNIST datasets by improving the adversarial performance of a never before seen pre-trained classifier by at least 45% with no additional training. Finally, using a natural image corruption dataset, we show that our approach improves robustness to naturally corrupted images,which has been identified as strongly indicative of true adversarial robustness.',\n",
       "  'authors': ['Pratik Vaishnavi',\n",
       "   'Kevin Eykholt',\n",
       "   'Atul Prakash',\n",
       "   'Amir Rahmati'],\n",
       "  'published': '2019-09-12',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': '190808016',\n",
       "  'arxiv_id': '1908.08016',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1908.08016v2',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1908.08016v2.pdf',\n",
       "  'title': 'Testing Robustness Against Unforeseen Adversaries',\n",
       "  'abstract': \"Most existing adversarial defenses only measure robustness to L_p adversarial attacks. Not only are adversaries unlikely to exclusively create small L_p perturbations, adversaries are unlikely to remain fixed. Adversaries adapt and evolve their attacks; hence adversarial defenses must be robust to a broad range of unforeseen attacks. We address this discrepancy between research and reality by proposing a new evaluation framework called ImageNet-UA. Our framework enables the research community to test ImageNet model robustness against attacks not encountered during training. To create ImageNet-UA's diverse attack suite, we introduce a total of four novel adversarial attacks. We also demonstrate that, in comparison to ImageNet-UA, prevailing L_inf robustness assessments give a narrow account of model robustness. By evaluating current defenses with ImageNet-UA, we find they provide little robustness to unforeseen attacks. We hope the greater variety and realism of ImageNet-UA enables development of more robust defenses which can generalize beyond attacks seen during training.\",\n",
       "  'authors': ['Daniel Kang',\n",
       "   'Yi Sun',\n",
       "   'Dan Hendrycks',\n",
       "   'Tom Brown',\n",
       "   'Jacob Steinhardt'],\n",
       "  'published': '2019-08-21',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'adversarial-defense-by-suppressing-high',\n",
       "  'arxiv_id': '1908.06566',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1908.06566v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1908.06566v3.pdf',\n",
       "  'title': 'Adversarial Defense by Suppressing High-frequency Components',\n",
       "  'abstract': 'Recent works show that deep neural networks trained on image classification dataset bias towards textures. Those models are easily fooled by applying small high-frequency perturbations to clean images. In this paper, we learn robust image classification models by removing high-frequency components. Specifically, we develop a differentiable high-frequency suppression module based on discrete Fourier transform (DFT). Combining with adversarial training, we won the 5th place in the IJCAI-2019 Alibaba Adversarial AI Challenge. Our code is available online.',\n",
       "  'authors': ['Zhendong Zhang', 'Cheolkon Jung', 'Xiaolong Liang'],\n",
       "  'published': '2019-08-19',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None},\n",
       " {'id': 'improving-adversarial-robustness-via-guided',\n",
       "  'arxiv_id': '1903.09799',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1903.09799v3',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1903.09799v3.pdf',\n",
       "  'title': 'Improving Adversarial Robustness via Guided Complement Entropy',\n",
       "  'abstract': 'Adversarial robustness has emerged as an important topic in deep learning as carefully crafted attack samples can significantly disturb the performance of a model. Many recent methods have proposed to improve adversarial robustness by utilizing adversarial training or model distillation, which adds additional procedures to model training. In this paper, we propose a new training paradigm called Guided Complement Entropy (GCE) that is capable of achieving \"adversarial defense for free,\" which involves no additional procedures in the process of improving adversarial robustness. In addition to maximizing model probabilities on the ground-truth class like cross-entropy, we neutralize its probabilities on the incorrect classes along with a \"guided\" term to balance between these two terms. We show in the experiments that our method achieves better model robustness with even better performance compared to the commonly used cross-entropy training objective. We also show that our method can be used orthogonal to adversarial training across well-known methods with noticeable robustness gain. To the best of our knowledge, our approach is the first one that improves model robustness without compromising performance.',\n",
       "  'authors': ['Hao-Yun Chen',\n",
       "   'Jhao-Hong Liang',\n",
       "   'Shih-Chieh Chang',\n",
       "   'Jia-Yu Pan',\n",
       "   'Yu-Ting Chen',\n",
       "   'Wei Wei',\n",
       "   'Da-Cheng Juan'],\n",
       "  'published': '2019-03-23',\n",
       "  'conference': 'improving-adversarial-robustness-via-guided-1',\n",
       "  'conference_url_abs': 'http://openaccess.thecvf.com/content_ICCV_2019/html/Chen_Improving_Adversarial_Robustness_via_Guided_Complement_Entropy_ICCV_2019_paper.html',\n",
       "  'conference_url_pdf': 'http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Improving_Adversarial_Robustness_via_Guided_Complement_Entropy_ICCV_2019_paper.pdf',\n",
       "  'proceeding': 'iccv-2019-10'},\n",
       " {'id': 'comment-on-adv-bnn-improved-adversarial',\n",
       "  'arxiv_id': '1907.00895',\n",
       "  'nips_id': None,\n",
       "  'url_abs': 'https://arxiv.org/abs/1907.00895v1',\n",
       "  'url_pdf': 'https://arxiv.org/pdf/1907.00895v1.pdf',\n",
       "  'title': 'Comment on \"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\"',\n",
       "  'abstract': 'A recent paper by Liu et al. combines the topics of adversarial training and Bayesian Neural Networks (BNN) and suggests that adversarially trained BNNs are more robust against adversarial attacks than their non-Bayesian counterparts. Here, I analyze the proposed defense and suggest that one needs to adjust the adversarial attack to incorporate the stochastic nature of a Bayesian network to perform an accurate evaluation of its robustness. Using this new type of attack I show that there appears to be no strong evidence for higher robustness of the adversarially trained BNNs.',\n",
       "  'authors': ['Roland S. Zimmermann'],\n",
       "  'published': '2019-07-01',\n",
       "  'conference': None,\n",
       "  'conference_url_abs': None,\n",
       "  'conference_url_pdf': None,\n",
       "  'proceeding': None}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http.get(f\"/tasks/{'bird-classification'}/papers/?page={1}\")['results'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:50:00.220536Z",
     "start_time": "2021-04-21T09:50:00.208992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901141"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(len, area_paper_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:51:12.811111Z",
     "start_time": "2021-04-21T09:51:12.737597Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:52:21.600319Z",
     "start_time": "2021-04-21T09:51:24.841487Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('paperswithcode.yml', 'w') as y:\n",
    "    yaml.dump(area_paper_dict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:08:07.655000Z",
     "start_time": "2021-04-21T08:08:07.647417Z"
    }
   },
   "outputs": [],
   "source": [
    "area_papers = {area: len(p) for area, p in area_paper_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:10:44.344016Z",
     "start_time": "2021-04-21T08:10:44.334974Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "_area_paper_dict = {area: list(chain(*area_paper_dict[area])) for area, a in area_paper_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:10:54.811154Z",
     "start_time": "2021-04-21T08:10:54.802509Z"
    }
   },
   "outputs": [],
   "source": [
    "area_papers = {area: len(p) for area, p in _area_paper_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:11:00.921902Z",
     "start_time": "2021-04-21T08:11:00.902901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversarial': 144,\n",
       " 'audio': 473,\n",
       " 'computer-code': 338,\n",
       " 'computer-vision': 779,\n",
       " 'graphs': 792,\n",
       " 'knowledge-base': 289,\n",
       " 'medical': 550,\n",
       " 'methodology': 1293,\n",
       " 'miscellaneous': 643,\n",
       " 'music': 239,\n",
       " 'natural-language-processing': 773,\n",
       " 'playing-games': 630,\n",
       " 'reasoning': 252,\n",
       " 'robots': 585,\n",
       " 'speech': 1283,\n",
       " 'time-series': 839}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:29:56.151098Z",
     "start_time": "2021-04-21T08:29:54.463222Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'page'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-0c553fd060c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_paper_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'music-generation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tea_client\\handler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHttpClientError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\paperswithcode\\client.py\u001b[0m in \u001b[0;36mtask_paper_list\u001b[1;34m(self, task_id, page, items_per_page)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mPapers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPapers\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m--> 429\u001b[1;33m         return self.__page(\n\u001b[0m\u001b[0;32m    430\u001b[0m             self.http.get(\n\u001b[0;32m    431\u001b[0m                 \u001b[1;34mf\"/tasks/{task_id}/papers/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\paperswithcode\\client.py\u001b[0m in \u001b[0;36m__page\u001b[1;34m(cls, result, page_model)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mprevious_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"previous\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprevious_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mprevious_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         return page_model(\n\u001b[0;32m     83\u001b[0m             \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\paperswithcode\\client.py\u001b[0m in \u001b[0;36m__parse\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_qs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"page\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'page'"
     ]
    }
   ],
   "source": [
    "client.task_paper_list(task_id='music-generation', page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:30:12.837758Z",
     "start_time": "2021-04-21T08:30:10.872811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['midi-sandwich2-rnn-based-hierarchical-multi',\n",
       " 'improving-automatic-jazz-melody-generation-by',\n",
       " 'lstm-based-music-generation-system',\n",
       " 'high-level-control-of-drum-track-generation',\n",
       " 'nonoto-a-model-agnostic-web-interface-for',\n",
       " 'neural-shuffle-exchange-networks-sequence',\n",
       " 'midinet-a-convolutional-generative',\n",
       " 'a-functional-taxonomy-of-music-generation',\n",
       " 'polyphonic-music-generation-by-modeling',\n",
       " 'interactive-music-generation-with-positional',\n",
       " 'style-imitation-and-chord-invention-in',\n",
       " 'adaptive-music-composition-for-games',\n",
       " 'semi-recurrent-cnn-based-vae-gan-for',\n",
       " 'from-context-to-concept-exploring-semantic',\n",
       " 'latent-normalizing-flows-for-discrete',\n",
       " 'the-nes-music-database-a-multi-instrumental',\n",
       " 'this-time-with-feeling-learning-expressive',\n",
       " 'deep-segment-hash-learning-for-music',\n",
       " 'sing-symbol-to-instrument-neural-generator',\n",
       " 'deep-learning-for-music',\n",
       " 'musegan-multi-track-sequential-generative',\n",
       " 'modeling-temporal-dependencies-in-high',\n",
       " 'lead-sheet-generation-and-arrangement-by',\n",
       " 'maximum-entropy-models-capture-melodic-styles',\n",
       " 'song-from-pi-a-musically-plausible-network',\n",
       " 'learning-to-fuse-music-genres-with-generative',\n",
       " 'progressive-generative-adversarial-binary',\n",
       " 'music-generation-by-deep-learning-challenges',\n",
       " 'melnet-a-generative-model-for-audio-in-the',\n",
       " 'classical-music-generation-in-distinct',\n",
       " 'inspecting-and-interacting-with-meaningful',\n",
       " 'a-classifying-variational-autoencoder-with',\n",
       " 'melody-generation-using-an-interactive',\n",
       " 'a-unit-selection-methodology-for-music',\n",
       " 'composing-music-with-grammar-argumented',\n",
       " 'a-critical-review-of-recurrent-neural',\n",
       " 'the-challenge-of-realistic-music-generation',\n",
       " 'glsr-vae-geodesic-latent-space-regularization',\n",
       " 'gelisp-a-library-to-represent-musical-csps',\n",
       " 'convolutional-generative-adversarial-networks',\n",
       " 'learning-temporal-dependencies-in-data-using',\n",
       " 'midi-sandwich-multi-model-multi-task',\n",
       " 'deep-learning-techniques-for-music-generation',\n",
       " 'live-orchestral-piano-a-system-for-real-time',\n",
       " 'conditioning-deep-generative-raw-audio-models',\n",
       " 'imposing-higher-level-structure-in-polyphonic',\n",
       " 'objective-reinforced-generative-adversarial',\n",
       " 'the-effect-of-explicit-structure-encoding-of',\n",
       " 'lakhnes-improving-multi-instrumental-music']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id = 'music-generation'\n",
    "page_idx = 2\n",
    "[x['id'] for x in http.get(f\"/tasks/{task_id}/papers/?page={page_idx}\")['results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http.get(\n",
    "    f\"/tasks/{task_id}/papers/\",\n",
    "    params=self.__params(page, items_per_page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
